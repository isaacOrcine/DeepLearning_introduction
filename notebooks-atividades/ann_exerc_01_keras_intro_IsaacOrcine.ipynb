{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clMqnuN8vady"
   },
   "source": [
    "# Curso: Redes Neurais e Deep Learning\n",
    "\n",
    "Prof. Denilson Alves Pereira\n",
    "https://sites.google.com/ufla.br/denilsonpereira/\n",
    "Departamento de Ciência da Computação -\n",
    "Instituto de Ciências Exatas e Tecnológicas -\n",
    "Universidade Federal de Lavras\n",
    "\n",
    "# Atividade Prática 01\n",
    "\n",
    "**Instruções:**\n",
    "1. Siga os passos indicados em cada célula abaixo para completar a atividade.\n",
    "2. Você deve inserir código somente entre as linhas marcadas com **INICIE O CÓDIGO AQUI** e **TERMINE O CÓDIGO AQUI**. Há uma indicação de quantas linhas de código são necessárias.\n",
    "3. Em alguns pontos, confira o resultado esperado conforme marcado com **SAÍDA ESPERADA**.\n",
    "\n",
    "**Tempo estimado para execução**: 1 hora\n",
    "\n",
    "Versão: Junho, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MaRAWDzLvad1"
   },
   "source": [
    "## O Problema a ser Resolvido\n",
    "\n",
    "O objetivo da atividade é elaborar uma rede neural para predizer se um paciente tem ou não diabetes, com base nas medidas diagnósticas contidas no *dataset* disponível em https://www.kaggle.com/uciml/pima-indians-diabetes-database.\n",
    "\n",
    "Os dados são de pacientes do sexo feminino, com pelo menos 20 anos de idade. Os atributos das condições médicas incluem o número de gestações que a paciente teve, seu IMC, nível de insulina, idade e outros. A classe a ser predita é o atributo \"Outcome\", cujos valores são 0 (não tem diabetes) ou 1 (tem diabetes). Portanto, é um problema de classificação binária.\n",
    "\n",
    "Você vai praticar as seguintes habilidades:\n",
    "- Efetuar o pré-processamento dos dados, separando-os em conjuntos de treino e teste.\n",
    "- Configurar uma rede neural simples para um problema de classificação binária."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U43keoUGvad3"
   },
   "source": [
    "## Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lN0UYIIEvad4"
   },
   "outputs": [],
   "source": [
    "import numpy as np # package for scientific computing\n",
    "import tensorflow as tf  #  package for numerical computation using data flow graphs\n",
    "from tensorflow import keras  # package for deep learning\n",
    "import pandas as pd # package for working with structured data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6-0Cwk-vad5"
   },
   "source": [
    "## Pré-Processamentos dos Dados de Treino e de Teste\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "suWA9irdvad6",
    "outputId": "7ccc3801-e2a1-4bfc-8059-9021fd6a83bc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"data\",\n  \"rows\": 768,\n  \"fields\": [\n    {\n      \"column\": \"Pregnancies\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 17,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          6,\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Glucose\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31,\n        \"min\": 0,\n        \"max\": 199,\n        \"num_unique_values\": 136,\n        \"samples\": [\n          151,\n          101,\n          112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BloodPressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 0,\n        \"max\": 122,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          86,\n          46,\n          85\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SkinThickness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          7,\n          12,\n          48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Insulin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115,\n        \"min\": 0,\n        \"max\": 846,\n        \"num_unique_values\": 186,\n        \"samples\": [\n          52,\n          41,\n          183\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.8841603203754405,\n        \"min\": 0.0,\n        \"max\": 67.1,\n        \"num_unique_values\": 248,\n        \"samples\": [\n          19.9,\n          31.0,\n          38.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DiabetesPedigreeFunction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33132859501277484,\n        \"min\": 0.078,\n        \"max\": 2.42,\n        \"num_unique_values\": 517,\n        \"samples\": [\n          1.731,\n          0.426,\n          0.138\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 21,\n        \"max\": 81,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          60,\n          47,\n          72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Outcome\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "data"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-786e2800-98d8-4ff3-a4d8-6a3642b2aa56\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-786e2800-98d8-4ff3-a4d8-6a3642b2aa56')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-786e2800-98d8-4ff3-a4d8-6a3642b2aa56 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-786e2800-98d8-4ff3-a4d8-6a3642b2aa56');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-1fa4ea25-b468-4a3f-9d6c-06eee4e8c44b\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1fa4ea25-b468-4a3f-9d6c-06eee4e8c44b')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-1fa4ea25-b468-4a3f-9d6c-06eee4e8c44b button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataset\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "data.head() # display dataset first lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZkG1pVkwmJv"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZW5ZY4WOvad7"
   },
   "outputs": [],
   "source": [
    "# Separate the class from other attributes\n",
    "X = data.drop(\"Outcome\", axis=1)\n",
    "Y = data[\"Outcome\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdzm3lv1vad8"
   },
   "source": [
    "Documentação de *train_test_split*: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html <br>\n",
    "A função divide os dados em partições de treino e teste, de acordo com a proporção especificada pelo parâmetro *test_size*. <br>\n",
    "O parâmetro *random_state* é usado para deixar os resultados reproduzíveis para fins de avaliação do exercício."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "aBjBevt8vad9"
   },
   "outputs": [],
   "source": [
    "# Preparing the dataset for training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set_X, test_set_X, train_set_Y, test_set_Y = train_test_split(X, Y, test_size=0.20, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9PlEpHwvad-"
   },
   "source": [
    "Padronize os atributos usando a média e a variância dos dados\n",
    "\n",
    "Dica: use a função *fit_transform*: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8127IEunvad-"
   },
   "outputs": [],
   "source": [
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "### INICIE O CÓDIGO AQUI ### (2 linhas de código)\n",
    "train_set_X = scaler.fit_transform(train_set_X) #ajusta e tranforma os dados de treino\n",
    "test_set_X  = scaler.fit_transform(test_set_X)\n",
    "### TERMINE O CÓDIGO AQUI ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VpBh8pipvad_",
    "outputId": "3901b0f5-5979-48ce-a38f-698496ba393d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_X:\n",
      " [[ 0.35483802 -0.370418    0.16624635  1.40032403 -0.01279543  0.49863797\n",
      "  -0.61786951  0.01064085]\n",
      " [-0.54794048 -0.55620696  0.9024924   0.96548604  0.40069886  1.70739891\n",
      "  -1.0345765  -0.86049025]]\n",
      "\n",
      "test_set_X:\n",
      " [[-0.83168001 -1.14367855 -0.39723824 -0.57849223 -0.36848171 -0.47210798\n",
      "   0.22800925 -0.84284936]\n",
      " [ 0.8647269   1.8633592   0.67258938  0.00976179  0.72124393  0.58740671\n",
      "   0.24525553  1.28629259]]\n"
     ]
    }
   ],
   "source": [
    "# Checking\n",
    "print(\"train_set_X:\\n\", train_set_X[:2,:])\n",
    "print(\"\\ntest_set_X:\\n\", test_set_X[:2,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-H_NaIlKvad_"
   },
   "source": [
    "**SAÍDA ESPERADA:** <br>\n",
    "train_set_X: <br>\n",
    " [[ 0.35483802 -0.370418    0.16624635  1.40032403 -0.01279543  0.49863797  -0.61786951  0.01064085] <br>\n",
    " [-0.54794048 -0.55620696  0.9024924   0.96548604  0.40069886  1.70739891  -1.0345765  -0.86049025]] <br>\n",
    "<br>\n",
    "test_set_X: <br>\n",
    "[[-0.83168001 -1.14367855 -0.39723824 -0.57849223 -0.36848171 -0.47210798  0.22800925 -0.84284936] <br>\n",
    " [ 0.8647269   1.8633592   0.67258938  0.00976179  0.72124393  0.58740671  0.24525553  1.28629259]] <br>\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4IoReOu6vad_"
   },
   "source": [
    "Obtenha o número de atributos e o número de exemplos de treinamento\n",
    "\n",
    "Dica: use a função *shape*: https://numpy.org/devdocs/reference/generated/numpy.shape.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9KwT-6lkvaeA",
    "outputId": "e56ef72a-cc7b-4a57-d474-979528ac8350"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of attributes: n = 8\n",
      "Number of training examples: m = 614\n",
      "Train set X shape: (614, 8)\n",
      "Train set Y shape: (614,)\n",
      "Test set X shape: (154, 8)\n",
      "Test set Y shape: (154,)\n"
     ]
    }
   ],
   "source": [
    "### INICIE O CÓDIGO AQUI ### (2 linhas de código)\n",
    "n = train_set_X.shape[1] # number of attributes\n",
    "m = train_set_X.shape[0] # number of training examples\n",
    "### TERMINE O CÓDIGO AQUI ###\n",
    "\n",
    "print (\"Number of attributes: n = \" + str(n))\n",
    "print (\"Number of training examples: m = \" + str(m))\n",
    "print (\"Train set X shape: \" + str(train_set_X.shape))\n",
    "print (\"Train set Y shape: \" + str(train_set_Y.shape))\n",
    "print (\"Test set X shape: \" + str(test_set_X.shape))\n",
    "print (\"Test set Y shape: \" + str(test_set_Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ComJl2tjvaeA"
   },
   "source": [
    "**SAÍDA ESPERADA**: <br>\n",
    "Number of attributes: n = 8 <br>\n",
    "Number of training examples: m = 614 <br>\n",
    "Train set X shape: (614, 8) <br>\n",
    "Train set Y shape: (614,) <br>\n",
    "Test set X shape: (154, 8) <br>\n",
    "Test set Y shape: (154,) <br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_bxYOD49vaeA"
   },
   "source": [
    "## Definição do Modelo\n",
    "\n",
    "Crie um modelo em Keras com a seguinte configuração:\n",
    "- Camada de entrada: no formato dos dados de entrada do problema\n",
    "- Camada 1: 3 neurônios, função de ativação *Tanh*\n",
    "- Camada 2: 5 neurônios, função de ativação *Tanh*\n",
    "- Camada 3: 3 neurônios, função de ativação *Tanh*\n",
    "- Camada 4 (saída): 1 neurônio, função de ativação *Sigmoid*\n",
    "\n",
    "Dica 1: use a classe *Model*: https://keras.io/api/models/model/ <br>\n",
    "Dica 2: veja as funções de ativação disponíveis: https://keras.io/api/layers/activations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "oEzfxI7HvaeB"
   },
   "outputs": [],
   "source": [
    "### INICIE O CÓDIGO AQUI ### (6 linhas de código)\n",
    "inputs = keras.Input(shape=(train_set_X.shape[1],))\n",
    "x = keras.layers.Dense(units=3, activation=\"tanh\")(inputs)  # Camada 1 com 3 neurônios\n",
    "x = keras.layers.Dense(units=5, activation=\"tanh\")(x)       # Camada 2 com 5 neurônios\n",
    "x = keras.layers.Dense(units=3, activation=\"tanh\")(x)       # Camada 3 com 3 neurônios\n",
    "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)    # Camada de saída com 1 neurônio\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)         #camada de modelo\n",
    "### TERMINE O CÓDIGO AQUI ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5UBqZXDlvaeB",
    "outputId": "3b9fb1fc-946b-4982-b40b-56cbcaa16f4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 1)\n"
     ]
    }
   ],
   "source": [
    "# Checking\n",
    "processed_data = model(train_set_X)\n",
    "print(processed_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DL8_kEKQvaeC"
   },
   "source": [
    "**SAÍDA ESPERADA**: <br>\n",
    "(614, 1)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "4cDspJ2YvaeC",
    "outputId": "083d3837-e34b-4b3e-ab80-1338c76c5f2c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │              \u001b[38;5;34m27\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m20\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │              \u001b[38;5;34m18\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m4\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69</span> (276.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m69\u001b[0m (276.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69</span> (276.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m69\u001b[0m (276.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prints a summary of the network, showing its architecture and parameters.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39OE_hBXvaeC"
   },
   "source": [
    "**SAÍDA ESPERADA**: <br>\n",
    "Confira a configuração da rede e o total de parâmetros = 69\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAEUbktBvaeD"
   },
   "source": [
    "## Compilação do Modelo\n",
    "\n",
    "Compile o model usando os seguintes parâmetros:\n",
    "- Função de perda: mean_absolute_error\n",
    "- Otimizador: RMSprop\n",
    "- Métricas: accuracy, Precision, Recall\n",
    "\n",
    "Dica 1: use a função *compile*: https://keras.io/api/models/model_training_apis/ <br>\n",
    "Dica 2: relação de funções de perda: https://www.tensorflow.org/api_docs/python/tf/keras/losses <br>\n",
    "Dica 3: relação de otimizadores: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers <br>\n",
    "Dica 4: relação de métricas: https://keras.io/api/metrics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "o7ggcnflvaeD"
   },
   "outputs": [],
   "source": [
    "### INICIE O CÓDIGO AQUI ### (1 linha de código)\n",
    "model.compile(optimizer='RMSprop',loss='mean_absolute_error',  metrics=['accuracy', 'Precision', 'Recall'])\n",
    "### TERMINE O CÓDIGO AQUI ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsIIjp9qvaeD"
   },
   "source": [
    "## Treinamento do Modelo\n",
    "\n",
    "Ajusta o modelo aos dados de treinamento.\n",
    "Devem ser fornecidos os dados de treinamento, o número de épocas (iterações) e o tamanho do lote (batch). Uma época é composta por uma única passagem por todos os exemplos do conjunto de treino. O tamanho do lote define o número de amostras (exemplos) a serem consideradas pelo modelo antes de atualizar os pesos. Assim, uma época é composta por um ou mais lotes.\n",
    "\n",
    "Efetue o treinamento do modelo usando os seguintes parâmetros:\n",
    "- Tamanho do lote: 64\n",
    "- Número de épocas: 1000\n",
    "\n",
    "Dica: use a função *fit*: https://keras.io/api/models/model_training_apis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ARTQLTJBvaeD",
    "outputId": "ea81abd7-c7df-4469-cf34-6f5a689ff9ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7790 - Recall: 0.6040 - accuracy: 0.8082 - loss: 0.1918 \n",
      "Epoch 2/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7736 - Recall: 0.5645 - accuracy: 0.7792 - loss: 0.2208 \n",
      "Epoch 3/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7763 - Recall: 0.6125 - accuracy: 0.7984 - loss: 0.2016 \n",
      "Epoch 4/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8113 - Recall: 0.5958 - accuracy: 0.8079 - loss: 0.1921 \n",
      "Epoch 5/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7412 - Recall: 0.6045 - accuracy: 0.8194 - loss: 0.1806 \n",
      "Epoch 6/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8094 - Recall: 0.5876 - accuracy: 0.8145 - loss: 0.1855 \n",
      "Epoch 7/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8030 - Recall: 0.6189 - accuracy: 0.8190 - loss: 0.1810 \n",
      "Epoch 8/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8146 - Recall: 0.6550 - accuracy: 0.8397 - loss: 0.1603 \n",
      "Epoch 9/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8068 - Recall: 0.6126 - accuracy: 0.8123 - loss: 0.1877 \n",
      "Epoch 10/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7781 - Recall: 0.5785 - accuracy: 0.8111 - loss: 0.1889 \n",
      "Epoch 11/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7864 - Recall: 0.6269 - accuracy: 0.8131 - loss: 0.1869 \n",
      "Epoch 12/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7705 - Recall: 0.5981 - accuracy: 0.7999 - loss: 0.2001 \n",
      "Epoch 13/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7909 - Recall: 0.5852 - accuracy: 0.8032 - loss: 0.1968 \n",
      "Epoch 14/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7701 - Recall: 0.5723 - accuracy: 0.8140 - loss: 0.1860 \n",
      "Epoch 15/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7350 - Recall: 0.5599 - accuracy: 0.7795 - loss: 0.2205 \n",
      "Epoch 16/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7985 - Recall: 0.6074 - accuracy: 0.8119 - loss: 0.1881 \n",
      "Epoch 17/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7798 - Recall: 0.6125 - accuracy: 0.8103 - loss: 0.1897 \n",
      "Epoch 18/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7923 - Recall: 0.6112 - accuracy: 0.8037 - loss: 0.1963 \n",
      "Epoch 19/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8070 - Recall: 0.5987 - accuracy: 0.8046 - loss: 0.1954 \n",
      "Epoch 20/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7792 - Recall: 0.6277 - accuracy: 0.8117 - loss: 0.1883 \n",
      "Epoch 21/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7909 - Recall: 0.6003 - accuracy: 0.7982 - loss: 0.2018 \n",
      "Epoch 22/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7725 - Recall: 0.6355 - accuracy: 0.8144 - loss: 0.1856 \n",
      "Epoch 23/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8181 - Recall: 0.5965 - accuracy: 0.8156 - loss: 0.1844 \n",
      "Epoch 24/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7745 - Recall: 0.5911 - accuracy: 0.8066 - loss: 0.1934 \n",
      "Epoch 25/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7820 - Recall: 0.5863 - accuracy: 0.7978 - loss: 0.2022 \n",
      "Epoch 26/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7967 - Recall: 0.5891 - accuracy: 0.8113 - loss: 0.1887 \n",
      "Epoch 27/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8133 - Recall: 0.5722 - accuracy: 0.8036 - loss: 0.1964 \n",
      "Epoch 28/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8218 - Recall: 0.6150 - accuracy: 0.8054 - loss: 0.1946 \n",
      "Epoch 29/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7874 - Recall: 0.6040 - accuracy: 0.8069 - loss: 0.1931 \n",
      "Epoch 30/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8152 - Recall: 0.5738 - accuracy: 0.8049 - loss: 0.1951 \n",
      "Epoch 31/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7737 - Recall: 0.6054 - accuracy: 0.8089 - loss: 0.1911 \n",
      "Epoch 32/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8179 - Recall: 0.5536 - accuracy: 0.8002 - loss: 0.1998 \n",
      "Epoch 33/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7453 - Recall: 0.6134 - accuracy: 0.7937 - loss: 0.2063 \n",
      "Epoch 34/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7998 - Recall: 0.6060 - accuracy: 0.8148 - loss: 0.1852 \n",
      "Epoch 35/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7932 - Recall: 0.5955 - accuracy: 0.7945 - loss: 0.2055  \n",
      "Epoch 36/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8073 - Recall: 0.6044 - accuracy: 0.8124 - loss: 0.1876 \n",
      "Epoch 37/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7819 - Recall: 0.6535 - accuracy: 0.8203 - loss: 0.1797  \n",
      "Epoch 38/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7864 - Recall: 0.6285 - accuracy: 0.8187 - loss: 0.1813 \n",
      "Epoch 39/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7751 - Recall: 0.6030 - accuracy: 0.8016 - loss: 0.1984 \n",
      "Epoch 40/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7978 - Recall: 0.6285 - accuracy: 0.8230 - loss: 0.1770 \n",
      "Epoch 41/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7840 - Recall: 0.5849 - accuracy: 0.7982 - loss: 0.2018 \n",
      "Epoch 42/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8232 - Recall: 0.6038 - accuracy: 0.8250 - loss: 0.1750 \n",
      "Epoch 43/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7781 - Recall: 0.6521 - accuracy: 0.8191 - loss: 0.1809 \n",
      "Epoch 44/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7874 - Recall: 0.6241 - accuracy: 0.8079 - loss: 0.1921 \n",
      "Epoch 45/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8189 - Recall: 0.6128 - accuracy: 0.8182 - loss: 0.1818 \n",
      "Epoch 46/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7909 - Recall: 0.5627 - accuracy: 0.7936 - loss: 0.2064 \n",
      "Epoch 47/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7793 - Recall: 0.6197 - accuracy: 0.8062 - loss: 0.1938 \n",
      "Epoch 48/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8233 - Recall: 0.6099 - accuracy: 0.8064 - loss: 0.1936 \n",
      "Epoch 49/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7799 - Recall: 0.5878 - accuracy: 0.7985 - loss: 0.2015 \n",
      "Epoch 50/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7834 - Recall: 0.5881 - accuracy: 0.7925 - loss: 0.2075 \n",
      "Epoch 51/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7829 - Recall: 0.6354 - accuracy: 0.8185 - loss: 0.1815 \n",
      "Epoch 52/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8242 - Recall: 0.6304 - accuracy: 0.8200 - loss: 0.1800 \n",
      "Epoch 53/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8414 - Recall: 0.6035 - accuracy: 0.8151 - loss: 0.1849  \n",
      "Epoch 54/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8211 - Recall: 0.5803 - accuracy: 0.8151 - loss: 0.1849 \n",
      "Epoch 55/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8077 - Recall: 0.6033 - accuracy: 0.8175 - loss: 0.1825 \n",
      "Epoch 56/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8424 - Recall: 0.6219 - accuracy: 0.8303 - loss: 0.1697 \n",
      "Epoch 57/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7887 - Recall: 0.6313 - accuracy: 0.8118 - loss: 0.1882 \n",
      "Epoch 58/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7644 - Recall: 0.6331 - accuracy: 0.8116 - loss: 0.1884 \n",
      "Epoch 59/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7921 - Recall: 0.6218 - accuracy: 0.8043 - loss: 0.1957 \n",
      "Epoch 60/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7896 - Recall: 0.6271 - accuracy: 0.8178 - loss: 0.1822 \n",
      "Epoch 61/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7969 - Recall: 0.6398 - accuracy: 0.8068 - loss: 0.1932 \n",
      "Epoch 62/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7801 - Recall: 0.5880 - accuracy: 0.7975 - loss: 0.2025 \n",
      "Epoch 63/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7728 - Recall: 0.6298 - accuracy: 0.8132 - loss: 0.1868 \n",
      "Epoch 64/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7650 - Recall: 0.6011 - accuracy: 0.8069 - loss: 0.1931 \n",
      "Epoch 65/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7802 - Recall: 0.5800 - accuracy: 0.7993 - loss: 0.2007 \n",
      "Epoch 66/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8441 - Recall: 0.6260 - accuracy: 0.8149 - loss: 0.1851 \n",
      "Epoch 67/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7660 - Recall: 0.5796 - accuracy: 0.8017 - loss: 0.1983 \n",
      "Epoch 68/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7903 - Recall: 0.6516 - accuracy: 0.8197 - loss: 0.1803  \n",
      "Epoch 69/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7619 - Recall: 0.5786 - accuracy: 0.8061 - loss: 0.1939 \n",
      "Epoch 70/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8101 - Recall: 0.5827 - accuracy: 0.8026 - loss: 0.1974 \n",
      "Epoch 71/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8142 - Recall: 0.5835 - accuracy: 0.8016 - loss: 0.1984 \n",
      "Epoch 72/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8402 - Recall: 0.6092 - accuracy: 0.8214 - loss: 0.1786 \n",
      "Epoch 73/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8120 - Recall: 0.5955 - accuracy: 0.8078 - loss: 0.1922 \n",
      "Epoch 74/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7861 - Recall: 0.6371 - accuracy: 0.8184 - loss: 0.1816 \n",
      "Epoch 75/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7720 - Recall: 0.6083 - accuracy: 0.8130 - loss: 0.1870 \n",
      "Epoch 76/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7647 - Recall: 0.6298 - accuracy: 0.8221 - loss: 0.1779 \n",
      "Epoch 77/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8151 - Recall: 0.6320 - accuracy: 0.8208 - loss: 0.1792 \n",
      "Epoch 78/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7869 - Recall: 0.5754 - accuracy: 0.8111 - loss: 0.1889 \n",
      "Epoch 79/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7936 - Recall: 0.6379 - accuracy: 0.8245 - loss: 0.1755 \n",
      "Epoch 80/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8218 - Recall: 0.6310 - accuracy: 0.8322 - loss: 0.1678 \n",
      "Epoch 81/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7910 - Recall: 0.6246 - accuracy: 0.8266 - loss: 0.1734 \n",
      "Epoch 82/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7830 - Recall: 0.5957 - accuracy: 0.8011 - loss: 0.1989 \n",
      "Epoch 83/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7794 - Recall: 0.5871 - accuracy: 0.7949 - loss: 0.2051 \n",
      "Epoch 84/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7702 - Recall: 0.6598 - accuracy: 0.8126 - loss: 0.1874 \n",
      "Epoch 85/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8293 - Recall: 0.6030 - accuracy: 0.8170 - loss: 0.1830 \n",
      "Epoch 86/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7916 - Recall: 0.6099 - accuracy: 0.8097 - loss: 0.1903 \n",
      "Epoch 87/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7725 - Recall: 0.6289 - accuracy: 0.8105 - loss: 0.1895 \n",
      "Epoch 88/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8015 - Recall: 0.5953 - accuracy: 0.7958 - loss: 0.2042 \n",
      "Epoch 89/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7852 - Recall: 0.6195 - accuracy: 0.8139 - loss: 0.1861 \n",
      "Epoch 90/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8056 - Recall: 0.5980 - accuracy: 0.8137 - loss: 0.1863 \n",
      "Epoch 91/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7977 - Recall: 0.6080 - accuracy: 0.8324 - loss: 0.1676 \n",
      "Epoch 92/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7557 - Recall: 0.5950 - accuracy: 0.8007 - loss: 0.1993 \n",
      "Epoch 93/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7799 - Recall: 0.5793 - accuracy: 0.8066 - loss: 0.1934 \n",
      "Epoch 94/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7949 - Recall: 0.6059 - accuracy: 0.8126 - loss: 0.1874 \n",
      "Epoch 95/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8097 - Recall: 0.6415 - accuracy: 0.8225 - loss: 0.1775 \n",
      "Epoch 96/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7965 - Recall: 0.6040 - accuracy: 0.8014 - loss: 0.1986 \n",
      "Epoch 97/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7689 - Recall: 0.6144 - accuracy: 0.7990 - loss: 0.2010 \n",
      "Epoch 98/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7715 - Recall: 0.6208 - accuracy: 0.7995 - loss: 0.2005 \n",
      "Epoch 99/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7975 - Recall: 0.6248 - accuracy: 0.8170 - loss: 0.1830  \n",
      "Epoch 100/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8276 - Recall: 0.5979 - accuracy: 0.8152 - loss: 0.1848 \n",
      "Epoch 101/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7819 - Recall: 0.5524 - accuracy: 0.7919 - loss: 0.2081 \n",
      "Epoch 102/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7870 - Recall: 0.5861 - accuracy: 0.8029 - loss: 0.1971 \n",
      "Epoch 103/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8151 - Recall: 0.6086 - accuracy: 0.8200 - loss: 0.1800 \n",
      "Epoch 104/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7920 - Recall: 0.6415 - accuracy: 0.8241 - loss: 0.1759 \n",
      "Epoch 105/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7791 - Recall: 0.6190 - accuracy: 0.7899 - loss: 0.2101 \n",
      "Epoch 106/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7878 - Recall: 0.5765 - accuracy: 0.8089 - loss: 0.1911 \n",
      "Epoch 107/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7498 - Recall: 0.5886 - accuracy: 0.8058 - loss: 0.1942 \n",
      "Epoch 108/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7590 - Recall: 0.6342 - accuracy: 0.8167 - loss: 0.1833 \n",
      "Epoch 109/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8118 - Recall: 0.6640 - accuracy: 0.8385 - loss: 0.1615 \n",
      "Epoch 110/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7665 - Recall: 0.5621 - accuracy: 0.7987 - loss: 0.2013 \n",
      "Epoch 111/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8304 - Recall: 0.6005 - accuracy: 0.8100 - loss: 0.1900 \n",
      "Epoch 112/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8043 - Recall: 0.5894 - accuracy: 0.8056 - loss: 0.1944 \n",
      "Epoch 113/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8143 - Recall: 0.6318 - accuracy: 0.8141 - loss: 0.1859 \n",
      "Epoch 114/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8150 - Recall: 0.6192 - accuracy: 0.8248 - loss: 0.1752 \n",
      "Epoch 115/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7919 - Recall: 0.5849 - accuracy: 0.8068 - loss: 0.1932  \n",
      "Epoch 116/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8027 - Recall: 0.6156 - accuracy: 0.8193 - loss: 0.1807 \n",
      "Epoch 117/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7887 - Recall: 0.6390 - accuracy: 0.8160 - loss: 0.1840 \n",
      "Epoch 118/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7809 - Recall: 0.5664 - accuracy: 0.7938 - loss: 0.2062 \n",
      "Epoch 119/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8238 - Recall: 0.6389 - accuracy: 0.8287 - loss: 0.1713 \n",
      "Epoch 120/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7777 - Recall: 0.5880 - accuracy: 0.7984 - loss: 0.2016 \n",
      "Epoch 121/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7848 - Recall: 0.6237 - accuracy: 0.8136 - loss: 0.1864 \n",
      "Epoch 122/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7986 - Recall: 0.5834 - accuracy: 0.8073 - loss: 0.1927 \n",
      "Epoch 123/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8530 - Recall: 0.6154 - accuracy: 0.8161 - loss: 0.1839 \n",
      "Epoch 124/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7960 - Recall: 0.6270 - accuracy: 0.8084 - loss: 0.1916 \n",
      "Epoch 125/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7664 - Recall: 0.5959 - accuracy: 0.8024 - loss: 0.1976 \n",
      "Epoch 126/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8028 - Recall: 0.5949 - accuracy: 0.8087 - loss: 0.1913  \n",
      "Epoch 127/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7899 - Recall: 0.5608 - accuracy: 0.7771 - loss: 0.2229  \n",
      "Epoch 128/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7755 - Recall: 0.5841 - accuracy: 0.8121 - loss: 0.1879 \n",
      "Epoch 129/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7917 - Recall: 0.6430 - accuracy: 0.8250 - loss: 0.1750  \n",
      "Epoch 130/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8333 - Recall: 0.6204 - accuracy: 0.8215 - loss: 0.1785 \n",
      "Epoch 131/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7973 - Recall: 0.6225 - accuracy: 0.8139 - loss: 0.1861 \n",
      "Epoch 132/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7862 - Recall: 0.6499 - accuracy: 0.8215 - loss: 0.1785  \n",
      "Epoch 133/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7832 - Recall: 0.6402 - accuracy: 0.8241 - loss: 0.1759  \n",
      "Epoch 134/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7951 - Recall: 0.6224 - accuracy: 0.8068 - loss: 0.1932  \n",
      "Epoch 135/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8096 - Recall: 0.6174 - accuracy: 0.8099 - loss: 0.1901 \n",
      "Epoch 136/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7413 - Recall: 0.6166 - accuracy: 0.8024 - loss: 0.1976  \n",
      "Epoch 137/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7857 - Recall: 0.5804 - accuracy: 0.8097 - loss: 0.1903  \n",
      "Epoch 138/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8160 - Recall: 0.6129 - accuracy: 0.8199 - loss: 0.1801  \n",
      "Epoch 139/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.8190 - Recall: 0.6026 - accuracy: 0.8129 - loss: 0.1871 \n",
      "Epoch 140/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.8068 - Recall: 0.6115 - accuracy: 0.8127 - loss: 0.1873 \n",
      "Epoch 141/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8189 - Recall: 0.5721 - accuracy: 0.8031 - loss: 0.1969 \n",
      "Epoch 142/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7806 - Recall: 0.5749 - accuracy: 0.8160 - loss: 0.1840 \n",
      "Epoch 143/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7803 - Recall: 0.6084 - accuracy: 0.8157 - loss: 0.1843  \n",
      "Epoch 144/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8059 - Recall: 0.6023 - accuracy: 0.8170 - loss: 0.1830  \n",
      "Epoch 145/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8066 - Recall: 0.6194 - accuracy: 0.8165 - loss: 0.1835  \n",
      "Epoch 146/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7814 - Recall: 0.5871 - accuracy: 0.8002 - loss: 0.1998 \n",
      "Epoch 147/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7845 - Recall: 0.6067 - accuracy: 0.8186 - loss: 0.1814  \n",
      "Epoch 148/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7950 - Recall: 0.6282 - accuracy: 0.8129 - loss: 0.1871 \n",
      "Epoch 149/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8103 - Recall: 0.6140 - accuracy: 0.8030 - loss: 0.1970 \n",
      "Epoch 150/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7724 - Recall: 0.5696 - accuracy: 0.7960 - loss: 0.2040 \n",
      "Epoch 151/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8264 - Recall: 0.5737 - accuracy: 0.8148 - loss: 0.1852  \n",
      "Epoch 152/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8139 - Recall: 0.5753 - accuracy: 0.8032 - loss: 0.1968 \n",
      "Epoch 153/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8017 - Recall: 0.6041 - accuracy: 0.8176 - loss: 0.1824 \n",
      "Epoch 154/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7632 - Recall: 0.5866 - accuracy: 0.8057 - loss: 0.1943 \n",
      "Epoch 155/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8215 - Recall: 0.6558 - accuracy: 0.8378 - loss: 0.1622 \n",
      "Epoch 156/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7673 - Recall: 0.5647 - accuracy: 0.7939 - loss: 0.2061 \n",
      "Epoch 157/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7553 - Recall: 0.5896 - accuracy: 0.8003 - loss: 0.1997 \n",
      "Epoch 158/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7829 - Recall: 0.5671 - accuracy: 0.8051 - loss: 0.1949 \n",
      "Epoch 159/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7954 - Recall: 0.6061 - accuracy: 0.8140 - loss: 0.1860 \n",
      "Epoch 160/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8017 - Recall: 0.6332 - accuracy: 0.8221 - loss: 0.1779 \n",
      "Epoch 161/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7913 - Recall: 0.5875 - accuracy: 0.8113 - loss: 0.1887 \n",
      "Epoch 162/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8305 - Recall: 0.6381 - accuracy: 0.8213 - loss: 0.1787 \n",
      "Epoch 163/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8283 - Recall: 0.6535 - accuracy: 0.8346 - loss: 0.1654 \n",
      "Epoch 164/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7942 - Recall: 0.5883 - accuracy: 0.8162 - loss: 0.1838 \n",
      "Epoch 165/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7923 - Recall: 0.6373 - accuracy: 0.8187 - loss: 0.1813 \n",
      "Epoch 166/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7654 - Recall: 0.5994 - accuracy: 0.8064 - loss: 0.1936  \n",
      "Epoch 167/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7588 - Recall: 0.6027 - accuracy: 0.8046 - loss: 0.1954 \n",
      "Epoch 168/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8278 - Recall: 0.6292 - accuracy: 0.8237 - loss: 0.1763 \n",
      "Epoch 169/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8002 - Recall: 0.6076 - accuracy: 0.8090 - loss: 0.1910 \n",
      "Epoch 170/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8297 - Recall: 0.6132 - accuracy: 0.8075 - loss: 0.1925 \n",
      "Epoch 171/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7840 - Recall: 0.6380 - accuracy: 0.8285 - loss: 0.1715 \n",
      "Epoch 172/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7712 - Recall: 0.5998 - accuracy: 0.8120 - loss: 0.1880 \n",
      "Epoch 173/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7854 - Recall: 0.5835 - accuracy: 0.8102 - loss: 0.1898 \n",
      "Epoch 174/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7955 - Recall: 0.5923 - accuracy: 0.8222 - loss: 0.1778 \n",
      "Epoch 175/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8027 - Recall: 0.6141 - accuracy: 0.8106 - loss: 0.1894 \n",
      "Epoch 176/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7817 - Recall: 0.5860 - accuracy: 0.8036 - loss: 0.1964 \n",
      "Epoch 177/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8376 - Recall: 0.6186 - accuracy: 0.8360 - loss: 0.1640 \n",
      "Epoch 178/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8253 - Recall: 0.6496 - accuracy: 0.8355 - loss: 0.1645 \n",
      "Epoch 179/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7851 - Recall: 0.6087 - accuracy: 0.8156 - loss: 0.1844 \n",
      "Epoch 180/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8467 - Recall: 0.5934 - accuracy: 0.8172 - loss: 0.1828  \n",
      "Epoch 181/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7782 - Recall: 0.5966 - accuracy: 0.7992 - loss: 0.2008  \n",
      "Epoch 182/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7913 - Recall: 0.6420 - accuracy: 0.8243 - loss: 0.1757 \n",
      "Epoch 183/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8155 - Recall: 0.6340 - accuracy: 0.8219 - loss: 0.1781 \n",
      "Epoch 184/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7983 - Recall: 0.6405 - accuracy: 0.8240 - loss: 0.1760 \n",
      "Epoch 185/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7856 - Recall: 0.6021 - accuracy: 0.8025 - loss: 0.1975 \n",
      "Epoch 186/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7900 - Recall: 0.6114 - accuracy: 0.8147 - loss: 0.1853 \n",
      "Epoch 187/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8102 - Recall: 0.6242 - accuracy: 0.8139 - loss: 0.1861 \n",
      "Epoch 188/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8044 - Recall: 0.5740 - accuracy: 0.8039 - loss: 0.1961 \n",
      "Epoch 189/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7913 - Recall: 0.6213 - accuracy: 0.8274 - loss: 0.1726 \n",
      "Epoch 190/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7700 - Recall: 0.6552 - accuracy: 0.8222 - loss: 0.1778 \n",
      "Epoch 191/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7772 - Recall: 0.5904 - accuracy: 0.7941 - loss: 0.2059 \n",
      "Epoch 192/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7582 - Recall: 0.6050 - accuracy: 0.8075 - loss: 0.1925 \n",
      "Epoch 193/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8346 - Recall: 0.6281 - accuracy: 0.8197 - loss: 0.1803  \n",
      "Epoch 194/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7915 - Recall: 0.5703 - accuracy: 0.7950 - loss: 0.2050 \n",
      "Epoch 195/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8131 - Recall: 0.6143 - accuracy: 0.8178 - loss: 0.1822 \n",
      "Epoch 196/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7963 - Recall: 0.6298 - accuracy: 0.8157 - loss: 0.1843 \n",
      "Epoch 197/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8088 - Recall: 0.5858 - accuracy: 0.8173 - loss: 0.1827 \n",
      "Epoch 198/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8052 - Recall: 0.5791 - accuracy: 0.8194 - loss: 0.1806 \n",
      "Epoch 199/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8086 - Recall: 0.6329 - accuracy: 0.8271 - loss: 0.1729 \n",
      "Epoch 200/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7987 - Recall: 0.5843 - accuracy: 0.8106 - loss: 0.1894 \n",
      "Epoch 201/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8076 - Recall: 0.6257 - accuracy: 0.8304 - loss: 0.1696 \n",
      "Epoch 202/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7925 - Recall: 0.6437 - accuracy: 0.8187 - loss: 0.1813 \n",
      "Epoch 203/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8189 - Recall: 0.6230 - accuracy: 0.8193 - loss: 0.1807 \n",
      "Epoch 204/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7708 - Recall: 0.5979 - accuracy: 0.8016 - loss: 0.1984 \n",
      "Epoch 205/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7974 - Recall: 0.5882 - accuracy: 0.8121 - loss: 0.1879 \n",
      "Epoch 206/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7749 - Recall: 0.5945 - accuracy: 0.8003 - loss: 0.1997 \n",
      "Epoch 207/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7875 - Recall: 0.6005 - accuracy: 0.7993 - loss: 0.2007 \n",
      "Epoch 208/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8008 - Recall: 0.5663 - accuracy: 0.7959 - loss: 0.2041 \n",
      "Epoch 209/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8017 - Recall: 0.6270 - accuracy: 0.8091 - loss: 0.1909 \n",
      "Epoch 210/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7921 - Recall: 0.6081 - accuracy: 0.8118 - loss: 0.1882 \n",
      "Epoch 211/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7532 - Recall: 0.6306 - accuracy: 0.8151 - loss: 0.1849  \n",
      "Epoch 212/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8304 - Recall: 0.6430 - accuracy: 0.8211 - loss: 0.1789 \n",
      "Epoch 213/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7737 - Recall: 0.5906 - accuracy: 0.7955 - loss: 0.2045 \n",
      "Epoch 214/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7908 - Recall: 0.5812 - accuracy: 0.8163 - loss: 0.1837 \n",
      "Epoch 215/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7945 - Recall: 0.6207 - accuracy: 0.8141 - loss: 0.1859 \n",
      "Epoch 216/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8102 - Recall: 0.5823 - accuracy: 0.8045 - loss: 0.1955 \n",
      "Epoch 217/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8233 - Recall: 0.6179 - accuracy: 0.8195 - loss: 0.1805 \n",
      "Epoch 218/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8113 - Recall: 0.5776 - accuracy: 0.8088 - loss: 0.1912 \n",
      "Epoch 219/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7827 - Recall: 0.5686 - accuracy: 0.8023 - loss: 0.1977 \n",
      "Epoch 220/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7781 - Recall: 0.6221 - accuracy: 0.8136 - loss: 0.1864 \n",
      "Epoch 221/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7788 - Recall: 0.6180 - accuracy: 0.8105 - loss: 0.1895 \n",
      "Epoch 222/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7959 - Recall: 0.6166 - accuracy: 0.8195 - loss: 0.1805 \n",
      "Epoch 223/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8201 - Recall: 0.5779 - accuracy: 0.8073 - loss: 0.1927 \n",
      "Epoch 224/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8182 - Recall: 0.6151 - accuracy: 0.8227 - loss: 0.1773 \n",
      "Epoch 225/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7774 - Recall: 0.5939 - accuracy: 0.8170 - loss: 0.1830 \n",
      "Epoch 226/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7733 - Recall: 0.6001 - accuracy: 0.8073 - loss: 0.1927 \n",
      "Epoch 227/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7815 - Recall: 0.6108 - accuracy: 0.8109 - loss: 0.1891 \n",
      "Epoch 228/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8257 - Recall: 0.6162 - accuracy: 0.8247 - loss: 0.1753 \n",
      "Epoch 229/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7843 - Recall: 0.5748 - accuracy: 0.8118 - loss: 0.1882 \n",
      "Epoch 230/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8274 - Recall: 0.5878 - accuracy: 0.8033 - loss: 0.1967 \n",
      "Epoch 231/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7929 - Recall: 0.6246 - accuracy: 0.8174 - loss: 0.1826 \n",
      "Epoch 232/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7785 - Recall: 0.5938 - accuracy: 0.8091 - loss: 0.1909 \n",
      "Epoch 233/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7592 - Recall: 0.6275 - accuracy: 0.8114 - loss: 0.1886 \n",
      "Epoch 234/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7865 - Recall: 0.5671 - accuracy: 0.7884 - loss: 0.2116 \n",
      "Epoch 235/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8044 - Recall: 0.6059 - accuracy: 0.8091 - loss: 0.1909 \n",
      "Epoch 236/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8406 - Recall: 0.6015 - accuracy: 0.8112 - loss: 0.1888 \n",
      "Epoch 237/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8124 - Recall: 0.5925 - accuracy: 0.8080 - loss: 0.1920 \n",
      "Epoch 238/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8483 - Recall: 0.6068 - accuracy: 0.8233 - loss: 0.1767 \n",
      "Epoch 239/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8285 - Recall: 0.6115 - accuracy: 0.8060 - loss: 0.1940 \n",
      "Epoch 240/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8339 - Recall: 0.6121 - accuracy: 0.8119 - loss: 0.1881 \n",
      "Epoch 241/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7729 - Recall: 0.6160 - accuracy: 0.7969 - loss: 0.2031 \n",
      "Epoch 242/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7925 - Recall: 0.5721 - accuracy: 0.8059 - loss: 0.1941 \n",
      "Epoch 243/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7679 - Recall: 0.5925 - accuracy: 0.7990 - loss: 0.2010  \n",
      "Epoch 244/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8229 - Recall: 0.6216 - accuracy: 0.8185 - loss: 0.1815 \n",
      "Epoch 245/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7971 - Recall: 0.6449 - accuracy: 0.8193 - loss: 0.1807 \n",
      "Epoch 246/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8083 - Recall: 0.5676 - accuracy: 0.8032 - loss: 0.1968 \n",
      "Epoch 247/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8267 - Recall: 0.5928 - accuracy: 0.7944 - loss: 0.2056 \n",
      "Epoch 248/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7995 - Recall: 0.6319 - accuracy: 0.8248 - loss: 0.1752 \n",
      "Epoch 249/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7726 - Recall: 0.6181 - accuracy: 0.8112 - loss: 0.1888 \n",
      "Epoch 250/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7883 - Recall: 0.5809 - accuracy: 0.8067 - loss: 0.1933 \n",
      "Epoch 251/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8213 - Recall: 0.6005 - accuracy: 0.8207 - loss: 0.1793 \n",
      "Epoch 252/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7995 - Recall: 0.6427 - accuracy: 0.8126 - loss: 0.1874 \n",
      "Epoch 253/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7373 - Recall: 0.5681 - accuracy: 0.7758 - loss: 0.2242 \n",
      "Epoch 254/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8020 - Recall: 0.6006 - accuracy: 0.8072 - loss: 0.1928 \n",
      "Epoch 255/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8336 - Recall: 0.5634 - accuracy: 0.8053 - loss: 0.1947 \n",
      "Epoch 256/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7718 - Recall: 0.6469 - accuracy: 0.8185 - loss: 0.1815 \n",
      "Epoch 257/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7819 - Recall: 0.6298 - accuracy: 0.8208 - loss: 0.1792 \n",
      "Epoch 258/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7796 - Recall: 0.5980 - accuracy: 0.8143 - loss: 0.1857 \n",
      "Epoch 259/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7588 - Recall: 0.5730 - accuracy: 0.7965 - loss: 0.2035 \n",
      "Epoch 260/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8052 - Recall: 0.6210 - accuracy: 0.8145 - loss: 0.1855 \n",
      "Epoch 261/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7906 - Recall: 0.5806 - accuracy: 0.7947 - loss: 0.2053  \n",
      "Epoch 262/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7995 - Recall: 0.6263 - accuracy: 0.8189 - loss: 0.1811 \n",
      "Epoch 263/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8522 - Recall: 0.6103 - accuracy: 0.8142 - loss: 0.1858 \n",
      "Epoch 264/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7663 - Recall: 0.6267 - accuracy: 0.8099 - loss: 0.1901 \n",
      "Epoch 265/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8360 - Recall: 0.6433 - accuracy: 0.8339 - loss: 0.1661 \n",
      "Epoch 266/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7924 - Recall: 0.6421 - accuracy: 0.8297 - loss: 0.1703 \n",
      "Epoch 267/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7864 - Recall: 0.6234 - accuracy: 0.8153 - loss: 0.1847  \n",
      "Epoch 268/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7645 - Recall: 0.5983 - accuracy: 0.7969 - loss: 0.2031 \n",
      "Epoch 269/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7984 - Recall: 0.6376 - accuracy: 0.8230 - loss: 0.1770 \n",
      "Epoch 270/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7941 - Recall: 0.6538 - accuracy: 0.8341 - loss: 0.1659 \n",
      "Epoch 271/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7894 - Recall: 0.6105 - accuracy: 0.8172 - loss: 0.1828 \n",
      "Epoch 272/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7839 - Recall: 0.5932 - accuracy: 0.8024 - loss: 0.1976 \n",
      "Epoch 273/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8030 - Recall: 0.6117 - accuracy: 0.8090 - loss: 0.1910 \n",
      "Epoch 274/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7744 - Recall: 0.5933 - accuracy: 0.8107 - loss: 0.1893 \n",
      "Epoch 275/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7772 - Recall: 0.5614 - accuracy: 0.8006 - loss: 0.1994 \n",
      "Epoch 276/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8268 - Recall: 0.6357 - accuracy: 0.8306 - loss: 0.1694 \n",
      "Epoch 277/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7959 - Recall: 0.5886 - accuracy: 0.8055 - loss: 0.1945 \n",
      "Epoch 278/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7888 - Recall: 0.6000 - accuracy: 0.8066 - loss: 0.1934 \n",
      "Epoch 279/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8397 - Recall: 0.6274 - accuracy: 0.8284 - loss: 0.1716 \n",
      "Epoch 280/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7615 - Recall: 0.6144 - accuracy: 0.8011 - loss: 0.1989 \n",
      "Epoch 281/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7798 - Recall: 0.6136 - accuracy: 0.8135 - loss: 0.1865  \n",
      "Epoch 282/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8439 - Recall: 0.5943 - accuracy: 0.8267 - loss: 0.1733 \n",
      "Epoch 283/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7699 - Recall: 0.5924 - accuracy: 0.8099 - loss: 0.1901 \n",
      "Epoch 284/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7825 - Recall: 0.6401 - accuracy: 0.8177 - loss: 0.1823 \n",
      "Epoch 285/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7817 - Recall: 0.5973 - accuracy: 0.8117 - loss: 0.1883 \n",
      "Epoch 286/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7714 - Recall: 0.5233 - accuracy: 0.7890 - loss: 0.2110 \n",
      "Epoch 287/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7739 - Recall: 0.5919 - accuracy: 0.8055 - loss: 0.1945 \n",
      "Epoch 288/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8015 - Recall: 0.6166 - accuracy: 0.8177 - loss: 0.1823 \n",
      "Epoch 289/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8006 - Recall: 0.6059 - accuracy: 0.8137 - loss: 0.1863 \n",
      "Epoch 290/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7688 - Recall: 0.6132 - accuracy: 0.8018 - loss: 0.1982 \n",
      "Epoch 291/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7835 - Recall: 0.6034 - accuracy: 0.8156 - loss: 0.1844 \n",
      "Epoch 292/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7925 - Recall: 0.6351 - accuracy: 0.8250 - loss: 0.1750  \n",
      "Epoch 293/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7864 - Recall: 0.5764 - accuracy: 0.7980 - loss: 0.2020  \n",
      "Epoch 294/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7994 - Recall: 0.6345 - accuracy: 0.8192 - loss: 0.1808 \n",
      "Epoch 295/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7820 - Recall: 0.5954 - accuracy: 0.8074 - loss: 0.1926 \n",
      "Epoch 296/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.8123 - Recall: 0.5977 - accuracy: 0.7948 - loss: 0.2052  \n",
      "Epoch 297/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8051 - Recall: 0.6384 - accuracy: 0.8226 - loss: 0.1774 \n",
      "Epoch 298/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8026 - Recall: 0.5938 - accuracy: 0.8217 - loss: 0.1783  \n",
      "Epoch 299/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7914 - Recall: 0.6312 - accuracy: 0.8174 - loss: 0.1826  \n",
      "Epoch 300/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7938 - Recall: 0.5744 - accuracy: 0.7924 - loss: 0.2076 \n",
      "Epoch 301/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7801 - Recall: 0.6190 - accuracy: 0.8120 - loss: 0.1880  \n",
      "Epoch 302/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7835 - Recall: 0.6725 - accuracy: 0.8329 - loss: 0.1671 \n",
      "Epoch 303/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8224 - Recall: 0.6100 - accuracy: 0.8151 - loss: 0.1849 \n",
      "Epoch 304/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7863 - Recall: 0.6219 - accuracy: 0.8136 - loss: 0.1864 \n",
      "Epoch 305/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7843 - Recall: 0.5834 - accuracy: 0.8005 - loss: 0.1995  \n",
      "Epoch 306/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7894 - Recall: 0.6287 - accuracy: 0.8008 - loss: 0.1992  \n",
      "Epoch 307/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8104 - Recall: 0.6402 - accuracy: 0.8278 - loss: 0.1722 \n",
      "Epoch 308/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8007 - Recall: 0.6033 - accuracy: 0.8131 - loss: 0.1869  \n",
      "Epoch 309/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7813 - Recall: 0.6208 - accuracy: 0.8079 - loss: 0.1921  \n",
      "Epoch 310/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8178 - Recall: 0.6221 - accuracy: 0.8256 - loss: 0.1744 \n",
      "Epoch 311/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8059 - Recall: 0.6339 - accuracy: 0.8238 - loss: 0.1762  \n",
      "Epoch 312/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7538 - Recall: 0.5483 - accuracy: 0.7992 - loss: 0.2008  \n",
      "Epoch 313/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7637 - Recall: 0.5954 - accuracy: 0.8058 - loss: 0.1942 \n",
      "Epoch 314/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8141 - Recall: 0.6432 - accuracy: 0.8194 - loss: 0.1806 \n",
      "Epoch 315/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8079 - Recall: 0.6096 - accuracy: 0.8118 - loss: 0.1882  \n",
      "Epoch 316/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.8201 - Recall: 0.6199 - accuracy: 0.8212 - loss: 0.1788 \n",
      "Epoch 317/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.8355 - Recall: 0.6042 - accuracy: 0.8212 - loss: 0.1788 \n",
      "Epoch 318/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7685 - Recall: 0.5555 - accuracy: 0.7900 - loss: 0.2100 \n",
      "Epoch 319/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7864 - Recall: 0.6060 - accuracy: 0.8057 - loss: 0.1943 \n",
      "Epoch 320/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7951 - Recall: 0.6037 - accuracy: 0.8097 - loss: 0.1903  \n",
      "Epoch 321/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8111 - Recall: 0.6222 - accuracy: 0.8192 - loss: 0.1808 \n",
      "Epoch 322/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7731 - Recall: 0.6034 - accuracy: 0.8012 - loss: 0.1988  \n",
      "Epoch 323/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7846 - Recall: 0.5940 - accuracy: 0.8008 - loss: 0.1992 \n",
      "Epoch 324/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8367 - Recall: 0.6041 - accuracy: 0.8192 - loss: 0.1808 \n",
      "Epoch 325/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7926 - Recall: 0.6186 - accuracy: 0.8074 - loss: 0.1926  \n",
      "Epoch 326/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8269 - Recall: 0.6080 - accuracy: 0.8096 - loss: 0.1904  \n",
      "Epoch 327/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7607 - Recall: 0.6391 - accuracy: 0.8148 - loss: 0.1852 \n",
      "Epoch 328/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7651 - Recall: 0.6315 - accuracy: 0.8024 - loss: 0.1976 \n",
      "Epoch 329/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8171 - Recall: 0.6080 - accuracy: 0.8139 - loss: 0.1861 \n",
      "Epoch 330/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7925 - Recall: 0.6480 - accuracy: 0.8214 - loss: 0.1786 \n",
      "Epoch 331/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7973 - Recall: 0.6215 - accuracy: 0.8099 - loss: 0.1901 \n",
      "Epoch 332/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8047 - Recall: 0.6181 - accuracy: 0.8205 - loss: 0.1795 \n",
      "Epoch 333/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8116 - Recall: 0.6010 - accuracy: 0.8101 - loss: 0.1899 \n",
      "Epoch 334/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7930 - Recall: 0.5885 - accuracy: 0.8113 - loss: 0.1887 \n",
      "Epoch 335/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8215 - Recall: 0.5775 - accuracy: 0.8008 - loss: 0.1992  \n",
      "Epoch 336/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8030 - Recall: 0.6005 - accuracy: 0.8147 - loss: 0.1853 \n",
      "Epoch 337/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8153 - Recall: 0.6472 - accuracy: 0.8260 - loss: 0.1740  \n",
      "Epoch 338/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7851 - Recall: 0.5947 - accuracy: 0.8111 - loss: 0.1889  \n",
      "Epoch 339/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7776 - Recall: 0.6060 - accuracy: 0.8036 - loss: 0.1964 \n",
      "Epoch 340/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7763 - Recall: 0.5844 - accuracy: 0.8070 - loss: 0.1930 \n",
      "Epoch 341/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7736 - Recall: 0.5900 - accuracy: 0.8001 - loss: 0.2000 \n",
      "Epoch 342/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8079 - Recall: 0.6169 - accuracy: 0.8228 - loss: 0.1772 \n",
      "Epoch 343/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8054 - Recall: 0.6118 - accuracy: 0.8392 - loss: 0.1608 \n",
      "Epoch 344/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7961 - Recall: 0.6352 - accuracy: 0.8226 - loss: 0.1774 \n",
      "Epoch 345/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8020 - Recall: 0.6043 - accuracy: 0.7989 - loss: 0.2011 \n",
      "Epoch 346/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8210 - Recall: 0.6462 - accuracy: 0.8287 - loss: 0.1713  \n",
      "Epoch 347/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8181 - Recall: 0.6906 - accuracy: 0.8434 - loss: 0.1566 \n",
      "Epoch 348/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7879 - Recall: 0.6135 - accuracy: 0.8195 - loss: 0.1805 \n",
      "Epoch 349/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7942 - Recall: 0.6304 - accuracy: 0.8283 - loss: 0.1717 \n",
      "Epoch 350/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7753 - Recall: 0.5917 - accuracy: 0.8055 - loss: 0.1945 \n",
      "Epoch 351/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7588 - Recall: 0.5516 - accuracy: 0.7969 - loss: 0.2031 \n",
      "Epoch 352/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8125 - Recall: 0.5801 - accuracy: 0.8174 - loss: 0.1826  \n",
      "Epoch 353/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7773 - Recall: 0.6533 - accuracy: 0.8220 - loss: 0.1780 \n",
      "Epoch 354/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8357 - Recall: 0.6156 - accuracy: 0.8150 - loss: 0.1850 \n",
      "Epoch 355/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8209 - Recall: 0.5744 - accuracy: 0.8084 - loss: 0.1916 \n",
      "Epoch 356/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7964 - Recall: 0.5989 - accuracy: 0.8079 - loss: 0.1921 \n",
      "Epoch 357/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8084 - Recall: 0.5711 - accuracy: 0.7999 - loss: 0.2001 \n",
      "Epoch 358/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8197 - Recall: 0.6170 - accuracy: 0.8184 - loss: 0.1816 \n",
      "Epoch 359/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8110 - Recall: 0.6419 - accuracy: 0.8375 - loss: 0.1625 \n",
      "Epoch 360/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7924 - Recall: 0.6189 - accuracy: 0.8159 - loss: 0.1841 \n",
      "Epoch 361/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8094 - Recall: 0.6199 - accuracy: 0.8112 - loss: 0.1888 \n",
      "Epoch 362/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8163 - Recall: 0.6500 - accuracy: 0.8384 - loss: 0.1616 \n",
      "Epoch 363/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8366 - Recall: 0.6305 - accuracy: 0.8324 - loss: 0.1676 \n",
      "Epoch 364/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7949 - Recall: 0.5966 - accuracy: 0.8166 - loss: 0.1834 \n",
      "Epoch 365/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7255 - Recall: 0.5929 - accuracy: 0.7988 - loss: 0.2012 \n",
      "Epoch 366/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7948 - Recall: 0.5838 - accuracy: 0.8087 - loss: 0.1913 \n",
      "Epoch 367/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7418 - Recall: 0.6128 - accuracy: 0.8108 - loss: 0.1892  \n",
      "Epoch 368/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8206 - Recall: 0.6081 - accuracy: 0.8030 - loss: 0.1970 \n",
      "Epoch 369/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8175 - Recall: 0.6381 - accuracy: 0.8222 - loss: 0.1778 \n",
      "Epoch 370/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7766 - Recall: 0.5955 - accuracy: 0.8147 - loss: 0.1853 \n",
      "Epoch 371/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7671 - Recall: 0.6278 - accuracy: 0.8157 - loss: 0.1843  \n",
      "Epoch 372/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8220 - Recall: 0.6385 - accuracy: 0.8253 - loss: 0.1747 \n",
      "Epoch 373/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8096 - Recall: 0.6142 - accuracy: 0.8072 - loss: 0.1928 \n",
      "Epoch 374/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7982 - Recall: 0.5832 - accuracy: 0.7994 - loss: 0.2006 \n",
      "Epoch 375/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8005 - Recall: 0.6043 - accuracy: 0.8255 - loss: 0.1745 \n",
      "Epoch 376/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8024 - Recall: 0.6043 - accuracy: 0.8116 - loss: 0.1884 \n",
      "Epoch 377/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8331 - Recall: 0.6156 - accuracy: 0.8222 - loss: 0.1778  \n",
      "Epoch 378/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8141 - Recall: 0.5928 - accuracy: 0.8063 - loss: 0.1937 \n",
      "Epoch 379/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8026 - Recall: 0.6142 - accuracy: 0.8048 - loss: 0.1952 \n",
      "Epoch 380/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7802 - Recall: 0.5956 - accuracy: 0.8135 - loss: 0.1865 \n",
      "Epoch 381/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8197 - Recall: 0.5845 - accuracy: 0.8082 - loss: 0.1918 \n",
      "Epoch 382/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7905 - Recall: 0.5958 - accuracy: 0.7995 - loss: 0.2005 \n",
      "Epoch 383/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7796 - Recall: 0.6002 - accuracy: 0.8110 - loss: 0.1890 \n",
      "Epoch 384/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8118 - Recall: 0.6043 - accuracy: 0.8083 - loss: 0.1917 \n",
      "Epoch 385/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7842 - Recall: 0.6178 - accuracy: 0.8075 - loss: 0.1925 \n",
      "Epoch 386/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8420 - Recall: 0.5448 - accuracy: 0.8057 - loss: 0.1943 \n",
      "Epoch 387/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7626 - Recall: 0.5839 - accuracy: 0.7899 - loss: 0.2101 \n",
      "Epoch 388/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8253 - Recall: 0.5766 - accuracy: 0.8182 - loss: 0.1818 \n",
      "Epoch 389/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7705 - Recall: 0.5989 - accuracy: 0.8081 - loss: 0.1919 \n",
      "Epoch 390/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7945 - Recall: 0.5664 - accuracy: 0.8041 - loss: 0.1959 \n",
      "Epoch 391/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7775 - Recall: 0.5720 - accuracy: 0.8086 - loss: 0.1914  \n",
      "Epoch 392/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8140 - Recall: 0.5968 - accuracy: 0.7968 - loss: 0.2032 \n",
      "Epoch 393/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7951 - Recall: 0.6073 - accuracy: 0.8061 - loss: 0.1939 \n",
      "Epoch 394/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8026 - Recall: 0.5998 - accuracy: 0.8040 - loss: 0.1960  \n",
      "Epoch 395/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8128 - Recall: 0.6242 - accuracy: 0.8230 - loss: 0.1770 \n",
      "Epoch 396/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7288 - Recall: 0.6010 - accuracy: 0.7919 - loss: 0.2081 \n",
      "Epoch 397/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8291 - Recall: 0.6422 - accuracy: 0.8185 - loss: 0.1815 \n",
      "Epoch 398/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7870 - Recall: 0.6220 - accuracy: 0.8214 - loss: 0.1786 \n",
      "Epoch 399/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7961 - Recall: 0.5865 - accuracy: 0.7920 - loss: 0.2080 \n",
      "Epoch 400/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7904 - Recall: 0.5916 - accuracy: 0.7964 - loss: 0.2036  \n",
      "Epoch 401/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7800 - Recall: 0.6239 - accuracy: 0.8177 - loss: 0.1823 \n",
      "Epoch 402/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7899 - Recall: 0.5832 - accuracy: 0.8003 - loss: 0.1997  \n",
      "Epoch 403/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7818 - Recall: 0.5791 - accuracy: 0.8058 - loss: 0.1942 \n",
      "Epoch 404/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7878 - Recall: 0.6357 - accuracy: 0.8271 - loss: 0.1729 \n",
      "Epoch 405/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7542 - Recall: 0.5853 - accuracy: 0.7954 - loss: 0.2046 \n",
      "Epoch 406/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8049 - Recall: 0.6210 - accuracy: 0.8118 - loss: 0.1882 \n",
      "Epoch 407/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7779 - Recall: 0.6144 - accuracy: 0.8096 - loss: 0.1904 \n",
      "Epoch 408/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7910 - Recall: 0.6107 - accuracy: 0.8135 - loss: 0.1865 \n",
      "Epoch 409/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8031 - Recall: 0.5825 - accuracy: 0.8004 - loss: 0.1996 \n",
      "Epoch 410/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7847 - Recall: 0.5759 - accuracy: 0.8024 - loss: 0.1976 \n",
      "Epoch 411/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8254 - Recall: 0.6605 - accuracy: 0.8336 - loss: 0.1664 \n",
      "Epoch 412/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7799 - Recall: 0.6082 - accuracy: 0.8040 - loss: 0.1960 \n",
      "Epoch 413/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7474 - Recall: 0.5403 - accuracy: 0.7872 - loss: 0.2128 \n",
      "Epoch 414/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8256 - Recall: 0.5842 - accuracy: 0.8104 - loss: 0.1896 \n",
      "Epoch 415/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8388 - Recall: 0.5995 - accuracy: 0.8226 - loss: 0.1774 \n",
      "Epoch 416/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8238 - Recall: 0.6363 - accuracy: 0.8206 - loss: 0.1794 \n",
      "Epoch 417/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8072 - Recall: 0.5927 - accuracy: 0.8033 - loss: 0.1967  \n",
      "Epoch 418/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7750 - Recall: 0.6640 - accuracy: 0.8240 - loss: 0.1760 \n",
      "Epoch 419/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7789 - Recall: 0.6062 - accuracy: 0.8106 - loss: 0.1894 \n",
      "Epoch 420/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7938 - Recall: 0.5903 - accuracy: 0.8012 - loss: 0.1988  \n",
      "Epoch 421/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8069 - Recall: 0.6082 - accuracy: 0.8158 - loss: 0.1842 \n",
      "Epoch 422/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7909 - Recall: 0.5817 - accuracy: 0.7879 - loss: 0.2121 \n",
      "Epoch 423/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7978 - Recall: 0.5984 - accuracy: 0.7997 - loss: 0.2003 \n",
      "Epoch 424/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7403 - Recall: 0.6117 - accuracy: 0.8073 - loss: 0.1927  \n",
      "Epoch 425/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8380 - Recall: 0.5924 - accuracy: 0.8047 - loss: 0.1953 \n",
      "Epoch 426/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7891 - Recall: 0.6770 - accuracy: 0.8195 - loss: 0.1805 \n",
      "Epoch 427/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7694 - Recall: 0.6052 - accuracy: 0.8093 - loss: 0.1907  \n",
      "Epoch 428/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7822 - Recall: 0.6033 - accuracy: 0.8006 - loss: 0.1994 \n",
      "Epoch 429/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7827 - Recall: 0.6536 - accuracy: 0.8129 - loss: 0.1871 \n",
      "Epoch 430/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8155 - Recall: 0.6302 - accuracy: 0.8379 - loss: 0.1621 \n",
      "Epoch 431/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8043 - Recall: 0.6342 - accuracy: 0.8224 - loss: 0.1776 \n",
      "Epoch 432/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8012 - Recall: 0.6031 - accuracy: 0.8126 - loss: 0.1874  \n",
      "Epoch 433/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7848 - Recall: 0.5780 - accuracy: 0.7990 - loss: 0.2010 \n",
      "Epoch 434/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8012 - Recall: 0.5685 - accuracy: 0.8107 - loss: 0.1893 \n",
      "Epoch 435/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8126 - Recall: 0.6420 - accuracy: 0.8253 - loss: 0.1747 \n",
      "Epoch 436/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8104 - Recall: 0.5938 - accuracy: 0.8035 - loss: 0.1965 \n",
      "Epoch 437/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8120 - Recall: 0.6065 - accuracy: 0.8079 - loss: 0.1921 \n",
      "Epoch 438/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7927 - Recall: 0.6398 - accuracy: 0.8257 - loss: 0.1743 \n",
      "Epoch 439/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7639 - Recall: 0.5935 - accuracy: 0.8030 - loss: 0.1970  \n",
      "Epoch 440/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7842 - Recall: 0.5744 - accuracy: 0.8032 - loss: 0.1968 \n",
      "Epoch 441/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7903 - Recall: 0.5640 - accuracy: 0.7988 - loss: 0.2012  \n",
      "Epoch 442/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7990 - Recall: 0.6630 - accuracy: 0.8257 - loss: 0.1743 \n",
      "Epoch 443/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7997 - Recall: 0.5788 - accuracy: 0.8026 - loss: 0.1974  \n",
      "Epoch 444/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7839 - Recall: 0.6108 - accuracy: 0.8156 - loss: 0.1844  \n",
      "Epoch 445/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8094 - Recall: 0.6130 - accuracy: 0.8201 - loss: 0.1799 \n",
      "Epoch 446/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7617 - Recall: 0.5791 - accuracy: 0.7935 - loss: 0.2065  \n",
      "Epoch 447/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7676 - Recall: 0.6024 - accuracy: 0.8133 - loss: 0.1867 \n",
      "Epoch 448/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.8032 - Recall: 0.6476 - accuracy: 0.8268 - loss: 0.1732 \n",
      "Epoch 449/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7554 - Recall: 0.5786 - accuracy: 0.7976 - loss: 0.2024 \n",
      "Epoch 450/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8094 - Recall: 0.6066 - accuracy: 0.8131 - loss: 0.1869 \n",
      "Epoch 451/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7801 - Recall: 0.6210 - accuracy: 0.8138 - loss: 0.1862  \n",
      "Epoch 452/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7893 - Recall: 0.6185 - accuracy: 0.8071 - loss: 0.1929  \n",
      "Epoch 453/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7724 - Recall: 0.6302 - accuracy: 0.8151 - loss: 0.1849 \n",
      "Epoch 454/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8336 - Recall: 0.6007 - accuracy: 0.8445 - loss: 0.1555  \n",
      "Epoch 455/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7991 - Recall: 0.6667 - accuracy: 0.8332 - loss: 0.1668  \n",
      "Epoch 456/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7924 - Recall: 0.6038 - accuracy: 0.8185 - loss: 0.1815  \n",
      "Epoch 457/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7958 - Recall: 0.5651 - accuracy: 0.7843 - loss: 0.2157 \n",
      "Epoch 458/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8022 - Recall: 0.6136 - accuracy: 0.8155 - loss: 0.1845 \n",
      "Epoch 459/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7463 - Recall: 0.5365 - accuracy: 0.7900 - loss: 0.2100 \n",
      "Epoch 460/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.8270 - Recall: 0.6181 - accuracy: 0.8186 - loss: 0.1814 \n",
      "Epoch 461/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.8128 - Recall: 0.6006 - accuracy: 0.8177 - loss: 0.1823 \n",
      "Epoch 462/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.8062 - Recall: 0.6007 - accuracy: 0.8136 - loss: 0.1864 \n",
      "Epoch 463/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Precision: 0.8322 - Recall: 0.6181 - accuracy: 0.8174 - loss: 0.1826\n",
      "Epoch 464/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7964 - Recall: 0.6174 - accuracy: 0.8081 - loss: 0.1919  \n",
      "Epoch 465/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7921 - Recall: 0.6271 - accuracy: 0.8277 - loss: 0.1723  \n",
      "Epoch 466/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7989 - Recall: 0.6063 - accuracy: 0.8140 - loss: 0.1860  \n",
      "Epoch 467/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7898 - Recall: 0.6001 - accuracy: 0.7928 - loss: 0.2072 \n",
      "Epoch 468/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8240 - Recall: 0.6147 - accuracy: 0.8209 - loss: 0.1791 \n",
      "Epoch 469/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7892 - Recall: 0.5834 - accuracy: 0.7976 - loss: 0.2024 \n",
      "Epoch 470/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8035 - Recall: 0.6179 - accuracy: 0.8174 - loss: 0.1826 \n",
      "Epoch 471/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7977 - Recall: 0.5971 - accuracy: 0.8152 - loss: 0.1848 \n",
      "Epoch 472/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8027 - Recall: 0.5945 - accuracy: 0.8101 - loss: 0.1899 \n",
      "Epoch 473/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7990 - Recall: 0.6135 - accuracy: 0.8069 - loss: 0.1931  \n",
      "Epoch 474/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7967 - Recall: 0.5909 - accuracy: 0.8037 - loss: 0.1963  \n",
      "Epoch 475/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8168 - Recall: 0.5638 - accuracy: 0.8099 - loss: 0.1901 \n",
      "Epoch 476/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8112 - Recall: 0.6021 - accuracy: 0.8226 - loss: 0.1774 \n",
      "Epoch 477/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8083 - Recall: 0.6388 - accuracy: 0.8144 - loss: 0.1856 \n",
      "Epoch 478/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8079 - Recall: 0.6466 - accuracy: 0.8215 - loss: 0.1785  \n",
      "Epoch 479/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7908 - Recall: 0.5951 - accuracy: 0.8086 - loss: 0.1914 \n",
      "Epoch 480/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7946 - Recall: 0.6240 - accuracy: 0.8137 - loss: 0.1863 \n",
      "Epoch 481/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8286 - Recall: 0.6345 - accuracy: 0.8304 - loss: 0.1696 \n",
      "Epoch 482/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7602 - Recall: 0.5573 - accuracy: 0.7878 - loss: 0.2122 \n",
      "Epoch 483/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8175 - Recall: 0.6330 - accuracy: 0.8205 - loss: 0.1795  \n",
      "Epoch 484/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7483 - Recall: 0.5899 - accuracy: 0.7978 - loss: 0.2022  \n",
      "Epoch 485/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7810 - Recall: 0.6089 - accuracy: 0.8190 - loss: 0.1810  \n",
      "Epoch 486/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8656 - Recall: 0.6228 - accuracy: 0.8354 - loss: 0.1646 \n",
      "Epoch 487/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7948 - Recall: 0.5851 - accuracy: 0.8074 - loss: 0.1926 \n",
      "Epoch 488/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7933 - Recall: 0.6070 - accuracy: 0.8256 - loss: 0.1744  \n",
      "Epoch 489/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7918 - Recall: 0.5948 - accuracy: 0.7995 - loss: 0.2005 \n",
      "Epoch 490/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8533 - Recall: 0.6489 - accuracy: 0.8304 - loss: 0.1696  \n",
      "Epoch 491/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.8116 - Recall: 0.6259 - accuracy: 0.8164 - loss: 0.1836  \n",
      "Epoch 492/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7519 - Recall: 0.5655 - accuracy: 0.8016 - loss: 0.1984 \n",
      "Epoch 493/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8449 - Recall: 0.5951 - accuracy: 0.8221 - loss: 0.1779  \n",
      "Epoch 494/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8367 - Recall: 0.6441 - accuracy: 0.8315 - loss: 0.1685 \n",
      "Epoch 495/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8076 - Recall: 0.6171 - accuracy: 0.8160 - loss: 0.1840 \n",
      "Epoch 496/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7867 - Recall: 0.5897 - accuracy: 0.8064 - loss: 0.1936  \n",
      "Epoch 497/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8127 - Recall: 0.5993 - accuracy: 0.8202 - loss: 0.1798  \n",
      "Epoch 498/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7947 - Recall: 0.6151 - accuracy: 0.8183 - loss: 0.1817 \n",
      "Epoch 499/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7816 - Recall: 0.5948 - accuracy: 0.8066 - loss: 0.1934 \n",
      "Epoch 500/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7919 - Recall: 0.6328 - accuracy: 0.8111 - loss: 0.1889  \n",
      "Epoch 501/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.8143 - Recall: 0.5913 - accuracy: 0.8066 - loss: 0.1934  \n",
      "Epoch 502/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7940 - Recall: 0.6288 - accuracy: 0.8192 - loss: 0.1808  \n",
      "Epoch 503/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7938 - Recall: 0.6323 - accuracy: 0.8306 - loss: 0.1694  \n",
      "Epoch 504/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8073 - Recall: 0.6111 - accuracy: 0.8097 - loss: 0.1903  \n",
      "Epoch 505/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8309 - Recall: 0.5865 - accuracy: 0.8172 - loss: 0.1828 \n",
      "Epoch 506/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7921 - Recall: 0.6286 - accuracy: 0.8147 - loss: 0.1853  \n",
      "Epoch 507/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7555 - Recall: 0.5965 - accuracy: 0.7970 - loss: 0.2030  \n",
      "Epoch 508/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7995 - Recall: 0.5905 - accuracy: 0.7987 - loss: 0.2013 \n",
      "Epoch 509/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8297 - Recall: 0.5811 - accuracy: 0.8104 - loss: 0.1896  \n",
      "Epoch 510/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7961 - Recall: 0.6212 - accuracy: 0.8194 - loss: 0.1806 \n",
      "Epoch 511/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8134 - Recall: 0.5903 - accuracy: 0.8082 - loss: 0.1918  \n",
      "Epoch 512/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - Precision: 0.7959 - Recall: 0.5775 - accuracy: 0.7951 - loss: 0.2049\n",
      "Epoch 513/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7647 - Recall: 0.6149 - accuracy: 0.8163 - loss: 0.1837  \n",
      "Epoch 514/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7518 - Recall: 0.5804 - accuracy: 0.8070 - loss: 0.1930 \n",
      "Epoch 515/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8232 - Recall: 0.6337 - accuracy: 0.8224 - loss: 0.1776  \n",
      "Epoch 516/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7942 - Recall: 0.5986 - accuracy: 0.8168 - loss: 0.1832 \n",
      "Epoch 517/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7845 - Recall: 0.6410 - accuracy: 0.8222 - loss: 0.1778 \n",
      "Epoch 518/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8127 - Recall: 0.6001 - accuracy: 0.8095 - loss: 0.1905 \n",
      "Epoch 519/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7623 - Recall: 0.5782 - accuracy: 0.7933 - loss: 0.2067 \n",
      "Epoch 520/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7374 - Recall: 0.5875 - accuracy: 0.8031 - loss: 0.1969 \n",
      "Epoch 521/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8221 - Recall: 0.6686 - accuracy: 0.8385 - loss: 0.1615  \n",
      "Epoch 522/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8073 - Recall: 0.6069 - accuracy: 0.8048 - loss: 0.1952  \n",
      "Epoch 523/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7818 - Recall: 0.6321 - accuracy: 0.8053 - loss: 0.1947  \n",
      "Epoch 524/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7746 - Recall: 0.5990 - accuracy: 0.8042 - loss: 0.1958  \n",
      "Epoch 525/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7809 - Recall: 0.6032 - accuracy: 0.8127 - loss: 0.1873  \n",
      "Epoch 526/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8088 - Recall: 0.6217 - accuracy: 0.8295 - loss: 0.1705 \n",
      "Epoch 527/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7872 - Recall: 0.5525 - accuracy: 0.8053 - loss: 0.1947 \n",
      "Epoch 528/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8122 - Recall: 0.6049 - accuracy: 0.8118 - loss: 0.1882 \n",
      "Epoch 529/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8260 - Recall: 0.6119 - accuracy: 0.8186 - loss: 0.1814  \n",
      "Epoch 530/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7954 - Recall: 0.5675 - accuracy: 0.8043 - loss: 0.1957 \n",
      "Epoch 531/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7485 - Recall: 0.6117 - accuracy: 0.8046 - loss: 0.1954  \n",
      "Epoch 532/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7877 - Recall: 0.5792 - accuracy: 0.8071 - loss: 0.1929  \n",
      "Epoch 533/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7671 - Recall: 0.6120 - accuracy: 0.8001 - loss: 0.1999 \n",
      "Epoch 534/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7863 - Recall: 0.5953 - accuracy: 0.8063 - loss: 0.1937  \n",
      "Epoch 535/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7790 - Recall: 0.6078 - accuracy: 0.7992 - loss: 0.2008 \n",
      "Epoch 536/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8066 - Recall: 0.6182 - accuracy: 0.8213 - loss: 0.1787 \n",
      "Epoch 537/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7895 - Recall: 0.6568 - accuracy: 0.8343 - loss: 0.1657  \n",
      "Epoch 538/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8127 - Recall: 0.6108 - accuracy: 0.8260 - loss: 0.1740  \n",
      "Epoch 539/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7630 - Recall: 0.6578 - accuracy: 0.8329 - loss: 0.1671 \n",
      "Epoch 540/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7796 - Recall: 0.5993 - accuracy: 0.7882 - loss: 0.2118 \n",
      "Epoch 541/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8150 - Recall: 0.6411 - accuracy: 0.8330 - loss: 0.1670 \n",
      "Epoch 542/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8094 - Recall: 0.5873 - accuracy: 0.8272 - loss: 0.1728  \n",
      "Epoch 543/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8246 - Recall: 0.6438 - accuracy: 0.8165 - loss: 0.1835 \n",
      "Epoch 544/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8110 - Recall: 0.5914 - accuracy: 0.8030 - loss: 0.1970  \n",
      "Epoch 545/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7885 - Recall: 0.6166 - accuracy: 0.8118 - loss: 0.1882  \n",
      "Epoch 546/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7964 - Recall: 0.6015 - accuracy: 0.8108 - loss: 0.1892  \n",
      "Epoch 547/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7821 - Recall: 0.5749 - accuracy: 0.8154 - loss: 0.1846  \n",
      "Epoch 548/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7790 - Recall: 0.6045 - accuracy: 0.8127 - loss: 0.1873  \n",
      "Epoch 549/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7965 - Recall: 0.5580 - accuracy: 0.8017 - loss: 0.1983  \n",
      "Epoch 550/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8234 - Recall: 0.6303 - accuracy: 0.8341 - loss: 0.1659 \n",
      "Epoch 551/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7773 - Recall: 0.5644 - accuracy: 0.7808 - loss: 0.2192 \n",
      "Epoch 552/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7769 - Recall: 0.5853 - accuracy: 0.8043 - loss: 0.1957 \n",
      "Epoch 553/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7926 - Recall: 0.5842 - accuracy: 0.8027 - loss: 0.1973 \n",
      "Epoch 554/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7917 - Recall: 0.6222 - accuracy: 0.8205 - loss: 0.1795  \n",
      "Epoch 555/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7725 - Recall: 0.5892 - accuracy: 0.7857 - loss: 0.2143  \n",
      "Epoch 556/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8337 - Recall: 0.6303 - accuracy: 0.8264 - loss: 0.1736 \n",
      "Epoch 557/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7970 - Recall: 0.5967 - accuracy: 0.8058 - loss: 0.1942 \n",
      "Epoch 558/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7976 - Recall: 0.6612 - accuracy: 0.8296 - loss: 0.1704 \n",
      "Epoch 559/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7631 - Recall: 0.5458 - accuracy: 0.7765 - loss: 0.2235 \n",
      "Epoch 560/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8090 - Recall: 0.6027 - accuracy: 0.7955 - loss: 0.2045 \n",
      "Epoch 561/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8010 - Recall: 0.6339 - accuracy: 0.8279 - loss: 0.1721 \n",
      "Epoch 562/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7931 - Recall: 0.6822 - accuracy: 0.8361 - loss: 0.1639 \n",
      "Epoch 563/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8200 - Recall: 0.6089 - accuracy: 0.8219 - loss: 0.1781  \n",
      "Epoch 564/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8031 - Recall: 0.6154 - accuracy: 0.8103 - loss: 0.1897 \n",
      "Epoch 565/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7835 - Recall: 0.5831 - accuracy: 0.7961 - loss: 0.2039  \n",
      "Epoch 566/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7875 - Recall: 0.6102 - accuracy: 0.8179 - loss: 0.1821  \n",
      "Epoch 567/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7554 - Recall: 0.5626 - accuracy: 0.7896 - loss: 0.2104 \n",
      "Epoch 568/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.8051 - Recall: 0.6099 - accuracy: 0.8132 - loss: 0.1868  \n",
      "Epoch 569/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7973 - Recall: 0.6074 - accuracy: 0.8136 - loss: 0.1864 \n",
      "Epoch 570/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8031 - Recall: 0.6062 - accuracy: 0.8225 - loss: 0.1775  \n",
      "Epoch 571/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7645 - Recall: 0.6012 - accuracy: 0.8071 - loss: 0.1929 \n",
      "Epoch 572/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7514 - Recall: 0.5677 - accuracy: 0.7946 - loss: 0.2054  \n",
      "Epoch 573/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7866 - Recall: 0.6672 - accuracy: 0.8382 - loss: 0.1618 \n",
      "Epoch 574/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8106 - Recall: 0.6128 - accuracy: 0.8130 - loss: 0.1870  \n",
      "Epoch 575/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8086 - Recall: 0.6014 - accuracy: 0.8020 - loss: 0.1980  \n",
      "Epoch 576/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7896 - Recall: 0.5849 - accuracy: 0.7992 - loss: 0.2008 \n",
      "Epoch 577/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7822 - Recall: 0.5786 - accuracy: 0.8068 - loss: 0.1932  \n",
      "Epoch 578/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7922 - Recall: 0.5868 - accuracy: 0.7919 - loss: 0.2081  \n",
      "Epoch 579/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7696 - Recall: 0.5913 - accuracy: 0.8051 - loss: 0.1949  \n",
      "Epoch 580/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.7977 - Recall: 0.5898 - accuracy: 0.8211 - loss: 0.1789 \n",
      "Epoch 581/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7803 - Recall: 0.6356 - accuracy: 0.8143 - loss: 0.1857 \n",
      "Epoch 582/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7762 - Recall: 0.5893 - accuracy: 0.8049 - loss: 0.1951 \n",
      "Epoch 583/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7761 - Recall: 0.5685 - accuracy: 0.8006 - loss: 0.1994 \n",
      "Epoch 584/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.8062 - Recall: 0.6025 - accuracy: 0.8119 - loss: 0.1881  \n",
      "Epoch 585/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7945 - Recall: 0.6177 - accuracy: 0.8215 - loss: 0.1785 \n",
      "Epoch 586/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8208 - Recall: 0.6310 - accuracy: 0.8154 - loss: 0.1846 \n",
      "Epoch 587/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8340 - Recall: 0.6210 - accuracy: 0.8250 - loss: 0.1750 \n",
      "Epoch 588/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7949 - Recall: 0.6205 - accuracy: 0.8132 - loss: 0.1868  \n",
      "Epoch 589/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7844 - Recall: 0.5888 - accuracy: 0.7960 - loss: 0.2040  \n",
      "Epoch 590/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7910 - Recall: 0.5624 - accuracy: 0.7999 - loss: 0.2001 \n",
      "Epoch 591/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8023 - Recall: 0.6255 - accuracy: 0.8141 - loss: 0.1859 \n",
      "Epoch 592/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7721 - Recall: 0.5686 - accuracy: 0.7871 - loss: 0.2129 \n",
      "Epoch 593/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8586 - Recall: 0.6449 - accuracy: 0.8471 - loss: 0.1529  \n",
      "Epoch 594/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7825 - Recall: 0.6278 - accuracy: 0.8185 - loss: 0.1815 \n",
      "Epoch 595/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7900 - Recall: 0.6424 - accuracy: 0.8114 - loss: 0.1886  \n",
      "Epoch 596/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7918 - Recall: 0.5856 - accuracy: 0.7943 - loss: 0.2057 \n",
      "Epoch 597/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7365 - Recall: 0.5892 - accuracy: 0.7983 - loss: 0.2017 \n",
      "Epoch 598/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8119 - Recall: 0.6349 - accuracy: 0.8174 - loss: 0.1826 \n",
      "Epoch 599/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8016 - Recall: 0.5764 - accuracy: 0.8145 - loss: 0.1855 \n",
      "Epoch 600/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7993 - Recall: 0.6362 - accuracy: 0.8162 - loss: 0.1838  \n",
      "Epoch 601/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7974 - Recall: 0.6171 - accuracy: 0.8121 - loss: 0.1879 \n",
      "Epoch 602/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7745 - Recall: 0.6276 - accuracy: 0.8096 - loss: 0.1904  \n",
      "Epoch 603/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8306 - Recall: 0.6332 - accuracy: 0.8121 - loss: 0.1879  \n",
      "Epoch 604/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7853 - Recall: 0.5868 - accuracy: 0.8071 - loss: 0.1929 \n",
      "Epoch 605/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7944 - Recall: 0.6175 - accuracy: 0.8079 - loss: 0.1921 \n",
      "Epoch 606/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8011 - Recall: 0.6234 - accuracy: 0.8208 - loss: 0.1792  \n",
      "Epoch 607/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7564 - Recall: 0.5885 - accuracy: 0.7808 - loss: 0.2192  \n",
      "Epoch 608/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7691 - Recall: 0.5882 - accuracy: 0.7931 - loss: 0.2069  \n",
      "Epoch 609/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8032 - Recall: 0.5932 - accuracy: 0.8083 - loss: 0.1917 \n",
      "Epoch 610/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7563 - Recall: 0.5914 - accuracy: 0.8097 - loss: 0.1903 \n",
      "Epoch 611/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7948 - Recall: 0.6263 - accuracy: 0.8138 - loss: 0.1862 \n",
      "Epoch 612/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8116 - Recall: 0.6162 - accuracy: 0.8135 - loss: 0.1865 \n",
      "Epoch 613/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7653 - Recall: 0.5943 - accuracy: 0.8041 - loss: 0.1959  \n",
      "Epoch 614/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7415 - Recall: 0.5511 - accuracy: 0.7869 - loss: 0.2131 \n",
      "Epoch 615/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7987 - Recall: 0.5831 - accuracy: 0.7990 - loss: 0.2010 \n",
      "Epoch 616/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7783 - Recall: 0.6109 - accuracy: 0.8206 - loss: 0.1794 \n",
      "Epoch 617/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7637 - Recall: 0.5696 - accuracy: 0.8019 - loss: 0.1981  \n",
      "Epoch 618/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7627 - Recall: 0.5846 - accuracy: 0.7933 - loss: 0.2067 \n",
      "Epoch 619/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8036 - Recall: 0.6212 - accuracy: 0.8038 - loss: 0.1962 \n",
      "Epoch 620/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7776 - Recall: 0.5696 - accuracy: 0.7942 - loss: 0.2058 \n",
      "Epoch 621/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7806 - Recall: 0.6615 - accuracy: 0.8220 - loss: 0.1780  \n",
      "Epoch 622/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7799 - Recall: 0.6138 - accuracy: 0.8177 - loss: 0.1823 \n",
      "Epoch 623/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7883 - Recall: 0.6244 - accuracy: 0.8160 - loss: 0.1840 \n",
      "Epoch 624/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8091 - Recall: 0.6256 - accuracy: 0.8209 - loss: 0.1791 \n",
      "Epoch 625/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7897 - Recall: 0.5994 - accuracy: 0.8072 - loss: 0.1928  \n",
      "Epoch 626/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7962 - Recall: 0.5880 - accuracy: 0.8068 - loss: 0.1932 \n",
      "Epoch 627/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7926 - Recall: 0.5790 - accuracy: 0.7911 - loss: 0.2089 \n",
      "Epoch 628/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8103 - Recall: 0.6526 - accuracy: 0.8305 - loss: 0.1695  \n",
      "Epoch 629/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8035 - Recall: 0.5665 - accuracy: 0.8025 - loss: 0.1975  \n",
      "Epoch 630/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7987 - Recall: 0.6368 - accuracy: 0.8243 - loss: 0.1757 \n",
      "Epoch 631/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7668 - Recall: 0.6257 - accuracy: 0.8027 - loss: 0.1973  \n",
      "Epoch 632/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8019 - Recall: 0.6160 - accuracy: 0.8140 - loss: 0.1860  \n",
      "Epoch 633/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8112 - Recall: 0.6091 - accuracy: 0.8018 - loss: 0.1982 \n",
      "Epoch 634/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7770 - Recall: 0.5984 - accuracy: 0.7898 - loss: 0.2102  \n",
      "Epoch 635/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8115 - Recall: 0.6226 - accuracy: 0.8194 - loss: 0.1806 \n",
      "Epoch 636/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8021 - Recall: 0.6420 - accuracy: 0.8193 - loss: 0.1807 \n",
      "Epoch 637/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8217 - Recall: 0.5946 - accuracy: 0.8052 - loss: 0.1948  \n",
      "Epoch 638/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7914 - Recall: 0.6230 - accuracy: 0.8055 - loss: 0.1945  \n",
      "Epoch 639/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8018 - Recall: 0.6159 - accuracy: 0.8148 - loss: 0.1853 \n",
      "Epoch 640/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7975 - Recall: 0.5908 - accuracy: 0.8050 - loss: 0.1950  \n",
      "Epoch 641/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7966 - Recall: 0.5963 - accuracy: 0.8048 - loss: 0.1952  \n",
      "Epoch 642/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8552 - Recall: 0.6240 - accuracy: 0.8302 - loss: 0.1698  \n",
      "Epoch 643/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8275 - Recall: 0.6170 - accuracy: 0.8150 - loss: 0.1850 \n",
      "Epoch 644/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7978 - Recall: 0.6253 - accuracy: 0.8241 - loss: 0.1759  \n",
      "Epoch 645/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7906 - Recall: 0.6061 - accuracy: 0.8078 - loss: 0.1922  \n",
      "Epoch 646/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8068 - Recall: 0.5714 - accuracy: 0.7945 - loss: 0.2055 \n",
      "Epoch 647/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7739 - Recall: 0.6050 - accuracy: 0.8112 - loss: 0.1888  \n",
      "Epoch 648/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7976 - Recall: 0.6276 - accuracy: 0.8158 - loss: 0.1842 \n",
      "Epoch 649/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7860 - Recall: 0.5651 - accuracy: 0.7973 - loss: 0.2027  \n",
      "Epoch 650/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8155 - Recall: 0.6114 - accuracy: 0.8070 - loss: 0.1930 \n",
      "Epoch 651/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7992 - Recall: 0.6414 - accuracy: 0.8119 - loss: 0.1881  \n",
      "Epoch 652/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7872 - Recall: 0.5919 - accuracy: 0.8069 - loss: 0.1931  \n",
      "Epoch 653/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7906 - Recall: 0.5882 - accuracy: 0.7875 - loss: 0.2125  \n",
      "Epoch 654/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8197 - Recall: 0.6756 - accuracy: 0.8326 - loss: 0.1674 \n",
      "Epoch 655/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8199 - Recall: 0.5869 - accuracy: 0.8073 - loss: 0.1927  \n",
      "Epoch 656/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7900 - Recall: 0.6034 - accuracy: 0.8058 - loss: 0.1942 \n",
      "Epoch 657/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8052 - Recall: 0.6310 - accuracy: 0.8225 - loss: 0.1775 \n",
      "Epoch 658/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8012 - Recall: 0.6260 - accuracy: 0.8219 - loss: 0.1781 \n",
      "Epoch 659/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8097 - Recall: 0.5877 - accuracy: 0.8030 - loss: 0.1970 \n",
      "Epoch 660/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7644 - Recall: 0.6073 - accuracy: 0.8147 - loss: 0.1853  \n",
      "Epoch 661/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7667 - Recall: 0.5870 - accuracy: 0.7965 - loss: 0.2035 \n",
      "Epoch 662/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7638 - Recall: 0.6175 - accuracy: 0.8135 - loss: 0.1865 \n",
      "Epoch 663/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8110 - Recall: 0.6144 - accuracy: 0.8159 - loss: 0.1841  \n",
      "Epoch 664/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8009 - Recall: 0.5772 - accuracy: 0.8086 - loss: 0.1914 \n",
      "Epoch 665/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8108 - Recall: 0.5830 - accuracy: 0.7979 - loss: 0.2021 \n",
      "Epoch 666/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7611 - Recall: 0.5691 - accuracy: 0.7960 - loss: 0.2040 \n",
      "Epoch 667/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7910 - Recall: 0.6046 - accuracy: 0.8129 - loss: 0.1871  \n",
      "Epoch 668/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8123 - Recall: 0.5806 - accuracy: 0.8083 - loss: 0.1917 \n",
      "Epoch 669/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8201 - Recall: 0.5997 - accuracy: 0.8107 - loss: 0.1893  \n",
      "Epoch 670/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8037 - Recall: 0.5935 - accuracy: 0.8028 - loss: 0.1972  \n",
      "Epoch 671/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7972 - Recall: 0.5570 - accuracy: 0.7885 - loss: 0.2115  \n",
      "Epoch 672/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8111 - Recall: 0.6190 - accuracy: 0.8084 - loss: 0.1916 \n",
      "Epoch 673/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8193 - Recall: 0.6383 - accuracy: 0.8323 - loss: 0.1677  \n",
      "Epoch 674/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8272 - Recall: 0.6369 - accuracy: 0.8293 - loss: 0.1707 \n",
      "Epoch 675/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8111 - Recall: 0.5929 - accuracy: 0.8170 - loss: 0.1830  \n",
      "Epoch 676/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7975 - Recall: 0.6156 - accuracy: 0.8184 - loss: 0.1816 \n",
      "Epoch 677/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8187 - Recall: 0.6290 - accuracy: 0.8391 - loss: 0.1609 \n",
      "Epoch 678/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7812 - Recall: 0.6271 - accuracy: 0.8093 - loss: 0.1907 \n",
      "Epoch 679/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7877 - Recall: 0.6153 - accuracy: 0.8147 - loss: 0.1853  \n",
      "Epoch 680/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8095 - Recall: 0.6628 - accuracy: 0.8306 - loss: 0.1694 \n",
      "Epoch 681/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7826 - Recall: 0.6135 - accuracy: 0.8193 - loss: 0.1807  \n",
      "Epoch 682/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7700 - Recall: 0.6216 - accuracy: 0.8133 - loss: 0.1867  \n",
      "Epoch 683/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8336 - Recall: 0.6259 - accuracy: 0.8226 - loss: 0.1774 \n",
      "Epoch 684/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8205 - Recall: 0.6052 - accuracy: 0.8180 - loss: 0.1820  \n",
      "Epoch 685/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7846 - Recall: 0.5772 - accuracy: 0.8039 - loss: 0.1961 \n",
      "Epoch 686/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8055 - Recall: 0.6142 - accuracy: 0.8232 - loss: 0.1768 \n",
      "Epoch 687/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.8115 - Recall: 0.5597 - accuracy: 0.7961 - loss: 0.2039 \n",
      "Epoch 688/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7997 - Recall: 0.6088 - accuracy: 0.8063 - loss: 0.1937 \n",
      "Epoch 689/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7679 - Recall: 0.6125 - accuracy: 0.7884 - loss: 0.2116  \n",
      "Epoch 690/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8098 - Recall: 0.6085 - accuracy: 0.8175 - loss: 0.1825  \n",
      "Epoch 691/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7805 - Recall: 0.5629 - accuracy: 0.7909 - loss: 0.2091 \n",
      "Epoch 692/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8126 - Recall: 0.6023 - accuracy: 0.8178 - loss: 0.1822 \n",
      "Epoch 693/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.8108 - Recall: 0.6486 - accuracy: 0.8209 - loss: 0.1791  \n",
      "Epoch 694/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7559 - Recall: 0.5638 - accuracy: 0.7899 - loss: 0.2101 \n",
      "Epoch 695/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8300 - Recall: 0.6467 - accuracy: 0.8262 - loss: 0.1738  \n",
      "Epoch 696/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8178 - Recall: 0.6211 - accuracy: 0.8141 - loss: 0.1859  \n",
      "Epoch 697/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8002 - Recall: 0.6308 - accuracy: 0.8173 - loss: 0.1827 \n",
      "Epoch 698/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7691 - Recall: 0.6199 - accuracy: 0.8070 - loss: 0.1930 \n",
      "Epoch 699/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8105 - Recall: 0.5614 - accuracy: 0.8037 - loss: 0.1963 \n",
      "Epoch 700/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.8135 - Recall: 0.5699 - accuracy: 0.8050 - loss: 0.1950 \n",
      "Epoch 701/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7890 - Recall: 0.6058 - accuracy: 0.8118 - loss: 0.1882 \n",
      "Epoch 702/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7661 - Recall: 0.6050 - accuracy: 0.8062 - loss: 0.1938 \n",
      "Epoch 703/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.8156 - Recall: 0.6207 - accuracy: 0.8245 - loss: 0.1755 \n",
      "Epoch 704/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8080 - Recall: 0.6006 - accuracy: 0.8026 - loss: 0.1974 \n",
      "Epoch 705/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7963 - Recall: 0.6347 - accuracy: 0.8192 - loss: 0.1808 \n",
      "Epoch 706/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7869 - Recall: 0.6040 - accuracy: 0.8089 - loss: 0.1911  \n",
      "Epoch 707/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7718 - Recall: 0.5921 - accuracy: 0.8097 - loss: 0.1903 \n",
      "Epoch 708/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.7530 - Recall: 0.5687 - accuracy: 0.8029 - loss: 0.1971 \n",
      "Epoch 709/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8037 - Recall: 0.5698 - accuracy: 0.8022 - loss: 0.1978 \n",
      "Epoch 710/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7990 - Recall: 0.5977 - accuracy: 0.8191 - loss: 0.1809 \n",
      "Epoch 711/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7771 - Recall: 0.5421 - accuracy: 0.7849 - loss: 0.2151 \n",
      "Epoch 712/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7936 - Recall: 0.5735 - accuracy: 0.7926 - loss: 0.2074 \n",
      "Epoch 713/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8246 - Recall: 0.6300 - accuracy: 0.8273 - loss: 0.1727 \n",
      "Epoch 714/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7895 - Recall: 0.6474 - accuracy: 0.8119 - loss: 0.1881  \n",
      "Epoch 715/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8102 - Recall: 0.5886 - accuracy: 0.8023 - loss: 0.1977 \n",
      "Epoch 716/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.8000 - Recall: 0.6267 - accuracy: 0.8100 - loss: 0.1901 \n",
      "Epoch 717/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.8086 - Recall: 0.6115 - accuracy: 0.8111 - loss: 0.1889 \n",
      "Epoch 718/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8354 - Recall: 0.6167 - accuracy: 0.8237 - loss: 0.1763 \n",
      "Epoch 719/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8025 - Recall: 0.5832 - accuracy: 0.8120 - loss: 0.1880  \n",
      "Epoch 720/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7739 - Recall: 0.5662 - accuracy: 0.7995 - loss: 0.2005 \n",
      "Epoch 721/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7825 - Recall: 0.6185 - accuracy: 0.8109 - loss: 0.1891 \n",
      "Epoch 722/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7769 - Recall: 0.6177 - accuracy: 0.8148 - loss: 0.1852 \n",
      "Epoch 723/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8366 - Recall: 0.6186 - accuracy: 0.8187 - loss: 0.1813  \n",
      "Epoch 724/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8263 - Recall: 0.6336 - accuracy: 0.8281 - loss: 0.1719 \n",
      "Epoch 725/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8090 - Recall: 0.6284 - accuracy: 0.8157 - loss: 0.1843  \n",
      "Epoch 726/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7946 - Recall: 0.6420 - accuracy: 0.8246 - loss: 0.1754 \n",
      "Epoch 727/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8362 - Recall: 0.5393 - accuracy: 0.8071 - loss: 0.1929 \n",
      "Epoch 728/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7886 - Recall: 0.5986 - accuracy: 0.7977 - loss: 0.2023  \n",
      "Epoch 729/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8188 - Recall: 0.5750 - accuracy: 0.8057 - loss: 0.1943  \n",
      "Epoch 730/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8098 - Recall: 0.5576 - accuracy: 0.7871 - loss: 0.2129  \n",
      "Epoch 731/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7924 - Recall: 0.5691 - accuracy: 0.8020 - loss: 0.1980  \n",
      "Epoch 732/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7895 - Recall: 0.5722 - accuracy: 0.8020 - loss: 0.1980 \n",
      "Epoch 733/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7624 - Recall: 0.5420 - accuracy: 0.8021 - loss: 0.1979  \n",
      "Epoch 734/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8066 - Recall: 0.6046 - accuracy: 0.8152 - loss: 0.1848  \n",
      "Epoch 735/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8165 - Recall: 0.6266 - accuracy: 0.8146 - loss: 0.1854 \n",
      "Epoch 736/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7973 - Recall: 0.6167 - accuracy: 0.8203 - loss: 0.1797  \n",
      "Epoch 737/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8207 - Recall: 0.5857 - accuracy: 0.8071 - loss: 0.1929  \n",
      "Epoch 738/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7910 - Recall: 0.6480 - accuracy: 0.8152 - loss: 0.1848 \n",
      "Epoch 739/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7691 - Recall: 0.6267 - accuracy: 0.8128 - loss: 0.1872  \n",
      "Epoch 740/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7946 - Recall: 0.6289 - accuracy: 0.8087 - loss: 0.1913 \n",
      "Epoch 741/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7765 - Recall: 0.6021 - accuracy: 0.8032 - loss: 0.1968 \n",
      "Epoch 742/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7632 - Recall: 0.6221 - accuracy: 0.8085 - loss: 0.1915  \n",
      "Epoch 743/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7795 - Recall: 0.5878 - accuracy: 0.8112 - loss: 0.1888  \n",
      "Epoch 744/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7943 - Recall: 0.6067 - accuracy: 0.8067 - loss: 0.1933 \n",
      "Epoch 745/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7819 - Recall: 0.6247 - accuracy: 0.8254 - loss: 0.1746  \n",
      "Epoch 746/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8167 - Recall: 0.6033 - accuracy: 0.8106 - loss: 0.1894 \n",
      "Epoch 747/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8239 - Recall: 0.6144 - accuracy: 0.7978 - loss: 0.2022 \n",
      "Epoch 748/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7849 - Recall: 0.6079 - accuracy: 0.8133 - loss: 0.1867  \n",
      "Epoch 749/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7908 - Recall: 0.5863 - accuracy: 0.7880 - loss: 0.2120  \n",
      "Epoch 750/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7875 - Recall: 0.6288 - accuracy: 0.8105 - loss: 0.1895  \n",
      "Epoch 751/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8089 - Recall: 0.6175 - accuracy: 0.8154 - loss: 0.1846  \n",
      "Epoch 752/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7970 - Recall: 0.6130 - accuracy: 0.8229 - loss: 0.1771 \n",
      "Epoch 753/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8247 - Recall: 0.6163 - accuracy: 0.8188 - loss: 0.1812 \n",
      "Epoch 754/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8038 - Recall: 0.6016 - accuracy: 0.8081 - loss: 0.1919 \n",
      "Epoch 755/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8261 - Recall: 0.6481 - accuracy: 0.8226 - loss: 0.1774 \n",
      "Epoch 756/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7684 - Recall: 0.5763 - accuracy: 0.7983 - loss: 0.2017  \n",
      "Epoch 757/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7929 - Recall: 0.6082 - accuracy: 0.8175 - loss: 0.1825 \n",
      "Epoch 758/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7674 - Recall: 0.5563 - accuracy: 0.7824 - loss: 0.2176  \n",
      "Epoch 759/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8006 - Recall: 0.6263 - accuracy: 0.8173 - loss: 0.1827  \n",
      "Epoch 760/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8148 - Recall: 0.6573 - accuracy: 0.8333 - loss: 0.1667  \n",
      "Epoch 761/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8199 - Recall: 0.6087 - accuracy: 0.8142 - loss: 0.1858  \n",
      "Epoch 762/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8177 - Recall: 0.6440 - accuracy: 0.8298 - loss: 0.1702 \n",
      "Epoch 763/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7716 - Recall: 0.5937 - accuracy: 0.7915 - loss: 0.2085 \n",
      "Epoch 764/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7915 - Recall: 0.6327 - accuracy: 0.8315 - loss: 0.1685 \n",
      "Epoch 765/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8191 - Recall: 0.6140 - accuracy: 0.8160 - loss: 0.1840 \n",
      "Epoch 766/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8051 - Recall: 0.6065 - accuracy: 0.8102 - loss: 0.1898  \n",
      "Epoch 767/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8109 - Recall: 0.5746 - accuracy: 0.7991 - loss: 0.2009 \n",
      "Epoch 768/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8006 - Recall: 0.6240 - accuracy: 0.8122 - loss: 0.1878  \n",
      "Epoch 769/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7833 - Recall: 0.6222 - accuracy: 0.8113 - loss: 0.1887  \n",
      "Epoch 770/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8127 - Recall: 0.6341 - accuracy: 0.8205 - loss: 0.1795 \n",
      "Epoch 771/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7849 - Recall: 0.6002 - accuracy: 0.8039 - loss: 0.1961  \n",
      "Epoch 772/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7551 - Recall: 0.5888 - accuracy: 0.8195 - loss: 0.1805  \n",
      "Epoch 773/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8040 - Recall: 0.6184 - accuracy: 0.8231 - loss: 0.1769  \n",
      "Epoch 774/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7718 - Recall: 0.5800 - accuracy: 0.7916 - loss: 0.2084  \n",
      "Epoch 775/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7817 - Recall: 0.5835 - accuracy: 0.7959 - loss: 0.2041  \n",
      "Epoch 776/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7806 - Recall: 0.5902 - accuracy: 0.8031 - loss: 0.1969 \n",
      "Epoch 777/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8091 - Recall: 0.5821 - accuracy: 0.8144 - loss: 0.1856  \n",
      "Epoch 778/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8024 - Recall: 0.6241 - accuracy: 0.8254 - loss: 0.1746  \n",
      "Epoch 779/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8248 - Recall: 0.6363 - accuracy: 0.8244 - loss: 0.1756 \n",
      "Epoch 780/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8498 - Recall: 0.6067 - accuracy: 0.8198 - loss: 0.1802 \n",
      "Epoch 781/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7749 - Recall: 0.5791 - accuracy: 0.8042 - loss: 0.1958 \n",
      "Epoch 782/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8009 - Recall: 0.6351 - accuracy: 0.8118 - loss: 0.1882  \n",
      "Epoch 783/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7990 - Recall: 0.6057 - accuracy: 0.8112 - loss: 0.1888  \n",
      "Epoch 784/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7740 - Recall: 0.5655 - accuracy: 0.7855 - loss: 0.2145  \n",
      "Epoch 785/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7813 - Recall: 0.6339 - accuracy: 0.8220 - loss: 0.1780  \n",
      "Epoch 786/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7724 - Recall: 0.5582 - accuracy: 0.7882 - loss: 0.2118  \n",
      "Epoch 787/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7845 - Recall: 0.6035 - accuracy: 0.8019 - loss: 0.1981 \n",
      "Epoch 788/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7910 - Recall: 0.6253 - accuracy: 0.8019 - loss: 0.1982  \n",
      "Epoch 789/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8086 - Recall: 0.5893 - accuracy: 0.8140 - loss: 0.1860 \n",
      "Epoch 790/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7855 - Recall: 0.6298 - accuracy: 0.8214 - loss: 0.1786 \n",
      "Epoch 791/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8211 - Recall: 0.6124 - accuracy: 0.8165 - loss: 0.1835  \n",
      "Epoch 792/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7547 - Recall: 0.6477 - accuracy: 0.8169 - loss: 0.1831 \n",
      "Epoch 793/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8311 - Recall: 0.5571 - accuracy: 0.8137 - loss: 0.1863 \n",
      "Epoch 794/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7898 - Recall: 0.6146 - accuracy: 0.8277 - loss: 0.1723  \n",
      "Epoch 795/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8035 - Recall: 0.6254 - accuracy: 0.8181 - loss: 0.1819  \n",
      "Epoch 796/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7857 - Recall: 0.5871 - accuracy: 0.8093 - loss: 0.1907  \n",
      "Epoch 797/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8172 - Recall: 0.6103 - accuracy: 0.8170 - loss: 0.1830  \n",
      "Epoch 798/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8157 - Recall: 0.6383 - accuracy: 0.8287 - loss: 0.1713  \n",
      "Epoch 799/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7987 - Recall: 0.6479 - accuracy: 0.8252 - loss: 0.1748  \n",
      "Epoch 800/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8183 - Recall: 0.6278 - accuracy: 0.8190 - loss: 0.1810 \n",
      "Epoch 801/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7604 - Recall: 0.5758 - accuracy: 0.7819 - loss: 0.2181  \n",
      "Epoch 802/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7758 - Recall: 0.6138 - accuracy: 0.7986 - loss: 0.2014  \n",
      "Epoch 803/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7931 - Recall: 0.6005 - accuracy: 0.7993 - loss: 0.2007  \n",
      "Epoch 804/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8071 - Recall: 0.6193 - accuracy: 0.8126 - loss: 0.1874  \n",
      "Epoch 805/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7624 - Recall: 0.5977 - accuracy: 0.8096 - loss: 0.1904 \n",
      "Epoch 806/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7676 - Recall: 0.6135 - accuracy: 0.8104 - loss: 0.1896 \n",
      "Epoch 807/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8095 - Recall: 0.6291 - accuracy: 0.8144 - loss: 0.1856 \n",
      "Epoch 808/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7919 - Recall: 0.6426 - accuracy: 0.8174 - loss: 0.1826 \n",
      "Epoch 809/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7849 - Recall: 0.6038 - accuracy: 0.8180 - loss: 0.1820 \n",
      "Epoch 810/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7772 - Recall: 0.6258 - accuracy: 0.8184 - loss: 0.1816  \n",
      "Epoch 811/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8007 - Recall: 0.5952 - accuracy: 0.8117 - loss: 0.1883  \n",
      "Epoch 812/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8498 - Recall: 0.6272 - accuracy: 0.8246 - loss: 0.1754 \n",
      "Epoch 813/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7411 - Recall: 0.5821 - accuracy: 0.7961 - loss: 0.2039 \n",
      "Epoch 814/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8043 - Recall: 0.5960 - accuracy: 0.8164 - loss: 0.1836 \n",
      "Epoch 815/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7813 - Recall: 0.6119 - accuracy: 0.8115 - loss: 0.1885 \n",
      "Epoch 816/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8055 - Recall: 0.6362 - accuracy: 0.8119 - loss: 0.1881 \n",
      "Epoch 817/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7970 - Recall: 0.6099 - accuracy: 0.8311 - loss: 0.1689  \n",
      "Epoch 818/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7905 - Recall: 0.5786 - accuracy: 0.8104 - loss: 0.1896 \n",
      "Epoch 819/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7948 - Recall: 0.5664 - accuracy: 0.8007 - loss: 0.1993  \n",
      "Epoch 820/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7925 - Recall: 0.5950 - accuracy: 0.8061 - loss: 0.1939  \n",
      "Epoch 821/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7873 - Recall: 0.6194 - accuracy: 0.8120 - loss: 0.1880  \n",
      "Epoch 822/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7678 - Recall: 0.5652 - accuracy: 0.7989 - loss: 0.2011 \n",
      "Epoch 823/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.7674 - Recall: 0.6573 - accuracy: 0.8262 - loss: 0.1738 \n",
      "Epoch 824/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8063 - Recall: 0.6267 - accuracy: 0.8195 - loss: 0.1805 \n",
      "Epoch 825/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7884 - Recall: 0.6131 - accuracy: 0.7968 - loss: 0.2032  \n",
      "Epoch 826/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7941 - Recall: 0.5842 - accuracy: 0.7976 - loss: 0.2024 \n",
      "Epoch 827/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7762 - Recall: 0.5680 - accuracy: 0.8029 - loss: 0.1971  \n",
      "Epoch 828/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.8239 - Recall: 0.6148 - accuracy: 0.8173 - loss: 0.1827 \n",
      "Epoch 829/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7983 - Recall: 0.5985 - accuracy: 0.8119 - loss: 0.1881 \n",
      "Epoch 830/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7997 - Recall: 0.6122 - accuracy: 0.8226 - loss: 0.1774 \n",
      "Epoch 831/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7862 - Recall: 0.5764 - accuracy: 0.8032 - loss: 0.1968  \n",
      "Epoch 832/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7580 - Recall: 0.5730 - accuracy: 0.7885 - loss: 0.2115 \n",
      "Epoch 833/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7886 - Recall: 0.6039 - accuracy: 0.8054 - loss: 0.1946 \n",
      "Epoch 834/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.7874 - Recall: 0.6097 - accuracy: 0.8085 - loss: 0.1916  \n",
      "Epoch 835/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.7848 - Recall: 0.5767 - accuracy: 0.7943 - loss: 0.2057 \n",
      "Epoch 836/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8080 - Recall: 0.6052 - accuracy: 0.8175 - loss: 0.1825 \n",
      "Epoch 837/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.8134 - Recall: 0.5961 - accuracy: 0.8020 - loss: 0.1980 \n",
      "Epoch 838/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8077 - Recall: 0.6290 - accuracy: 0.8225 - loss: 0.1775 \n",
      "Epoch 839/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8164 - Recall: 0.6026 - accuracy: 0.8209 - loss: 0.1791  \n",
      "Epoch 840/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8148 - Recall: 0.5769 - accuracy: 0.8104 - loss: 0.1896  \n",
      "Epoch 841/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7792 - Recall: 0.6282 - accuracy: 0.8146 - loss: 0.1854  \n",
      "Epoch 842/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7837 - Recall: 0.6203 - accuracy: 0.8086 - loss: 0.1914  \n",
      "Epoch 843/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8031 - Recall: 0.5933 - accuracy: 0.8061 - loss: 0.1939 \n",
      "Epoch 844/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7709 - Recall: 0.6310 - accuracy: 0.8230 - loss: 0.1770 \n",
      "Epoch 845/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8305 - Recall: 0.6129 - accuracy: 0.8200 - loss: 0.1800 \n",
      "Epoch 846/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7933 - Recall: 0.5526 - accuracy: 0.8052 - loss: 0.1948  \n",
      "Epoch 847/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8215 - Recall: 0.6156 - accuracy: 0.8135 - loss: 0.1865  \n",
      "Epoch 848/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7547 - Recall: 0.6032 - accuracy: 0.8067 - loss: 0.1933  \n",
      "Epoch 849/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8378 - Recall: 0.6074 - accuracy: 0.8236 - loss: 0.1764  \n",
      "Epoch 850/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7741 - Recall: 0.5965 - accuracy: 0.8159 - loss: 0.1841  \n",
      "Epoch 851/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8177 - Recall: 0.6236 - accuracy: 0.8247 - loss: 0.1753  \n",
      "Epoch 852/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7932 - Recall: 0.6366 - accuracy: 0.8241 - loss: 0.1759 \n",
      "Epoch 853/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8238 - Recall: 0.6414 - accuracy: 0.8287 - loss: 0.1713  \n",
      "Epoch 854/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7876 - Recall: 0.5928 - accuracy: 0.8087 - loss: 0.1913 \n",
      "Epoch 855/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8279 - Recall: 0.6463 - accuracy: 0.8245 - loss: 0.1755  \n",
      "Epoch 856/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7883 - Recall: 0.6196 - accuracy: 0.8118 - loss: 0.1882  \n",
      "Epoch 857/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7836 - Recall: 0.5836 - accuracy: 0.8089 - loss: 0.1911  \n",
      "Epoch 858/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7843 - Recall: 0.6206 - accuracy: 0.8219 - loss: 0.1781  \n",
      "Epoch 859/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8042 - Recall: 0.6077 - accuracy: 0.8068 - loss: 0.1932  \n",
      "Epoch 860/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8118 - Recall: 0.5942 - accuracy: 0.8087 - loss: 0.1913 \n",
      "Epoch 861/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8057 - Recall: 0.6042 - accuracy: 0.8084 - loss: 0.1916 \n",
      "Epoch 862/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8181 - Recall: 0.5831 - accuracy: 0.8121 - loss: 0.1879 \n",
      "Epoch 863/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7943 - Recall: 0.6153 - accuracy: 0.8168 - loss: 0.1832  \n",
      "Epoch 864/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8291 - Recall: 0.5864 - accuracy: 0.8054 - loss: 0.1946 \n",
      "Epoch 865/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7870 - Recall: 0.6519 - accuracy: 0.8267 - loss: 0.1733 \n",
      "Epoch 866/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7822 - Recall: 0.5927 - accuracy: 0.7978 - loss: 0.2022  \n",
      "Epoch 867/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8226 - Recall: 0.6291 - accuracy: 0.8238 - loss: 0.1762  \n",
      "Epoch 868/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8300 - Recall: 0.5931 - accuracy: 0.8196 - loss: 0.1804  \n",
      "Epoch 869/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8009 - Recall: 0.6710 - accuracy: 0.8385 - loss: 0.1615  \n",
      "Epoch 870/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7833 - Recall: 0.6130 - accuracy: 0.8195 - loss: 0.1805  \n",
      "Epoch 871/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8239 - Recall: 0.6296 - accuracy: 0.8271 - loss: 0.1729  \n",
      "Epoch 872/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8170 - Recall: 0.5992 - accuracy: 0.8130 - loss: 0.1870  \n",
      "Epoch 873/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7870 - Recall: 0.5896 - accuracy: 0.8092 - loss: 0.1908 \n",
      "Epoch 874/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7839 - Recall: 0.6301 - accuracy: 0.8103 - loss: 0.1897  \n",
      "Epoch 875/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7724 - Recall: 0.6507 - accuracy: 0.8176 - loss: 0.1824 \n",
      "Epoch 876/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8304 - Recall: 0.6155 - accuracy: 0.8097 - loss: 0.1903  \n",
      "Epoch 877/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7601 - Recall: 0.5398 - accuracy: 0.7944 - loss: 0.2056  \n",
      "Epoch 878/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8201 - Recall: 0.6467 - accuracy: 0.8383 - loss: 0.1618  \n",
      "Epoch 879/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8188 - Recall: 0.6301 - accuracy: 0.8263 - loss: 0.1737 \n",
      "Epoch 880/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7831 - Recall: 0.5639 - accuracy: 0.8003 - loss: 0.1997  \n",
      "Epoch 881/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8097 - Recall: 0.6437 - accuracy: 0.8097 - loss: 0.1903  \n",
      "Epoch 882/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8134 - Recall: 0.6397 - accuracy: 0.8327 - loss: 0.1673  \n",
      "Epoch 883/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7895 - Recall: 0.5914 - accuracy: 0.8033 - loss: 0.1967  \n",
      "Epoch 884/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7730 - Recall: 0.6073 - accuracy: 0.8039 - loss: 0.1961 \n",
      "Epoch 885/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8448 - Recall: 0.6204 - accuracy: 0.8217 - loss: 0.1783  \n",
      "Epoch 886/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7998 - Recall: 0.5961 - accuracy: 0.8039 - loss: 0.1961 \n",
      "Epoch 887/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7958 - Recall: 0.6129 - accuracy: 0.8170 - loss: 0.1830  \n",
      "Epoch 888/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7630 - Recall: 0.5749 - accuracy: 0.7930 - loss: 0.2070  \n",
      "Epoch 889/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7930 - Recall: 0.6132 - accuracy: 0.8084 - loss: 0.1916  \n",
      "Epoch 890/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7858 - Recall: 0.5856 - accuracy: 0.8032 - loss: 0.1968  \n",
      "Epoch 891/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7783 - Recall: 0.6036 - accuracy: 0.8034 - loss: 0.1966  \n",
      "Epoch 892/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7718 - Recall: 0.5983 - accuracy: 0.7949 - loss: 0.2051 \n",
      "Epoch 893/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7840 - Recall: 0.5498 - accuracy: 0.7886 - loss: 0.2114 \n",
      "Epoch 894/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8044 - Recall: 0.6556 - accuracy: 0.8318 - loss: 0.1682  \n",
      "Epoch 895/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7864 - Recall: 0.5890 - accuracy: 0.8060 - loss: 0.1940  \n",
      "Epoch 896/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7934 - Recall: 0.6081 - accuracy: 0.8055 - loss: 0.1945  \n",
      "Epoch 897/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7511 - Recall: 0.6368 - accuracy: 0.8078 - loss: 0.1922 \n",
      "Epoch 898/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7902 - Recall: 0.6261 - accuracy: 0.8189 - loss: 0.1811  \n",
      "Epoch 899/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7728 - Recall: 0.5984 - accuracy: 0.7987 - loss: 0.2013  \n",
      "Epoch 900/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8090 - Recall: 0.6381 - accuracy: 0.8265 - loss: 0.1735 \n",
      "Epoch 901/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8212 - Recall: 0.5967 - accuracy: 0.8146 - loss: 0.1854 \n",
      "Epoch 902/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8110 - Recall: 0.5760 - accuracy: 0.8187 - loss: 0.1813 \n",
      "Epoch 903/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7706 - Recall: 0.6237 - accuracy: 0.8080 - loss: 0.1920  \n",
      "Epoch 904/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7831 - Recall: 0.5720 - accuracy: 0.8074 - loss: 0.1926  \n",
      "Epoch 905/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7963 - Recall: 0.5907 - accuracy: 0.8085 - loss: 0.1915  \n",
      "Epoch 906/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8181 - Recall: 0.6133 - accuracy: 0.8185 - loss: 0.1815  \n",
      "Epoch 907/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7789 - Recall: 0.5823 - accuracy: 0.8187 - loss: 0.1813  \n",
      "Epoch 908/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7852 - Recall: 0.6076 - accuracy: 0.8061 - loss: 0.1939  \n",
      "Epoch 909/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8088 - Recall: 0.5749 - accuracy: 0.8008 - loss: 0.1992  \n",
      "Epoch 910/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8054 - Recall: 0.5964 - accuracy: 0.8319 - loss: 0.1681  \n",
      "Epoch 911/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7933 - Recall: 0.5809 - accuracy: 0.8062 - loss: 0.1938 \n",
      "Epoch 912/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8181 - Recall: 0.5992 - accuracy: 0.8171 - loss: 0.1829  \n",
      "Epoch 913/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8019 - Recall: 0.6042 - accuracy: 0.8078 - loss: 0.1922  \n",
      "Epoch 914/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7628 - Recall: 0.6171 - accuracy: 0.8075 - loss: 0.1925  \n",
      "Epoch 915/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7724 - Recall: 0.5698 - accuracy: 0.7969 - loss: 0.2031  \n",
      "Epoch 916/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8202 - Recall: 0.5905 - accuracy: 0.8034 - loss: 0.1966 \n",
      "Epoch 917/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7948 - Recall: 0.6089 - accuracy: 0.8151 - loss: 0.1849  \n",
      "Epoch 918/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8044 - Recall: 0.6292 - accuracy: 0.8175 - loss: 0.1825 \n",
      "Epoch 919/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8250 - Recall: 0.6188 - accuracy: 0.8117 - loss: 0.1883  \n",
      "Epoch 920/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8372 - Recall: 0.6014 - accuracy: 0.8158 - loss: 0.1842 \n",
      "Epoch 921/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8173 - Recall: 0.5858 - accuracy: 0.8139 - loss: 0.1861  \n",
      "Epoch 922/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8038 - Recall: 0.6132 - accuracy: 0.8032 - loss: 0.1968 \n",
      "Epoch 923/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7755 - Recall: 0.6216 - accuracy: 0.8050 - loss: 0.1950 \n",
      "Epoch 924/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7877 - Recall: 0.5709 - accuracy: 0.8063 - loss: 0.1937  \n",
      "Epoch 925/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7972 - Recall: 0.6110 - accuracy: 0.8169 - loss: 0.1831  \n",
      "Epoch 926/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8039 - Recall: 0.5958 - accuracy: 0.8003 - loss: 0.1997 \n",
      "Epoch 927/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8050 - Recall: 0.6083 - accuracy: 0.8170 - loss: 0.1830 \n",
      "Epoch 928/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7886 - Recall: 0.6240 - accuracy: 0.7993 - loss: 0.2007 \n",
      "Epoch 929/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7938 - Recall: 0.6104 - accuracy: 0.8030 - loss: 0.1970 \n",
      "Epoch 930/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.8376 - Recall: 0.6077 - accuracy: 0.8179 - loss: 0.1821 \n",
      "Epoch 931/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.7719 - Recall: 0.6236 - accuracy: 0.8048 - loss: 0.1952 \n",
      "Epoch 932/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8127 - Recall: 0.5785 - accuracy: 0.8073 - loss: 0.1927 \n",
      "Epoch 933/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7441 - Recall: 0.5823 - accuracy: 0.7930 - loss: 0.2070 \n",
      "Epoch 934/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8189 - Recall: 0.6452 - accuracy: 0.8285 - loss: 0.1715  \n",
      "Epoch 935/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8232 - Recall: 0.6186 - accuracy: 0.8308 - loss: 0.1692 \n",
      "Epoch 936/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8467 - Recall: 0.6211 - accuracy: 0.8163 - loss: 0.1837 \n",
      "Epoch 937/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7918 - Recall: 0.6090 - accuracy: 0.8130 - loss: 0.1870 \n",
      "Epoch 938/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.7572 - Recall: 0.5934 - accuracy: 0.8068 - loss: 0.1932 \n",
      "Epoch 939/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.8196 - Recall: 0.5914 - accuracy: 0.8035 - loss: 0.1965 \n",
      "Epoch 940/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7910 - Recall: 0.6266 - accuracy: 0.8053 - loss: 0.1947 \n",
      "Epoch 941/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8036 - Recall: 0.6300 - accuracy: 0.8254 - loss: 0.1746 \n",
      "Epoch 942/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7922 - Recall: 0.5868 - accuracy: 0.8036 - loss: 0.1964 \n",
      "Epoch 943/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8000 - Recall: 0.5372 - accuracy: 0.8011 - loss: 0.1989 \n",
      "Epoch 944/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7784 - Recall: 0.6073 - accuracy: 0.8042 - loss: 0.1958 \n",
      "Epoch 945/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7945 - Recall: 0.5911 - accuracy: 0.8016 - loss: 0.1984 \n",
      "Epoch 946/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7882 - Recall: 0.5711 - accuracy: 0.7998 - loss: 0.2002 \n",
      "Epoch 947/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.8105 - Recall: 0.5826 - accuracy: 0.8103 - loss: 0.1897 \n",
      "Epoch 948/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.7585 - Recall: 0.6262 - accuracy: 0.8221 - loss: 0.1779 \n",
      "Epoch 949/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7925 - Recall: 0.5998 - accuracy: 0.8197 - loss: 0.1803 \n",
      "Epoch 950/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8075 - Recall: 0.6385 - accuracy: 0.8191 - loss: 0.1809 \n",
      "Epoch 951/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7573 - Recall: 0.6131 - accuracy: 0.8010 - loss: 0.1990 \n",
      "Epoch 952/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.7984 - Recall: 0.6054 - accuracy: 0.8100 - loss: 0.1900 \n",
      "Epoch 953/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7977 - Recall: 0.5905 - accuracy: 0.7956 - loss: 0.2044 \n",
      "Epoch 954/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8181 - Recall: 0.5829 - accuracy: 0.7992 - loss: 0.2008 \n",
      "Epoch 955/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7960 - Recall: 0.5814 - accuracy: 0.7896 - loss: 0.2104 \n",
      "Epoch 956/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7955 - Recall: 0.5775 - accuracy: 0.8007 - loss: 0.1994  \n",
      "Epoch 957/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8015 - Recall: 0.5876 - accuracy: 0.8051 - loss: 0.1949  \n",
      "Epoch 958/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7924 - Recall: 0.6128 - accuracy: 0.8049 - loss: 0.1951  \n",
      "Epoch 959/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7932 - Recall: 0.5708 - accuracy: 0.7978 - loss: 0.2022 \n",
      "Epoch 960/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7942 - Recall: 0.6222 - accuracy: 0.8151 - loss: 0.1849  \n",
      "Epoch 961/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8107 - Recall: 0.6465 - accuracy: 0.8282 - loss: 0.1718 \n",
      "Epoch 962/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7717 - Recall: 0.6350 - accuracy: 0.8089 - loss: 0.1911  \n",
      "Epoch 963/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7843 - Recall: 0.5953 - accuracy: 0.7946 - loss: 0.2054 \n",
      "Epoch 964/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7853 - Recall: 0.6185 - accuracy: 0.8066 - loss: 0.1934  \n",
      "Epoch 965/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8184 - Recall: 0.6035 - accuracy: 0.8226 - loss: 0.1774 \n",
      "Epoch 966/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8072 - Recall: 0.6090 - accuracy: 0.8096 - loss: 0.1904  \n",
      "Epoch 967/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7896 - Recall: 0.6248 - accuracy: 0.8130 - loss: 0.1870 \n",
      "Epoch 968/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7919 - Recall: 0.6016 - accuracy: 0.8027 - loss: 0.1973  \n",
      "Epoch 969/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8417 - Recall: 0.5974 - accuracy: 0.8138 - loss: 0.1862  \n",
      "Epoch 970/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8268 - Recall: 0.6281 - accuracy: 0.8250 - loss: 0.1750  \n",
      "Epoch 971/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8065 - Recall: 0.5848 - accuracy: 0.8151 - loss: 0.1849 \n",
      "Epoch 972/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8238 - Recall: 0.6468 - accuracy: 0.8290 - loss: 0.1710  \n",
      "Epoch 973/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7847 - Recall: 0.6221 - accuracy: 0.8079 - loss: 0.1921  \n",
      "Epoch 974/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7878 - Recall: 0.6209 - accuracy: 0.8124 - loss: 0.1876 \n",
      "Epoch 975/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7878 - Recall: 0.5656 - accuracy: 0.7880 - loss: 0.2120  \n",
      "Epoch 976/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7814 - Recall: 0.6210 - accuracy: 0.8240 - loss: 0.1760  \n",
      "Epoch 977/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7849 - Recall: 0.5794 - accuracy: 0.8063 - loss: 0.1937  \n",
      "Epoch 978/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8066 - Recall: 0.6189 - accuracy: 0.8159 - loss: 0.1841 \n",
      "Epoch 979/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7695 - Recall: 0.6070 - accuracy: 0.8073 - loss: 0.1927  \n",
      "Epoch 980/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7998 - Recall: 0.6275 - accuracy: 0.8261 - loss: 0.1739 \n",
      "Epoch 981/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8355 - Recall: 0.6362 - accuracy: 0.8137 - loss: 0.1863  \n",
      "Epoch 982/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8220 - Recall: 0.6202 - accuracy: 0.8143 - loss: 0.1857 \n",
      "Epoch 983/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8203 - Recall: 0.6098 - accuracy: 0.8151 - loss: 0.1849  \n",
      "Epoch 984/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8080 - Recall: 0.5987 - accuracy: 0.8097 - loss: 0.1903  \n",
      "Epoch 985/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7922 - Recall: 0.5923 - accuracy: 0.8104 - loss: 0.1896  \n",
      "Epoch 986/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7548 - Recall: 0.5964 - accuracy: 0.8090 - loss: 0.1910 \n",
      "Epoch 987/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8105 - Recall: 0.5924 - accuracy: 0.8042 - loss: 0.1958  \n",
      "Epoch 988/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7782 - Recall: 0.5611 - accuracy: 0.8115 - loss: 0.1885  \n",
      "Epoch 989/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7845 - Recall: 0.6289 - accuracy: 0.8159 - loss: 0.1841  \n",
      "Epoch 990/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7977 - Recall: 0.5779 - accuracy: 0.8070 - loss: 0.1930  \n",
      "Epoch 991/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7812 - Recall: 0.6260 - accuracy: 0.8016 - loss: 0.1984  \n",
      "Epoch 992/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8156 - Recall: 0.6325 - accuracy: 0.8200 - loss: 0.1800  \n",
      "Epoch 993/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7878 - Recall: 0.6068 - accuracy: 0.8239 - loss: 0.1761  \n",
      "Epoch 994/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.8292 - Recall: 0.6585 - accuracy: 0.8472 - loss: 0.1528 \n",
      "Epoch 995/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7787 - Recall: 0.5596 - accuracy: 0.7999 - loss: 0.2001  \n",
      "Epoch 996/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.8154 - Recall: 0.6238 - accuracy: 0.8236 - loss: 0.1764  \n",
      "Epoch 997/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7805 - Recall: 0.6251 - accuracy: 0.8147 - loss: 0.1853 \n",
      "Epoch 998/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8158 - Recall: 0.6155 - accuracy: 0.8146 - loss: 0.1854  \n",
      "Epoch 999/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7948 - Recall: 0.6077 - accuracy: 0.8212 - loss: 0.1788  \n",
      "Epoch 1000/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7901 - Recall: 0.6031 - accuracy: 0.8177 - loss: 0.1823  \n",
      "{'Precision': [0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285, 0.7950310707092285], 'Recall': [0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648, 0.6066350936889648], 'accuracy': [0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652, 0.8110749125480652], 'loss': [0.18892644345760345, 0.18892642855644226, 0.18892645835876465, 0.18892642855644226, 0.18892644345760345, 0.18892642855644226, 0.18892647325992584, 0.18892642855644226, 0.18892650306224823, 0.18892639875411987, 0.1889263540506363, 0.18892642855644226, 0.18892644345760345, 0.18892642855644226, 0.18892642855644226, 0.18892644345760345, 0.18892642855644226, 0.18892639875411987, 0.18892641365528107, 0.18892642855644226, 0.18892636895179749, 0.18892642855644226, 0.18892641365528107, 0.18892636895179749, 0.18892645835876465, 0.18892636895179749, 0.18892638385295868, 0.18892642855644226, 0.18892653286457062, 0.18892645835876465, 0.18892650306224823, 0.18892638385295868, 0.18892645835876465, 0.18892639875411987, 0.18892644345760345, 0.1889263540506363, 0.18892644345760345, 0.18892642855644226, 0.18892644345760345, 0.18892639875411987, 0.18892639875411987, 0.18892641365528107, 0.18892642855644226, 0.18892642855644226, 0.1889263540506363, 0.18892644345760345, 0.18892639875411987, 0.18892639875411987, 0.18892638385295868, 0.18892636895179749, 0.18892645835876465, 0.18892642855644226, 0.18892639875411987, 0.18892644345760345, 0.18892641365528107, 0.18892641365528107, 0.18892647325992584, 0.18892641365528107, 0.18892644345760345, 0.18892629444599152, 0.1889263093471527, 0.18892638385295868, 0.18892639875411987, 0.1889263540506363, 0.18892639875411987, 0.18892639875411987, 0.18892647325992584, 0.18892647325992584, 0.18892636895179749, 0.18892642855644226, 0.18892638385295868, 0.18892638385295868, 0.18892642855644226, 0.18892639875411987, 0.18892638385295868, 0.18892638385295868, 0.18892636895179749, 0.1889263391494751, 0.18892636895179749, 0.1889263540506363, 0.18892642855644226, 0.18892638385295868, 0.18892636895179749, 0.18892629444599152, 0.1889263242483139, 0.1889263540506363, 0.1889263540506363, 0.1889263540506363, 0.18892636895179749, 0.18892641365528107, 0.1889263242483139, 0.1889263540506363, 0.1889263093471527, 0.18892639875411987, 0.18892638385295868, 0.1889263540506363, 0.18892642855644226, 0.18892639875411987, 0.18892636895179749, 0.1889263242483139, 0.1889263242483139, 0.18892636895179749, 0.1889263391494751, 0.18892629444599152, 0.1889263242483139, 0.18892636895179749, 0.18892636895179749, 0.1889263540506363, 0.18892638385295868, 0.1889263242483139, 0.18892627954483032, 0.1889263540506363, 0.18892638385295868, 0.1889263540506363, 0.1889263540506363, 0.1889263540506363, 0.18892624974250793, 0.18892627954483032, 0.1889263540506363, 0.18892641365528107, 0.18892642855644226, 0.1889263242483139, 0.1889263540506363, 0.1889263540506363, 0.1889263540506363, 0.1889263540506363, 0.1889263242483139, 0.1889263540506363, 0.18892627954483032, 0.1889263242483139, 0.1889263093471527, 0.1889263391494751, 0.1889263540506363, 0.1889263093471527, 0.18892627954483032, 0.1889263391494751, 0.1889263540506363, 0.18892629444599152, 0.18892642855644226, 0.1889263242483139, 0.1889263540506363, 0.18892626464366913, 0.1889263540506363, 0.1889263540506363, 0.18892624974250793, 0.18892621994018555, 0.1889263391494751, 0.1889263540506363, 0.1889263242483139, 0.1889263242483139, 0.18892636895179749, 0.1889263242483139, 0.1889263540506363, 0.18892641365528107, 0.1889263093471527, 0.18892627954483032, 0.1889263540506363, 0.18892627954483032, 0.18892629444599152, 0.1889263093471527, 0.1889263242483139, 0.1889263093471527, 0.1889263391494751, 0.18892624974250793, 0.1889263391494751, 0.1889263391494751, 0.1889263242483139, 0.1889263540506363, 0.1889263242483139, 0.1889263540506363, 0.18892624974250793, 0.18892627954483032, 0.18892626464366913, 0.18892629444599152, 0.18892623484134674, 0.18892627954483032, 0.18892627954483032, 0.18892624974250793, 0.18892636895179749, 0.1889263242483139, 0.1889263391494751, 0.1889263242483139, 0.1889263242483139, 0.1889263391494751, 0.18892627954483032, 0.18892627954483032, 0.18892627954483032, 0.18892629444599152, 0.1889263391494751, 0.18892626464366913, 0.18892627954483032, 0.18892624974250793, 0.18892629444599152, 0.1889263391494751, 0.18892629444599152, 0.1889263540506363, 0.18892627954483032, 0.1889263391494751, 0.18892627954483032, 0.1889263093471527, 0.18892626464366913, 0.18892629444599152, 0.1889263093471527, 0.18892627954483032, 0.18892636895179749, 0.18892623484134674, 0.1889263242483139, 0.1889263540506363, 0.18892626464366913, 0.1889263242483139, 0.18892627954483032, 0.1889263391494751, 0.18892624974250793, 0.18892620503902435, 0.18892629444599152, 0.18892627954483032, 0.18892626464366913, 0.18892627954483032, 0.18892624974250793, 0.1889263093471527, 0.18892624974250793, 0.18892629444599152, 0.18892629444599152, 0.18892629444599152, 0.18892620503902435, 0.18892623484134674, 0.18892626464366913, 0.18892626464366913, 0.18892620503902435, 0.18892626464366913, 0.18892629444599152, 0.18892624974250793, 0.18892624974250793, 0.18892624974250793, 0.18892626464366913, 0.18892624974250793, 0.18892627954483032, 0.18892626464366913, 0.18892629444599152, 0.18892621994018555, 0.18892626464366913, 0.18892627954483032, 0.18892627954483032, 0.1889263242483139, 0.18892621994018555, 0.18892624974250793, 0.18892626464366913, 0.18892626464366913, 0.18892626464366913, 0.18892624974250793, 0.18892621994018555, 0.18892626464366913, 0.18892627954483032, 0.18892620503902435, 0.18892623484134674, 0.18892617523670197, 0.18892626464366913, 0.18892620503902435, 0.18892627954483032, 0.18892627954483032, 0.18892621994018555, 0.18892624974250793, 0.18892627954483032, 0.18892624974250793, 0.18892629444599152, 0.18892623484134674, 0.18892627954483032, 0.18892621994018555, 0.18892620503902435, 0.18892627954483032, 0.18892620503902435, 0.18892620503902435, 0.18892623484134674, 0.18892626464366913, 0.18892620503902435, 0.18892626464366913, 0.18892617523670197, 0.18892620503902435, 0.18892623484134674, 0.18892627954483032, 0.18892626464366913, 0.18892629444599152, 0.18892623484134674, 0.1889263093471527, 0.18892621994018555, 0.18892620503902435, 0.18892620503902435, 0.18892623484134674, 0.18892621994018555, 0.18892624974250793, 0.18892624974250793, 0.18892626464366913, 0.18892621994018555, 0.18892620503902435, 0.18892623484134674, 0.18892620503902435, 0.18892621994018555, 0.18892621994018555, 0.18892621994018555, 0.18892621994018555, 0.18892626464366913, 0.18892621994018555, 0.18892614543437958, 0.18892620503902435, 0.18892624974250793, 0.18892624974250793, 0.18892619013786316, 0.18892620503902435, 0.18892626464366913, 0.18892624974250793, 0.18892621994018555, 0.18892626464366913, 0.18892623484134674, 0.18892621994018555, 0.18892623484134674, 0.18892619013786316, 0.18892623484134674, 0.18892626464366913, 0.18892620503902435, 0.18892623484134674, 0.18892620503902435, 0.18892614543437958, 0.18892623484134674, 0.18892620503902435, 0.18892620503902435, 0.18892620503902435, 0.18892620503902435, 0.18892619013786316, 0.18892620503902435, 0.18892620503902435, 0.18892620503902435, 0.18892614543437958, 0.18892617523670197, 0.18892620503902435, 0.18892620503902435, 0.18892620503902435, 0.18892619013786316, 0.18892620503902435, 0.18892620503902435, 0.18892620503902435, 0.18892621994018555, 0.18892620503902435, 0.18892616033554077, 0.18892619013786316, 0.18892619013786316, 0.18892624974250793, 0.18892621994018555, 0.18892620503902435, 0.18892620503902435, 0.18892616033554077, 0.18892624974250793, 0.18892621994018555, 0.18892620503902435, 0.18892620503902435, 0.18892620503902435, 0.18892620503902435, 0.18892624974250793, 0.18892614543437958, 0.18892620503902435, 0.18892620503902435, 0.18892614543437958, 0.18892613053321838, 0.18892614543437958, 0.18892620503902435, 0.18892620503902435, 0.18892624974250793, 0.18892619013786316, 0.18892624974250793, 0.18892617523670197, 0.18892617523670197, 0.18892617523670197, 0.18892619013786316, 0.18892617523670197, 0.18892619013786316, 0.18892626464366913, 0.18892617523670197, 0.18892614543437958, 0.18892620503902435, 0.18892620503902435, 0.18892620503902435, 0.18892620503902435, 0.18892620503902435, 0.18892619013786316, 0.18892617523670197, 0.18892614543437958, 0.18892617523670197, 0.18892620503902435, 0.18892619013786316, 0.18892616033554077, 0.18892620503902435, 0.18892614543437958, 0.18892617523670197, 0.18892616033554077, 0.18892617523670197, 0.18892614543437958, 0.18892617523670197, 0.18892614543437958, 0.18892619013786316, 0.18892613053321838, 0.18892619013786316, 0.18892620503902435, 0.18892619013786316, 0.18892619013786316, 0.18892614543437958, 0.18892617523670197, 0.18892613053321838, 0.18892616033554077, 0.18892616033554077, 0.18892616033554077, 0.18892617523670197, 0.18892614543437958, 0.18892613053321838, 0.18892617523670197, 0.18892614543437958, 0.18892617523670197, 0.18892616033554077, 0.18892613053321838, 0.18892614543437958, 0.18892616033554077, 0.18892614543437958, 0.18892613053321838, 0.18892616033554077, 0.18892616033554077, 0.18892614543437958, 0.18892617523670197, 0.18892614543437958, 0.18892614543437958, 0.18892617523670197, 0.18892614543437958, 0.18892617523670197, 0.18892617523670197, 0.18892616033554077, 0.18892616033554077, 0.18892614543437958, 0.18892613053321838, 0.18892619013786316, 0.18892617523670197, 0.1889260709285736, 0.18892614543437958, 0.18892617523670197, 0.18892617523670197, 0.18892616033554077, 0.1889261156320572, 0.18892613053321838, 0.18892614543437958, 0.18892614543437958, 0.18892614543437958, 0.18892614543437958, 0.18892619013786316, 0.18892613053321838, 0.18892613053321838, 0.18892614543437958, 0.18892616033554077, 0.1889260858297348, 0.18892613053321838, 0.18892614543437958, 0.18892614543437958, 0.18892614543437958, 0.18892614543437958, 0.18892613053321838, 0.18892620503902435, 0.18892614543437958, 0.1889260858297348, 0.1889260858297348, 0.188926100730896, 0.18892613053321838, 0.18892616033554077, 0.18892613053321838, 0.18892613053321838, 0.18892613053321838, 0.18892613053321838, 0.1889261156320572, 0.18892616033554077, 0.18892614543437958, 0.18892614543437958, 0.18892613053321838, 0.18892613053321838, 0.18892613053321838, 0.18892616033554077, 0.18892614543437958, 0.18892613053321838, 0.18892613053321838, 0.1889261156320572, 0.18892613053321838, 0.18892613053321838, 0.18892613053321838, 0.18892614543437958, 0.18892613053321838, 0.18892613053321838, 0.1889261156320572, 0.1889260709285736, 0.1889261156320572, 0.18892613053321838, 0.18892613053321838, 0.188926100730896, 0.18892613053321838, 0.1889261156320572, 0.18892613053321838, 0.18892613053321838, 0.18892613053321838, 0.18892613053321838, 0.18892613053321838, 0.18892613053321838, 0.188926100730896, 0.188926100730896, 0.188926100730896, 0.18892613053321838, 0.188926100730896, 0.18892613053321838, 0.18892614543437958, 0.1889261156320572, 0.1889261156320572, 0.18892613053321838, 0.18892613053321838, 0.18892613053321838, 0.1889261156320572, 0.1889260858297348, 0.188926100730896, 0.1889260709285736, 0.18892616033554077, 0.188926100730896, 0.18892614543437958, 0.18892613053321838, 0.1889261156320572, 0.188926100730896, 0.18892613053321838, 0.18892613053321838, 0.1889261156320572, 0.18892616033554077, 0.1889260858297348, 0.188926100730896, 0.18892605602741241, 0.1889261156320572, 0.1889260709285736, 0.18892616033554077, 0.1889261156320572, 0.18892613053321838, 0.1889260858297348, 0.1889261156320572, 0.1889260858297348, 0.18892613053321838, 0.188926100730896, 0.18892605602741241, 0.18892613053321838, 0.188926100730896, 0.188926100730896, 0.18892605602741241, 0.18892605602741241, 0.1889261156320572, 0.18892614543437958, 0.188926100730896, 0.188926100730896, 0.18892605602741241, 0.1889260709285736, 0.1889260709285736, 0.1889260709285736, 0.1889261156320572, 0.1889260858297348, 0.1889260858297348, 0.1889260858297348, 0.18892605602741241, 0.188926100730896, 0.1889260858297348, 0.1889260709285736, 0.1889260858297348, 0.18892605602741241, 0.188926100730896, 0.1889260709285736, 0.1889261156320572, 0.1889260709285736, 0.18892605602741241, 0.18892605602741241, 0.1889260858297348, 0.1889260858297348, 0.188926100730896, 0.1889260858297348, 0.18892614543437958, 0.1889260709285736, 0.188926100730896, 0.18892605602741241, 0.18892613053321838, 0.1889260709285736, 0.188926100730896, 0.188926100730896, 0.18892605602741241, 0.1889260709285736, 0.18892605602741241, 0.18892604112625122, 0.18892605602741241, 0.1889260709285736, 0.18892605602741241, 0.18892605602741241, 0.188926100730896, 0.1889260858297348, 0.1889260858297348, 0.18892605602741241, 0.18892605602741241, 0.18892605602741241, 0.188926100730896, 0.1889260858297348, 0.18892602622509003, 0.18892605602741241, 0.1889260709285736, 0.1889260709285736, 0.18892605602741241, 0.18892604112625122, 0.18892605602741241, 0.1889260858297348, 0.18892604112625122, 0.18892601132392883, 0.1889260709285736, 0.18892605602741241, 0.1889260709285736, 0.188926100730896, 0.188926100730896, 0.18892605602741241, 0.18892605602741241, 0.18892604112625122, 0.18892605602741241, 0.18892605602741241, 0.188926100730896, 0.1889260709285736, 0.1889260709285736, 0.18892605602741241, 0.18892604112625122, 0.18892605602741241, 0.1889260709285736, 0.18892605602741241, 0.1889260709285736, 0.18892604112625122, 0.18892605602741241, 0.18892599642276764, 0.18892605602741241, 0.18892605602741241, 0.18892604112625122, 0.18892605602741241, 0.18892605602741241, 0.1889260709285736, 0.18892604112625122, 0.18892604112625122, 0.18892605602741241, 0.18892605602741241, 0.18892602622509003, 0.18892605602741241, 0.18892605602741241, 0.18892604112625122, 0.18892604112625122, 0.18892605602741241, 0.18892605602741241, 0.1889260709285736, 0.18892605602741241, 0.1889260709285736, 0.18892605602741241, 0.18892602622509003, 0.1889260709285736, 0.18892605602741241, 0.1889260858297348, 0.18892605602741241, 0.18892604112625122, 0.18892605602741241, 0.18892602622509003, 0.18892604112625122, 0.18892605602741241, 0.18892602622509003, 0.1889260709285736, 0.18892602622509003, 0.18892605602741241, 0.18892602622509003, 0.18892604112625122, 0.18892602622509003, 0.18892604112625122, 0.18892605602741241, 0.18892604112625122, 0.18892605602741241, 0.18892601132392883, 0.18892605602741241, 0.18892605602741241, 0.18892602622509003, 0.18892604112625122, 0.18892604112625122, 0.18892602622509003, 0.18892605602741241, 0.18892602622509003, 0.18892604112625122, 0.18892602622509003, 0.18892605602741241, 0.18892599642276764, 0.18892602622509003, 0.18892599642276764, 0.18892602622509003, 0.18892604112625122, 0.18892604112625122, 0.18892601132392883, 0.18892602622509003, 0.18892605602741241, 0.18892602622509003, 0.1889260709285736, 0.18892601132392883, 0.18892601132392883, 0.1889260709285736, 0.18892602622509003, 0.18892604112625122, 0.18892602622509003, 0.18892604112625122, 0.18892602622509003, 0.18892602622509003, 0.18892602622509003, 0.18892604112625122, 0.18892598152160645, 0.18892601132392883, 0.18892601132392883, 0.18892604112625122, 0.18892604112625122, 0.18892602622509003, 0.18892605602741241, 0.18892602622509003, 0.18892598152160645, 0.18892602622509003, 0.18892602622509003, 0.18892602622509003, 0.18892601132392883, 0.18892602622509003, 0.18892605602741241, 0.18892598152160645, 0.18892602622509003, 0.18892605602741241, 0.18892599642276764, 0.18892602622509003, 0.18892599642276764, 0.18892602622509003, 0.18892604112625122, 0.18892605602741241, 0.18892605602741241, 0.18892601132392883, 0.18892602622509003, 0.18892602622509003, 0.18892599642276764, 0.18892599642276764, 0.18892601132392883, 0.18892604112625122, 0.18892599642276764, 0.18892602622509003, 0.18892601132392883, 0.18892599642276764, 0.18892602622509003, 0.18892601132392883, 0.18892601132392883, 0.18892602622509003, 0.18892602622509003, 0.18892599642276764, 0.18892599642276764, 0.18892599642276764, 0.18892602622509003, 0.18892602622509003, 0.18892601132392883, 0.18892601132392883, 0.18892601132392883, 0.18892599642276764, 0.18892598152160645, 0.18892602622509003, 0.18892602622509003, 0.18892599642276764, 0.18892604112625122, 0.18892599642276764, 0.18892602622509003, 0.18892602622509003, 0.18892601132392883, 0.18892599642276764, 0.18892598152160645, 0.18892599642276764, 0.18892601132392883, 0.18892601132392883, 0.18892599642276764, 0.18892602622509003, 0.18892598152160645, 0.18892601132392883, 0.18892598152160645, 0.18892598152160645, 0.18892599642276764, 0.18892604112625122, 0.18892602622509003, 0.18892601132392883, 0.18892598152160645, 0.18892595171928406, 0.18892598152160645, 0.18892599642276764, 0.18892598152160645, 0.18892602622509003, 0.18892604112625122, 0.18892598152160645, 0.18892596662044525, 0.18892599642276764, 0.18892599642276764, 0.18892602622509003, 0.18892599642276764, 0.18892595171928406, 0.18892601132392883, 0.18892596662044525, 0.18892598152160645, 0.18892598152160645, 0.18892599642276764, 0.18892598152160645, 0.18892601132392883, 0.18892599642276764, 0.18892599642276764, 0.18892598152160645, 0.18892595171928406, 0.18892599642276764, 0.18892599642276764, 0.18892601132392883, 0.18892598152160645, 0.18892602622509003, 0.18892598152160645, 0.18892595171928406, 0.18892598152160645, 0.18892602622509003, 0.18892598152160645, 0.18892602622509003, 0.18892596662044525, 0.18892599642276764, 0.18892598152160645, 0.18892598152160645, 0.18892599642276764, 0.18892596662044525, 0.18892598152160645, 0.18892595171928406, 0.18892599642276764, 0.18892598152160645, 0.18892595171928406, 0.18892601132392883, 0.18892598152160645, 0.18892596662044525, 0.18892599642276764, 0.18892596662044525, 0.18892599642276764, 0.18892595171928406, 0.18892598152160645, 0.18892599642276764, 0.18892598152160645, 0.18892598152160645, 0.18892599642276764, 0.18892599642276764, 0.18892598152160645, 0.18892598152160645, 0.18892599642276764, 0.18892598152160645, 0.18892598152160645, 0.18892598152160645, 0.18892596662044525, 0.18892595171928406, 0.18892595171928406, 0.18892595171928406, 0.18892599642276764, 0.18892593681812286, 0.18892599642276764, 0.18892598152160645, 0.18892598152160645, 0.18892598152160645, 0.18892596662044525, 0.18892598152160645, 0.18892598152160645, 0.18892598152160645, 0.18892598152160645, 0.18892596662044525, 0.18892595171928406, 0.18892598152160645, 0.18892598152160645, 0.18892592191696167, 0.18892595171928406, 0.18892598152160645, 0.18892595171928406, 0.18892596662044525, 0.18892598152160645, 0.18892596662044525, 0.18892596662044525, 0.18892598152160645, 0.18892596662044525, 0.18892593681812286, 0.18892595171928406, 0.18892598152160645, 0.18892598152160645, 0.18892598152160645, 0.18892598152160645, 0.18892598152160645, 0.18892593681812286, 0.18892596662044525, 0.18892595171928406, 0.18892596662044525, 0.18892593681812286, 0.18892598152160645, 0.18892596662044525, 0.18892598152160645, 0.18892598152160645, 0.18892595171928406, 0.18892592191696167, 0.18892595171928406, 0.18892596662044525, 0.18892592191696167, 0.18892593681812286, 0.18892598152160645, 0.18892595171928406, 0.18892595171928406, 0.18892595171928406, 0.18892596662044525, 0.18892598152160645, 0.18892598152160645, 0.18892593681812286, 0.18892598152160645, 0.18892595171928406, 0.18892598152160645, 0.18892595171928406, 0.18892596662044525, 0.18892599642276764, 0.18892598152160645, 0.18892596662044525, 0.18892598152160645, 0.18892595171928406, 0.18892596662044525, 0.18892595171928406, 0.18892595171928406, 0.18892592191696167, 0.18892598152160645, 0.18892596662044525, 0.18892596662044525, 0.18892593681812286, 0.18892595171928406, 0.18892595171928406, 0.18892595171928406, 0.18892593681812286, 0.18892598152160645, 0.18892595171928406, 0.18892596662044525, 0.18892595171928406, 0.18892595171928406, 0.18892595171928406, 0.18892590701580048, 0.18892596662044525, 0.18892595171928406, 0.18892593681812286, 0.18892596662044525, 0.18892595171928406, 0.18892596662044525, 0.18892596662044525, 0.18892598152160645, 0.18892593681812286, 0.18892593681812286, 0.18892593681812286, 0.18892593681812286, 0.18892593681812286, 0.18892596662044525, 0.18892592191696167, 0.18892592191696167, 0.18892595171928406, 0.18892598152160645, 0.18892598152160645, 0.18892593681812286, 0.18892596662044525, 0.18892598152160645, 0.18892593681812286, 0.18892593681812286, 0.18892595171928406, 0.18892592191696167, 0.18892595171928406, 0.18892596662044525, 0.18892592191696167, 0.18892595171928406, 0.18892595171928406, 0.18892593681812286, 0.18892596662044525, 0.18892595171928406, 0.18892595171928406, 0.18892593681812286, 0.18892590701580048, 0.18892593681812286, 0.18892592191696167, 0.18892592191696167, 0.18892595171928406, 0.18892593681812286, 0.18892592191696167, 0.18892592191696167, 0.18892592191696167, 0.18892592191696167, 0.18892590701580048, 0.18892592191696167, 0.18892592191696167, 0.18892595171928406, 0.18892592191696167, 0.18892590701580048, 0.18892595171928406, 0.18892593681812286, 0.18892593681812286, 0.18892593681812286, 0.18892592191696167, 0.18892590701580048, 0.18892593681812286, 0.18892593681812286, 0.18892592191696167, 0.18892589211463928, 0.18892593681812286, 0.18892590701580048]}\n"
     ]
    }
   ],
   "source": [
    "### INICIE O CÓDIGO AQUI ### (1 linha de código)\n",
    "history = model.fit(train_set_X, train_set_Y, batch_size=64, epochs=1000)\n",
    "### TERMINE O CÓDIGO AQUI ###\n",
    "print(history.history)  # print per-epoch timeseries of metrics values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3ikhmuXvaeD"
   },
   "source": [
    "**SAÍDA ESPERADA**: <br>\n",
    "Na época 1000, tem-se o seguinte resultado (aproximado): <br>\n",
    "loss: 0.1938 - accuracy: 0.8062 - precision: 0.7644 - recall: 0.6303\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0-1QWSuvaeE"
   },
   "source": [
    "## Avaliação do Modelo\n",
    "\n",
    "Avalie o desempenho da rede no conjunto de teste.\n",
    "\n",
    "Dica: use a função *evaluate*: https://keras.io/api/models/model_training_apis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qvtc7HVcvaeE",
    "outputId": "cfc64932-3f4f-4d4a-a742-ade518a63ee6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.8119 - Recall: 0.6078 - accuracy: 0.8083 - loss: 0.1905  \n",
      "Loss: 0.19 \n",
      "Accuracy: 0.81 \n",
      "Precision: 0.83 \n",
      "Recall: 0.60\n"
     ]
    }
   ],
   "source": [
    "### INICIE O CÓDIGO AQUI ### (1 linha de código)\n",
    "loss, acc, prec, rec = model.evaluate(test_set_X, test_set_Y)\n",
    "### TERMINE O CÓDIGO AQUI ###\n",
    "print(\"Loss: %.2f\" % loss, \"\\nAccuracy: %.2f\" % acc, \"\\nPrecision: %.2f\" % prec, \"\\nRecall: %.2f\" % rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIe7SnurvaeE"
   },
   "source": [
    "**SAÍDA ESPERADA**: <br>\n",
    "Valores aproximados:\n",
    "\n",
    "Loss: 0.21  <br>\n",
    "Accuracy: 0.79  <br>\n",
    "Precision: 0.76  <br>\n",
    "Recall: 0.61\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbsaVPvivaeE"
   },
   "source": [
    "## Predição\n",
    "\n",
    "Apresente a predição do conjunto de teste.\n",
    "\n",
    "Dica: use a função *predict*: https://keras.io/api/models/model_training_apis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eL8iVRaZvaeE",
    "outputId": "efb13dd3-4f83-428d-bfc8-0a4a95c66ffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Predictions:  [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]\n",
      "\n",
      "Correct:      [0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "### INICIE O CÓDIGO AQUI ### (1 linha de código)\n",
    "predictions = model.predict(test_set_X)\n",
    "### TERMINE O CÓDIGO AQUI ###\n",
    "print(\"Predictions: \", [round(x[0]) for x in predictions])\n",
    "print(\"\\nCorrect:     \", [round(x) for x in test_set_Y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ydA6M-gVvaeF"
   },
   "source": [
    "**SAÍDA ESPERADA**: <br>\n",
    "Valores aproximados: <br>\n",
    "Predictions:  [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0]\n",
    "\n",
    "Correct:      [0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVL1T5uvvaeF"
   },
   "source": [
    "## Desafio\n",
    "\n",
    "Modifique a configuração da sua rede e/ou os parâmetros dos métodos com o objetivo de melhorar os resultados das métricas no conjunto de teste. Experimente várias opções. <br>\n",
    "Adicione abaixo a nova sequência de código que alcançou o melhor resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wt1YCdMkvaeF"
   },
   "outputs": [],
   "source": [
    "### INICIE O CÓDIGO AQUI ### (várias linhas de código / várias células)\n",
    "\n",
    "### TERMINE O CÓDIGO AQUI ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "HZ-tQ2uhChOb"
   },
   "outputs": [],
   "source": [
    "import numpy as np # package for scientific computing\n",
    "import tensorflow as tf  #  package for numerical computation using data flow graphs\n",
    "from tensorflow import keras  # package for deep learning\n",
    "import pandas as pd # package for working with structured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "jS0_gDnsCpQz",
    "outputId": "0a6aa15a-8429-4ea8-82d5-61239d354d57"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"data\",\n  \"rows\": 768,\n  \"fields\": [\n    {\n      \"column\": \"Pregnancies\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 17,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          6,\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Glucose\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31,\n        \"min\": 0,\n        \"max\": 199,\n        \"num_unique_values\": 136,\n        \"samples\": [\n          151,\n          101,\n          112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BloodPressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 0,\n        \"max\": 122,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          86,\n          46,\n          85\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SkinThickness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          7,\n          12,\n          48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Insulin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115,\n        \"min\": 0,\n        \"max\": 846,\n        \"num_unique_values\": 186,\n        \"samples\": [\n          52,\n          41,\n          183\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.8841603203754405,\n        \"min\": 0.0,\n        \"max\": 67.1,\n        \"num_unique_values\": 248,\n        \"samples\": [\n          19.9,\n          31.0,\n          38.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DiabetesPedigreeFunction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33132859501277484,\n        \"min\": 0.078,\n        \"max\": 2.42,\n        \"num_unique_values\": 517,\n        \"samples\": [\n          1.731,\n          0.426,\n          0.138\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 21,\n        \"max\": 81,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          60,\n          47,\n          72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Outcome\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "data"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-11fca1a9-9a9a-4e50-8e1b-655728f6dbdd\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11fca1a9-9a9a-4e50-8e1b-655728f6dbdd')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-11fca1a9-9a9a-4e50-8e1b-655728f6dbdd button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-11fca1a9-9a9a-4e50-8e1b-655728f6dbdd');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-66c698ba-c8e6-451d-bd41-015b37057b97\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-66c698ba-c8e6-451d-bd41-015b37057b97')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-66c698ba-c8e6-451d-bd41-015b37057b97 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataset\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "data.head() # display dataset first lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "lO0pBpsFCulk"
   },
   "outputs": [],
   "source": [
    "# Separate the class from other attributes\n",
    "X = data.drop(\"Outcome\", axis=1)\n",
    "Y = data[\"Outcome\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "D6YF6AGWDIcE"
   },
   "outputs": [],
   "source": [
    "# Preparing the dataset for training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set_X, test_set_X, train_set_Y, test_set_Y = train_test_split(X, Y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fokyJMf6DZys",
    "outputId": "fb8fc980-83ee-4bc3-bb4f-4fd64bc0606c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_X:\n",
      " [[ 0.35483802 -0.370418    0.16624635  1.40032403 -0.01279543  0.49863797\n",
      "  -0.61786951  0.01064085]\n",
      " [-0.54794048 -0.55620696  0.9024924   0.96548604  0.40069886  1.70739891\n",
      "  -1.0345765  -0.86049025]]\n",
      "\n",
      "test_set_X:\n",
      " [[-0.83168001 -1.14367855 -0.39723824 -0.57849223 -0.36848171 -0.47210798\n",
      "   0.22800925 -0.84284936]\n",
      " [ 0.8647269   1.8633592   0.67258938  0.00976179  0.72124393  0.58740671\n",
      "   0.24525553  1.28629259]]\n"
     ]
    }
   ],
   "source": [
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train_set_X = scaler.fit_transform(train_set_X) #ajusta e tranforma os dados de treino\n",
    "test_set_X  = scaler.fit_transform(test_set_X)\n",
    "# Checking\n",
    "print(\"train_set_X:\\n\", train_set_X[:2,:])\n",
    "print(\"\\ntest_set_X:\\n\", test_set_X[:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tjRxWWYGDpgs",
    "outputId": "4573ffa1-aaac-496f-f370-72c346fbd422"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of attributes: n = 8\n",
      "Number of training examples: m = 614\n",
      "Train set X shape: (614, 8)\n",
      "Train set Y shape: (614,)\n",
      "Test set X shape: (154, 8)\n",
      "Test set Y shape: (154,)\n"
     ]
    }
   ],
   "source": [
    "n = train_set_X.shape[1] # number of attributes\n",
    "m = train_set_X.shape[0] # number of training examples\n",
    "\n",
    "print (\"Number of attributes: n = \" + str(n))\n",
    "print (\"Number of training examples: m = \" + str(m))\n",
    "print (\"Train set X shape: \" + str(train_set_X.shape))\n",
    "print (\"Train set Y shape: \" + str(train_set_Y.shape))\n",
    "print (\"Test set X shape: \" + str(test_set_X.shape))\n",
    "print (\"Test set Y shape: \" + str(test_set_Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J0qj6i_zDxpr",
    "outputId": "308b7d0b-c0be-437b-c371-d4d10c54c3c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 1)\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(train_set_X.shape[1],))\n",
    "x = keras.layers.Dense(units=3, activation=\"tanh\")(inputs)  # Camada 1 com 3 neurônios\n",
    "x = keras.layers.Dense(units=5, activation=\"tanh\")(x)       # Camada 2 com 5 neurônios\n",
    "x = keras.layers.Dense(units=3, activation=\"tanh\")(x)       # Camada 3 com 3 neurônios\n",
    "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)    # Camada de saída com 1 neurônio\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)         #camada de modelo\n",
    "\n",
    "# Checking\n",
    "processed_data = model(train_set_X)\n",
    "print(processed_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "TquAk7KBEC9T",
    "outputId": "210704d8-7c96-4b91-e7b4-74cc9e261ad6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │              \u001b[38;5;34m27\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m20\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │              \u001b[38;5;34m18\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m4\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69</span> (276.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m69\u001b[0m (276.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69</span> (276.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m69\u001b[0m (276.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prints a summary of the network, showing its architecture and parameters.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "aMmEKYBREIML"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='Nadam',loss=tf.keras.losses.BinaryFocalCrossentropy(),  metrics=['accuracy', 'Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fTbUwSutEOij",
    "outputId": "ebbf219d-3312-425a-a94b-31a09b6023ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.7264 - Recall: 0.5495 - accuracy: 0.7672 - loss: 0.1190\n",
      "Epoch 2/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7482 - Recall: 0.6393 - accuracy: 0.8062 - loss: 0.1146 \n",
      "Epoch 3/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7717 - Recall: 0.5687 - accuracy: 0.7945 - loss: 0.1148 \n",
      "Epoch 4/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7393 - Recall: 0.5682 - accuracy: 0.7723 - loss: 0.1157 \n",
      "Epoch 5/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7271 - Recall: 0.5958 - accuracy: 0.7933 - loss: 0.1113 \n",
      "Epoch 6/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.6943 - Recall: 0.5286 - accuracy: 0.7576 - loss: 0.1212 \n",
      "Epoch 7/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.6770 - Recall: 0.5871 - accuracy: 0.7875 - loss: 0.1145 \n",
      "Epoch 8/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7344 - Recall: 0.5854 - accuracy: 0.7852 - loss: 0.1144 \n",
      "Epoch 9/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6777 - Recall: 0.5046 - accuracy: 0.7593 - loss: 0.1175 \n",
      "Epoch 10/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7216 - Recall: 0.5850 - accuracy: 0.7810 - loss: 0.1149 \n",
      "Epoch 11/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6912 - Recall: 0.5822 - accuracy: 0.7696 - loss: 0.1168 \n",
      "Epoch 12/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7346 - Recall: 0.5623 - accuracy: 0.7784 - loss: 0.1183 \n",
      "Epoch 13/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7404 - Recall: 0.5645 - accuracy: 0.7777 - loss: 0.1170 \n",
      "Epoch 14/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7082 - Recall: 0.5302 - accuracy: 0.7694 - loss: 0.1169  \n",
      "Epoch 15/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7362 - Recall: 0.5554 - accuracy: 0.7767 - loss: 0.1177 \n",
      "Epoch 16/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6855 - Recall: 0.5113 - accuracy: 0.7530 - loss: 0.1210 \n",
      "Epoch 17/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7012 - Recall: 0.5818 - accuracy: 0.7810 - loss: 0.1130  \n",
      "Epoch 18/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7074 - Recall: 0.5796 - accuracy: 0.7768 - loss: 0.1163 \n",
      "Epoch 19/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7117 - Recall: 0.5566 - accuracy: 0.7761 - loss: 0.1147 \n",
      "Epoch 20/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7402 - Recall: 0.5741 - accuracy: 0.7770 - loss: 0.1221 \n",
      "Epoch 21/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6809 - Recall: 0.6124 - accuracy: 0.7683 - loss: 0.1151 \n",
      "Epoch 22/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7354 - Recall: 0.5766 - accuracy: 0.7828 - loss: 0.1129 \n",
      "Epoch 23/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.6757 - Recall: 0.5670 - accuracy: 0.7425 - loss: 0.1251 \n",
      "Epoch 24/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7120 - Recall: 0.6124 - accuracy: 0.7886 - loss: 0.1149 \n",
      "Epoch 25/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.6977 - Recall: 0.5755 - accuracy: 0.7649 - loss: 0.1239 \n",
      "Epoch 26/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7397 - Recall: 0.5929 - accuracy: 0.7820 - loss: 0.1163 \n",
      "Epoch 27/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7260 - Recall: 0.5945 - accuracy: 0.7770 - loss: 0.1177 \n",
      "Epoch 28/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7585 - Recall: 0.5804 - accuracy: 0.7783 - loss: 0.1171  \n",
      "Epoch 29/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6557 - Recall: 0.5872 - accuracy: 0.7521 - loss: 0.1236 \n",
      "Epoch 30/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.6792 - Recall: 0.5766 - accuracy: 0.7658 - loss: 0.1174 \n",
      "Epoch 31/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7160 - Recall: 0.5741 - accuracy: 0.7803 - loss: 0.1145 \n",
      "Epoch 32/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7347 - Recall: 0.5692 - accuracy: 0.7814 - loss: 0.1160 \n",
      "Epoch 33/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.6894 - Recall: 0.5639 - accuracy: 0.7557 - loss: 0.1204 \n",
      "Epoch 34/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7407 - Recall: 0.6121 - accuracy: 0.7899 - loss: 0.1160 \n",
      "Epoch 35/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7354 - Recall: 0.6009 - accuracy: 0.7719 - loss: 0.1169 \n",
      "Epoch 36/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7127 - Recall: 0.6014 - accuracy: 0.7887 - loss: 0.1121 \n",
      "Epoch 37/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7248 - Recall: 0.5856 - accuracy: 0.7845 - loss: 0.1187 \n",
      "Epoch 38/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7038 - Recall: 0.5981 - accuracy: 0.7736 - loss: 0.1180 \n",
      "Epoch 39/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7124 - Recall: 0.5774 - accuracy: 0.7786 - loss: 0.1199 \n",
      "Epoch 40/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7291 - Recall: 0.6105 - accuracy: 0.7810 - loss: 0.1191 \n",
      "Epoch 41/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7283 - Recall: 0.6231 - accuracy: 0.7888 - loss: 0.1077 \n",
      "Epoch 42/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7046 - Recall: 0.5933 - accuracy: 0.7745 - loss: 0.1173 \n",
      "Epoch 43/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7117 - Recall: 0.6059 - accuracy: 0.7740 - loss: 0.1165 \n",
      "Epoch 44/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7056 - Recall: 0.5833 - accuracy: 0.7851 - loss: 0.1160 \n",
      "Epoch 45/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7088 - Recall: 0.5596 - accuracy: 0.7836 - loss: 0.1106 \n",
      "Epoch 46/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7357 - Recall: 0.5763 - accuracy: 0.7644 - loss: 0.1198  \n",
      "Epoch 47/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7184 - Recall: 0.5625 - accuracy: 0.7683 - loss: 0.1199 \n",
      "Epoch 48/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.6823 - Recall: 0.5913 - accuracy: 0.7711 - loss: 0.1163 \n",
      "Epoch 49/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.6918 - Recall: 0.5753 - accuracy: 0.7719 - loss: 0.1171 \n",
      "Epoch 50/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.6820 - Recall: 0.5461 - accuracy: 0.7692 - loss: 0.1184 \n",
      "Epoch 51/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7260 - Recall: 0.5972 - accuracy: 0.7916 - loss: 0.1142 \n",
      "Epoch 52/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7039 - Recall: 0.5581 - accuracy: 0.7563 - loss: 0.1213 \n",
      "Epoch 53/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6822 - Recall: 0.5570 - accuracy: 0.7533 - loss: 0.1223 \n",
      "Epoch 54/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7305 - Recall: 0.5766 - accuracy: 0.7761 - loss: 0.1166 \n",
      "Epoch 55/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7446 - Recall: 0.5975 - accuracy: 0.7919 - loss: 0.1140 \n",
      "Epoch 56/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7237 - Recall: 0.5664 - accuracy: 0.7648 - loss: 0.1194 \n",
      "Epoch 57/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.6797 - Recall: 0.5240 - accuracy: 0.7582 - loss: 0.1214 \n",
      "Epoch 58/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.6867 - Recall: 0.5343 - accuracy: 0.7498 - loss: 0.1201  \n",
      "Epoch 59/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7108 - Recall: 0.5538 - accuracy: 0.7692 - loss: 0.1172 \n",
      "Epoch 60/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7208 - Recall: 0.5806 - accuracy: 0.7799 - loss: 0.1114 \n",
      "Epoch 61/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7401 - Recall: 0.5763 - accuracy: 0.7850 - loss: 0.1135 \n",
      "Epoch 62/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7341 - Recall: 0.6605 - accuracy: 0.8007 - loss: 0.1125 \n",
      "Epoch 63/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7629 - Recall: 0.6058 - accuracy: 0.7876 - loss: 0.1171 \n",
      "Epoch 64/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7091 - Recall: 0.5839 - accuracy: 0.7802 - loss: 0.1164 \n",
      "Epoch 65/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.6908 - Recall: 0.5299 - accuracy: 0.7556 - loss: 0.1219 \n",
      "Epoch 66/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7275 - Recall: 0.6082 - accuracy: 0.7851 - loss: 0.1145 \n",
      "Epoch 67/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7367 - Recall: 0.6265 - accuracy: 0.7902 - loss: 0.1146 \n",
      "Epoch 68/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6668 - Recall: 0.5236 - accuracy: 0.7571 - loss: 0.1223 \n",
      "Epoch 69/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7548 - Recall: 0.5754 - accuracy: 0.7906 - loss: 0.1132 \n",
      "Epoch 70/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.6430 - Recall: 0.5202 - accuracy: 0.7620 - loss: 0.1227 \n",
      "Epoch 71/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7147 - Recall: 0.5906 - accuracy: 0.7714 - loss: 0.1178 \n",
      "Epoch 72/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7388 - Recall: 0.5852 - accuracy: 0.7937 - loss: 0.1106 \n",
      "Epoch 73/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7346 - Recall: 0.5541 - accuracy: 0.7638 - loss: 0.1189  \n",
      "Epoch 74/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7351 - Recall: 0.5630 - accuracy: 0.7873 - loss: 0.1133 \n",
      "Epoch 75/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7449 - Recall: 0.5627 - accuracy: 0.7799 - loss: 0.1148 \n",
      "Epoch 76/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7108 - Recall: 0.5578 - accuracy: 0.7906 - loss: 0.1099 \n",
      "Epoch 77/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.6797 - Recall: 0.5320 - accuracy: 0.7576 - loss: 0.1192  \n",
      "Epoch 78/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7575 - Recall: 0.6385 - accuracy: 0.8024 - loss: 0.1096 \n",
      "Epoch 79/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7004 - Recall: 0.5514 - accuracy: 0.7696 - loss: 0.1172 \n",
      "Epoch 80/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7588 - Recall: 0.6244 - accuracy: 0.8070 - loss: 0.1102  \n",
      "Epoch 81/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7254 - Recall: 0.5856 - accuracy: 0.7765 - loss: 0.1203 \n",
      "Epoch 82/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7064 - Recall: 0.5653 - accuracy: 0.7784 - loss: 0.1114 \n",
      "Epoch 83/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7697 - Recall: 0.6022 - accuracy: 0.7982 - loss: 0.1137 \n",
      "Epoch 84/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7105 - Recall: 0.5247 - accuracy: 0.7425 - loss: 0.1240 \n",
      "Epoch 85/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.6985 - Recall: 0.5619 - accuracy: 0.7628 - loss: 0.1198 \n",
      "Epoch 86/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7291 - Recall: 0.5476 - accuracy: 0.7779 - loss: 0.1117 \n",
      "Epoch 87/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.6836 - Recall: 0.5206 - accuracy: 0.7676 - loss: 0.1171 \n",
      "Epoch 88/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7455 - Recall: 0.5922 - accuracy: 0.7953 - loss: 0.1117 \n",
      "Epoch 89/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7147 - Recall: 0.5504 - accuracy: 0.7703 - loss: 0.1166 \n",
      "Epoch 90/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7483 - Recall: 0.5711 - accuracy: 0.7775 - loss: 0.1172 \n",
      "Epoch 91/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7042 - Recall: 0.5344 - accuracy: 0.7613 - loss: 0.1180 \n",
      "Epoch 92/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.6811 - Recall: 0.5827 - accuracy: 0.7643 - loss: 0.1162 \n",
      "Epoch 93/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7382 - Recall: 0.6236 - accuracy: 0.7925 - loss: 0.1132 \n",
      "Epoch 94/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7111 - Recall: 0.5415 - accuracy: 0.7641 - loss: 0.1205  \n",
      "Epoch 95/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7139 - Recall: 0.5666 - accuracy: 0.7768 - loss: 0.1119 \n",
      "Epoch 96/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7050 - Recall: 0.5444 - accuracy: 0.7670 - loss: 0.1168 \n",
      "Epoch 97/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7181 - Recall: 0.5650 - accuracy: 0.7670 - loss: 0.1159 \n",
      "Epoch 98/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7447 - Recall: 0.6125 - accuracy: 0.8088 - loss: 0.1101 \n",
      "Epoch 99/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Precision: 0.7458 - Recall: 0.5572 - accuracy: 0.7718 - loss: 0.1181\n",
      "Epoch 100/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7467 - Recall: 0.5864 - accuracy: 0.7886 - loss: 0.1138 \n",
      "Epoch 101/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.6845 - Recall: 0.5562 - accuracy: 0.7638 - loss: 0.1191  \n",
      "Epoch 102/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7396 - Recall: 0.5827 - accuracy: 0.7782 - loss: 0.1196 \n",
      "Epoch 103/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6934 - Recall: 0.5288 - accuracy: 0.7725 - loss: 0.1116 \n",
      "Epoch 104/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7090 - Recall: 0.5814 - accuracy: 0.7723 - loss: 0.1171 \n",
      "Epoch 105/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7066 - Recall: 0.5836 - accuracy: 0.7751 - loss: 0.1150 \n",
      "Epoch 106/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.6625 - Recall: 0.5293 - accuracy: 0.7480 - loss: 0.1227 \n",
      "Epoch 107/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7332 - Recall: 0.5957 - accuracy: 0.8000 - loss: 0.1069 \n",
      "Epoch 108/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7405 - Recall: 0.6405 - accuracy: 0.7983 - loss: 0.1118 \n",
      "Epoch 109/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7248 - Recall: 0.5813 - accuracy: 0.7844 - loss: 0.1143 \n",
      "Epoch 110/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7223 - Recall: 0.5707 - accuracy: 0.7747 - loss: 0.1132  \n",
      "Epoch 111/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7409 - Recall: 0.5835 - accuracy: 0.7767 - loss: 0.1188 \n",
      "Epoch 112/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7408 - Recall: 0.5976 - accuracy: 0.7988 - loss: 0.1098 \n",
      "Epoch 113/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7143 - Recall: 0.5719 - accuracy: 0.7691 - loss: 0.1178 \n",
      "Epoch 114/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6891 - Recall: 0.5583 - accuracy: 0.7630 - loss: 0.1175 \n",
      "Epoch 115/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7353 - Recall: 0.5712 - accuracy: 0.7809 - loss: 0.1134 \n",
      "Epoch 116/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7552 - Recall: 0.5731 - accuracy: 0.7859 - loss: 0.1120 \n",
      "Epoch 117/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7110 - Recall: 0.6103 - accuracy: 0.7812 - loss: 0.1112 \n",
      "Epoch 118/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6949 - Recall: 0.5356 - accuracy: 0.7682 - loss: 0.1210 \n",
      "Epoch 119/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7033 - Recall: 0.5373 - accuracy: 0.7520 - loss: 0.1225 \n",
      "Epoch 120/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7427 - Recall: 0.5754 - accuracy: 0.7751 - loss: 0.1198 \n",
      "Epoch 121/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7558 - Recall: 0.6019 - accuracy: 0.7939 - loss: 0.1086 \n",
      "Epoch 122/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7124 - Recall: 0.5009 - accuracy: 0.7574 - loss: 0.1176 \n",
      "Epoch 123/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7666 - Recall: 0.5476 - accuracy: 0.7729 - loss: 0.1144 \n",
      "Epoch 124/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7228 - Recall: 0.6035 - accuracy: 0.7930 - loss: 0.1148 \n",
      "Epoch 125/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7186 - Recall: 0.5457 - accuracy: 0.7659 - loss: 0.1168  \n",
      "Epoch 126/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7117 - Recall: 0.5674 - accuracy: 0.7812 - loss: 0.1162 \n",
      "Epoch 127/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7444 - Recall: 0.6116 - accuracy: 0.7910 - loss: 0.1135 \n",
      "Epoch 128/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7275 - Recall: 0.5740 - accuracy: 0.7754 - loss: 0.1148 \n",
      "Epoch 129/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7676 - Recall: 0.5890 - accuracy: 0.7953 - loss: 0.1103 \n",
      "Epoch 130/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6942 - Recall: 0.6081 - accuracy: 0.7770 - loss: 0.1131 \n",
      "Epoch 131/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7049 - Recall: 0.5269 - accuracy: 0.7650 - loss: 0.1153 \n",
      "Epoch 132/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7494 - Recall: 0.5714 - accuracy: 0.7868 - loss: 0.1106 \n",
      "Epoch 133/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7271 - Recall: 0.6017 - accuracy: 0.7859 - loss: 0.1136 \n",
      "Epoch 134/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7417 - Recall: 0.6024 - accuracy: 0.8007 - loss: 0.1108 \n",
      "Epoch 135/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7485 - Recall: 0.5874 - accuracy: 0.7925 - loss: 0.1124 \n",
      "Epoch 136/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7052 - Recall: 0.6015 - accuracy: 0.7770 - loss: 0.1157 \n",
      "Epoch 137/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7119 - Recall: 0.5614 - accuracy: 0.7584 - loss: 0.1187  \n",
      "Epoch 138/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7288 - Recall: 0.5733 - accuracy: 0.7603 - loss: 0.1163 \n",
      "Epoch 139/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7133 - Recall: 0.5784 - accuracy: 0.7808 - loss: 0.1126 \n",
      "Epoch 140/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7072 - Recall: 0.5448 - accuracy: 0.7730 - loss: 0.1147  \n",
      "Epoch 141/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7375 - Recall: 0.5573 - accuracy: 0.7867 - loss: 0.1128 \n",
      "Epoch 142/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7086 - Recall: 0.5779 - accuracy: 0.7776 - loss: 0.1162 \n",
      "Epoch 143/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7407 - Recall: 0.5822 - accuracy: 0.7820 - loss: 0.1130 \n",
      "Epoch 144/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7368 - Recall: 0.5972 - accuracy: 0.7849 - loss: 0.1090 \n",
      "Epoch 145/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7625 - Recall: 0.5957 - accuracy: 0.7953 - loss: 0.1134 \n",
      "Epoch 146/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7633 - Recall: 0.6123 - accuracy: 0.7912 - loss: 0.1120 \n",
      "Epoch 147/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7456 - Recall: 0.5785 - accuracy: 0.7754 - loss: 0.1128 \n",
      "Epoch 148/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7401 - Recall: 0.5819 - accuracy: 0.7803 - loss: 0.1167 \n",
      "Epoch 149/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7171 - Recall: 0.5648 - accuracy: 0.7836 - loss: 0.1111 \n",
      "Epoch 150/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7630 - Recall: 0.6070 - accuracy: 0.7964 - loss: 0.1103 \n",
      "Epoch 151/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6885 - Recall: 0.5904 - accuracy: 0.7786 - loss: 0.1158 \n",
      "Epoch 152/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7183 - Recall: 0.5841 - accuracy: 0.7741 - loss: 0.1154 \n",
      "Epoch 153/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7391 - Recall: 0.6038 - accuracy: 0.7796 - loss: 0.1152 \n",
      "Epoch 154/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7649 - Recall: 0.5978 - accuracy: 0.7957 - loss: 0.1074  \n",
      "Epoch 155/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7293 - Recall: 0.5968 - accuracy: 0.7797 - loss: 0.1135 \n",
      "Epoch 156/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7242 - Recall: 0.5486 - accuracy: 0.7629 - loss: 0.1191 \n",
      "Epoch 157/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7685 - Recall: 0.5703 - accuracy: 0.7804 - loss: 0.1146 \n",
      "Epoch 158/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7276 - Recall: 0.5785 - accuracy: 0.7802 - loss: 0.1154 \n",
      "Epoch 159/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6940 - Recall: 0.5419 - accuracy: 0.7678 - loss: 0.1129 \n",
      "Epoch 160/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6986 - Recall: 0.5785 - accuracy: 0.7727 - loss: 0.1125 \n",
      "Epoch 161/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7591 - Recall: 0.6161 - accuracy: 0.8029 - loss: 0.1082 \n",
      "Epoch 162/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7503 - Recall: 0.5610 - accuracy: 0.7918 - loss: 0.1056 \n",
      "Epoch 163/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7162 - Recall: 0.5674 - accuracy: 0.7682 - loss: 0.1144 \n",
      "Epoch 164/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7204 - Recall: 0.5582 - accuracy: 0.7678 - loss: 0.1191 \n",
      "Epoch 165/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7043 - Recall: 0.5750 - accuracy: 0.7784 - loss: 0.1162  \n",
      "Epoch 166/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7442 - Recall: 0.5578 - accuracy: 0.7642 - loss: 0.1143 \n",
      "Epoch 167/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6825 - Recall: 0.5552 - accuracy: 0.7674 - loss: 0.1200 \n",
      "Epoch 168/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7187 - Recall: 0.5485 - accuracy: 0.7662 - loss: 0.1185 \n",
      "Epoch 169/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7123 - Recall: 0.5327 - accuracy: 0.7578 - loss: 0.1185 \n",
      "Epoch 170/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7218 - Recall: 0.5685 - accuracy: 0.7837 - loss: 0.1109 \n",
      "Epoch 171/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7328 - Recall: 0.5996 - accuracy: 0.7868 - loss: 0.1127 \n",
      "Epoch 172/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7785 - Recall: 0.5681 - accuracy: 0.7789 - loss: 0.1173 \n",
      "Epoch 173/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7245 - Recall: 0.5876 - accuracy: 0.7833 - loss: 0.1138 \n",
      "Epoch 174/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7484 - Recall: 0.5857 - accuracy: 0.7851 - loss: 0.1160 \n",
      "Epoch 175/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7503 - Recall: 0.5611 - accuracy: 0.7841 - loss: 0.1147 \n",
      "Epoch 176/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6666 - Recall: 0.5593 - accuracy: 0.7625 - loss: 0.1168 \n",
      "Epoch 177/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7205 - Recall: 0.5662 - accuracy: 0.7784 - loss: 0.1115 \n",
      "Epoch 178/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7298 - Recall: 0.5665 - accuracy: 0.7866 - loss: 0.1100 \n",
      "Epoch 179/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7167 - Recall: 0.5862 - accuracy: 0.7882 - loss: 0.1119 \n",
      "Epoch 180/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.7208 - Recall: 0.5895 - accuracy: 0.7843 - loss: 0.1146  \n",
      "Epoch 181/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7302 - Recall: 0.6082 - accuracy: 0.7899 - loss: 0.1148 \n",
      "Epoch 182/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7130 - Recall: 0.5690 - accuracy: 0.7751 - loss: 0.1132 \n",
      "Epoch 183/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7391 - Recall: 0.5818 - accuracy: 0.7862 - loss: 0.1135 \n",
      "Epoch 184/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7251 - Recall: 0.5793 - accuracy: 0.7707 - loss: 0.1151 \n",
      "Epoch 185/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7122 - Recall: 0.5984 - accuracy: 0.7776 - loss: 0.1144 \n",
      "Epoch 186/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6939 - Recall: 0.5276 - accuracy: 0.7579 - loss: 0.1153 \n",
      "Epoch 187/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7401 - Recall: 0.6232 - accuracy: 0.7941 - loss: 0.1060 \n",
      "Epoch 188/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6875 - Recall: 0.5428 - accuracy: 0.7714 - loss: 0.1132 \n",
      "Epoch 189/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7265 - Recall: 0.5679 - accuracy: 0.7824 - loss: 0.1129 \n",
      "Epoch 190/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7145 - Recall: 0.5483 - accuracy: 0.7598 - loss: 0.1159 \n",
      "Epoch 191/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6885 - Recall: 0.5461 - accuracy: 0.7701 - loss: 0.1126 \n",
      "Epoch 192/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6934 - Recall: 0.5886 - accuracy: 0.7711 - loss: 0.1153 \n",
      "Epoch 193/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7560 - Recall: 0.5984 - accuracy: 0.7786 - loss: 0.1130 \n",
      "Epoch 194/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7457 - Recall: 0.6128 - accuracy: 0.7901 - loss: 0.1086  \n",
      "Epoch 195/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7023 - Recall: 0.5651 - accuracy: 0.7698 - loss: 0.1159 \n",
      "Epoch 196/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.6893 - Recall: 0.6019 - accuracy: 0.7831 - loss: 0.1141 \n",
      "Epoch 197/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Precision: 0.7062 - Recall: 0.5707 - accuracy: 0.7645 - loss: 0.1171  \n",
      "Epoch 198/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6908 - Recall: 0.5476 - accuracy: 0.7548 - loss: 0.1184 \n",
      "Epoch 199/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6849 - Recall: 0.5779 - accuracy: 0.7821 - loss: 0.1086 \n",
      "Epoch 200/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7196 - Recall: 0.5769 - accuracy: 0.7777 - loss: 0.1169 \n",
      "{'Precision': [0.6994219422340393, 0.7058823704719543, 0.707602322101593, 0.7100591659545898, 0.7065868377685547, 0.7108433842658997, 0.7108433842658997, 0.7100591659545898, 0.7083333134651184, 0.7100591659545898, 0.7041420340538025, 0.7083333134651184, 0.7083333134651184, 0.7108433842658997, 0.7083333134651184, 0.7058823704719543, 0.7041420340538025, 0.7083333134651184, 0.7058823704719543, 0.694915235042572, 0.6994219422340393, 0.6994219422340393, 0.7011494040489197, 0.7058823704719543, 0.6971428394317627, 0.7034883499145508, 0.7052023410797119, 0.7093023061752319, 0.707602322101593, 0.7023809552192688, 0.715976357460022, 0.707602322101593, 0.7052023410797119, 0.707602322101593, 0.7117646932601929, 0.7065868377685547, 0.707602322101593, 0.7109826803207397, 0.7151162624359131, 0.7134503126144409, 0.7052023410797119, 0.7134503126144409, 0.7134503126144409, 0.7117646932601929, 0.7041420340538025, 0.7052023410797119, 0.7017543911933899, 0.71257483959198, 0.71257483959198, 0.71856290102005, 0.7202380895614624, 0.7041420340538025, 0.7083333134651184, 0.7100591659545898, 0.7142857313156128, 0.7117646932601929, 0.71856290102005, 0.7083333134651184, 0.7117646932601929, 0.7083333134651184, 0.7093023061752319, 0.715976357460022, 0.7117646932601929, 0.7117646932601929, 0.7100591659545898, 0.707602322101593, 0.71856290102005, 0.71856290102005, 0.7176470756530762, 0.7176470756530762, 0.7218934893608093, 0.7202380895614624, 0.7142857313156128, 0.71856290102005, 0.7212121486663818, 0.7212121486663818, 0.7212121486663818, 0.7202380895614624, 0.7218934893608093, 0.7202380895614624, 0.7093023061752319, 0.7093023061752319, 0.7305389046669006, 0.7202380895614624, 0.7228915691375732, 0.7151514887809753, 0.7195122241973877, 0.7317073345184326, 0.71856290102005, 0.7195122241973877, 0.7168674468994141, 0.7245509028434753, 0.71856290102005, 0.71856290102005, 0.71856290102005, 0.7212121486663818, 0.7272727489471436, 0.7245509028434753, 0.7202380895614624, 0.7218934893608093, 0.7272727489471436, 0.7245509028434753, 0.7176470756530762, 0.7093023061752319, 0.7134503126144409, 0.715976357460022, 0.7245509028434753, 0.7245509028434753, 0.715976357460022, 0.7245509028434753, 0.715976357460022, 0.7245509028434753, 0.715976357460022, 0.7100591659545898, 0.7100591659545898, 0.715976357460022, 0.7245509028434753, 0.71856290102005, 0.715976357460022, 0.7228915691375732, 0.7300613522529602, 0.7256097793579102, 0.7245509028434753, 0.7333333492279053, 0.7272727489471436, 0.7256097793579102, 0.726190447807312, 0.7209302186965942, 0.719298243522644, 0.7228915691375732, 0.7317073345184326, 0.7225433588027954, 0.7251461744308472, 0.7245509028434753, 0.7305389046669006, 0.7337278127670288, 0.7167630195617676, 0.7126436829566956, 0.7289156913757324, 0.7283950448036194, 0.7228915691375732, 0.7289156913757324, 0.7202380895614624, 0.7134503126144409, 0.7251461744308472, 0.7126436829566956, 0.7151162624359131, 0.7245509028434753, 0.7283950448036194, 0.7300613522529602, 0.7289156913757324, 0.7235293984413147, 0.719298243522644, 0.719298243522644, 0.7278106212615967, 0.7228915691375732, 0.7202380895614624, 0.7176470756530762, 0.715976357460022, 0.7218934893608093, 0.7289156913757324, 0.7245509028434753, 0.7289156913757324, 0.7245509028434753, 0.7228915691375732, 0.7142857313156128, 0.7283950448036194, 0.7317073345184326, 0.7245509028434753, 0.7245509028434753, 0.7245509028434753, 0.7176470756530762, 0.7228915691375732, 0.7228915691375732, 0.7228915691375732, 0.7272727489471436, 0.7202380895614624, 0.7202380895614624, 0.7245509028434753, 0.7245509028434753, 0.7202380895614624, 0.715976357460022, 0.715976357460022, 0.7202380895614624, 0.7202380895614624, 0.7228915691375732, 0.7202380895614624, 0.7228915691375732, 0.7202380895614624, 0.7134503126144409, 0.7176470756530762, 0.7176470756530762, 0.7134503126144409, 0.7176470756530762, 0.71856290102005, 0.7228915691375732, 0.715976357460022, 0.7176470756530762, 0.7218934893608093, 0.7176470756530762], 'Recall': [0.5734597444534302, 0.5687204003334045, 0.5734597444534302, 0.5687204003334045, 0.5592417120933533, 0.5592417120933533, 0.5592417120933533, 0.5687204003334045, 0.5639810562133789, 0.5687204003334045, 0.5639810562133789, 0.5639810562133789, 0.5639810562133789, 0.5592417120933533, 0.5639810562133789, 0.5687204003334045, 0.5639810562133789, 0.5639810562133789, 0.5687204003334045, 0.5829383730888367, 0.5734597444534302, 0.5734597444534302, 0.578199028968811, 0.5687204003334045, 0.578199028968811, 0.5734597444534302, 0.578199028968811, 0.578199028968811, 0.5734597444534302, 0.5592417120933533, 0.5734597444534302, 0.5734597444534302, 0.578199028968811, 0.5734597444534302, 0.5734597444534302, 0.5592417120933533, 0.5734597444534302, 0.5829383730888367, 0.5829383730888367, 0.578199028968811, 0.578199028968811, 0.578199028968811, 0.578199028968811, 0.5734597444534302, 0.5639810562133789, 0.578199028968811, 0.5687204003334045, 0.5639810562133789, 0.5639810562133789, 0.5687204003334045, 0.5734597444534302, 0.5639810562133789, 0.5639810562133789, 0.5687204003334045, 0.5687204003334045, 0.5734597444534302, 0.5687204003334045, 0.5639810562133789, 0.5734597444534302, 0.5639810562133789, 0.578199028968811, 0.5734597444534302, 0.5734597444534302, 0.5734597444534302, 0.5687204003334045, 0.5734597444534302, 0.5687204003334045, 0.5687204003334045, 0.578199028968811, 0.578199028968811, 0.578199028968811, 0.5734597444534302, 0.5687204003334045, 0.5687204003334045, 0.5639810562133789, 0.5639810562133789, 0.5639810562133789, 0.5734597444534302, 0.578199028968811, 0.5734597444534302, 0.578199028968811, 0.578199028968811, 0.578199028968811, 0.5734597444534302, 0.5687204003334045, 0.5592417120933533, 0.5592417120933533, 0.5687204003334045, 0.5687204003334045, 0.5592417120933533, 0.5639810562133789, 0.5734597444534302, 0.5687204003334045, 0.5687204003334045, 0.5687204003334045, 0.5639810562133789, 0.5687204003334045, 0.5734597444534302, 0.5734597444534302, 0.578199028968811, 0.5687204003334045, 0.5734597444534302, 0.578199028968811, 0.578199028968811, 0.578199028968811, 0.5734597444534302, 0.5734597444534302, 0.5734597444534302, 0.5734597444534302, 0.5734597444534302, 0.5734597444534302, 0.5734597444534302, 0.5734597444534302, 0.5687204003334045, 0.5687204003334045, 0.5734597444534302, 0.5734597444534302, 0.5687204003334045, 0.5734597444534302, 0.5687204003334045, 0.5639810562133789, 0.5639810562133789, 0.5734597444534302, 0.5734597444534302, 0.5687204003334045, 0.5639810562133789, 0.578199028968811, 0.5876777172088623, 0.5829383730888367, 0.5687204003334045, 0.5687204003334045, 0.5924170613288879, 0.5876777172088623, 0.5734597444534302, 0.578199028968811, 0.5876777172088623, 0.5876777172088623, 0.5876777172088623, 0.5734597444534302, 0.5592417120933533, 0.5687204003334045, 0.5734597444534302, 0.5734597444534302, 0.578199028968811, 0.5876777172088623, 0.5876777172088623, 0.5829383730888367, 0.5734597444534302, 0.5592417120933533, 0.5639810562133789, 0.5734597444534302, 0.5829383730888367, 0.5829383730888367, 0.5829383730888367, 0.5829383730888367, 0.5687204003334045, 0.5734597444534302, 0.578199028968811, 0.5734597444534302, 0.578199028968811, 0.5734597444534302, 0.5734597444534302, 0.5734597444534302, 0.5734597444534302, 0.5687204003334045, 0.5687204003334045, 0.5592417120933533, 0.5687204003334045, 0.5734597444534302, 0.5734597444534302, 0.5734597444534302, 0.578199028968811, 0.5687204003334045, 0.5687204003334045, 0.5687204003334045, 0.5687204003334045, 0.5734597444534302, 0.5734597444534302, 0.5734597444534302, 0.5734597444534302, 0.5734597444534302, 0.5734597444534302, 0.5734597444534302, 0.5734597444534302, 0.5734597444534302, 0.5687204003334045, 0.5734597444534302, 0.5687204003334045, 0.5734597444534302, 0.578199028968811, 0.578199028968811, 0.578199028968811, 0.578199028968811, 0.578199028968811, 0.5687204003334045, 0.5687204003334045, 0.5734597444534302, 0.578199028968811, 0.578199028968811, 0.578199028968811], 'accuracy': [0.7687296271324158, 0.7703583240509033, 0.7719869613647461, 0.7719869613647461, 0.7687296271324158, 0.7703583240509033, 0.7703583240509033, 0.7719869613647461, 0.7703583240509033, 0.7719869613647461, 0.7687296271324158, 0.7703583240509033, 0.7703583240509033, 0.7703583240509033, 0.7703583240509033, 0.7703583240509033, 0.7687296271324158, 0.7703583240509033, 0.7703583240509033, 0.7687296271324158, 0.7687296271324158, 0.7687296271324158, 0.7703583240509033, 0.7703583240509033, 0.7687296271324158, 0.7703583240509033, 0.7719869613647461, 0.7736156582832336, 0.7719869613647461, 0.767100989818573, 0.7752442955970764, 0.7719869613647461, 0.7719869613647461, 0.7719869613647461, 0.7736156582832336, 0.7687296271324158, 0.7719869613647461, 0.7752442955970764, 0.776872992515564, 0.7752442955970764, 0.7719869613647461, 0.7752442955970764, 0.7752442955970764, 0.7736156582832336, 0.7687296271324158, 0.7719869613647461, 0.7687296271324158, 0.7719869613647461, 0.7719869613647461, 0.7752442955970764, 0.776872992515564, 0.7687296271324158, 0.7703583240509033, 0.7719869613647461, 0.7736156582832336, 0.7736156582832336, 0.7752442955970764, 0.7703583240509033, 0.7736156582832336, 0.7703583240509033, 0.7736156582832336, 0.7752442955970764, 0.7736156582832336, 0.7736156582832336, 0.7719869613647461, 0.7719869613647461, 0.7752442955970764, 0.7752442955970764, 0.776872992515564, 0.776872992515564, 0.7785016298294067, 0.776872992515564, 0.7736156582832336, 0.7752442955970764, 0.7752442955970764, 0.7752442955970764, 0.7752442955970764, 0.776872992515564, 0.7785016298294067, 0.776872992515564, 0.7736156582832336, 0.7736156582832336, 0.7817589640617371, 0.776872992515564, 0.776872992515564, 0.7719869613647461, 0.7736156582832336, 0.7801302671432495, 0.7752442955970764, 0.7736156582832336, 0.7736156582832336, 0.7785016298294067, 0.7752442955970764, 0.7752442955970764, 0.7752442955970764, 0.7752442955970764, 0.7785016298294067, 0.7785016298294067, 0.776872992515564, 0.7785016298294067, 0.7785016298294067, 0.7785016298294067, 0.776872992515564, 0.7736156582832336, 0.7752442955970764, 0.7752442955970764, 0.7785016298294067, 0.7785016298294067, 0.7752442955970764, 0.7785016298294067, 0.7752442955970764, 0.7785016298294067, 0.7752442955970764, 0.7719869613647461, 0.7719869613647461, 0.7752442955970764, 0.7785016298294067, 0.7752442955970764, 0.7752442955970764, 0.776872992515564, 0.7785016298294067, 0.776872992515564, 0.7785016298294067, 0.7817589640617371, 0.7785016298294067, 0.776872992515564, 0.7801302671432495, 0.7801302671432495, 0.7785016298294067, 0.776872992515564, 0.7801302671432495, 0.7817589640617371, 0.7817589640617371, 0.7785016298294067, 0.7817589640617371, 0.7850162982940674, 0.7785016298294067, 0.776872992515564, 0.7801302671432495, 0.776872992515564, 0.776872992515564, 0.7801302671432495, 0.776872992515564, 0.7752442955970764, 0.7817589640617371, 0.776872992515564, 0.776872992515564, 0.7785016298294067, 0.776872992515564, 0.7785016298294067, 0.7801302671432495, 0.7801302671432495, 0.7785016298294067, 0.7785016298294067, 0.7817589640617371, 0.776872992515564, 0.776872992515564, 0.776872992515564, 0.7752442955970764, 0.7785016298294067, 0.7801302671432495, 0.7785016298294067, 0.7801302671432495, 0.7785016298294067, 0.776872992515564, 0.7736156582832336, 0.776872992515564, 0.7801302671432495, 0.7785016298294067, 0.7785016298294067, 0.7785016298294067, 0.776872992515564, 0.776872992515564, 0.776872992515564, 0.776872992515564, 0.7785016298294067, 0.776872992515564, 0.776872992515564, 0.7785016298294067, 0.7785016298294067, 0.776872992515564, 0.7752442955970764, 0.7752442955970764, 0.776872992515564, 0.776872992515564, 0.776872992515564, 0.776872992515564, 0.776872992515564, 0.776872992515564, 0.7752442955970764, 0.776872992515564, 0.776872992515564, 0.7752442955970764, 0.776872992515564, 0.7752442955970764, 0.776872992515564, 0.7752442955970764, 0.776872992515564, 0.7785016298294067, 0.776872992515564], 'loss': [0.11986292898654938, 0.11964274942874908, 0.11962220817804337, 0.11947092413902283, 0.11950458586215973, 0.11938225477933884, 0.11935734003782272, 0.11921064555644989, 0.11913537234067917, 0.11908528208732605, 0.11900795251131058, 0.11896246671676636, 0.11890500783920288, 0.1188628226518631, 0.11882533133029938, 0.11874030530452728, 0.1187233179807663, 0.11857498437166214, 0.11856140941381454, 0.11857229471206665, 0.11855005472898483, 0.11838686466217041, 0.11837498843669891, 0.11829680949449539, 0.11835310608148575, 0.11819515377283096, 0.11812477558851242, 0.11807206273078918, 0.1180761530995369, 0.11801587045192719, 0.11794652789831161, 0.1179785206913948, 0.11789139360189438, 0.11786727607250214, 0.117784284055233, 0.11778359860181808, 0.1176740899682045, 0.11766716092824936, 0.11760825663805008, 0.11758594214916229, 0.11756911873817444, 0.11750741302967072, 0.11742008477449417, 0.11743053793907166, 0.1173667386174202, 0.1173759326338768, 0.1172977164387703, 0.1173262670636177, 0.1172003224492073, 0.11715897172689438, 0.11710640788078308, 0.11716978996992111, 0.11710456013679504, 0.11701565235853195, 0.11700979620218277, 0.11697884649038315, 0.11692249774932861, 0.11687470972537994, 0.11684929579496384, 0.11684498190879822, 0.11682485789060593, 0.11681158095598221, 0.11673679202795029, 0.11665995419025421, 0.11664785444736481, 0.11663773655891418, 0.11665105819702148, 0.11659856885671616, 0.11657969653606415, 0.11663457006216049, 0.1164618656039238, 0.11652228981256485, 0.116426981985569, 0.11639657616615295, 0.1163744255900383, 0.11630920320749283, 0.11629491299390793, 0.11631373316049576, 0.11624592542648315, 0.11624225229024887, 0.1163482815027237, 0.11615628749132156, 0.1161581501364708, 0.11618306487798691, 0.11609452962875366, 0.11607573181390762, 0.11604569107294083, 0.11605151742696762, 0.11592919379472733, 0.11591064184904099, 0.11591832339763641, 0.11585486680269241, 0.1158050000667572, 0.11583436280488968, 0.11584097146987915, 0.11585155874490738, 0.11569388955831528, 0.1157601848244667, 0.11564651131629944, 0.11573903262615204, 0.11563623696565628, 0.11553230881690979, 0.11554945260286331, 0.11548206955194473, 0.11543666571378708, 0.11545974016189575, 0.11537793278694153, 0.11531978845596313, 0.11527629941701889, 0.11525367200374603, 0.11522594094276428, 0.11521318554878235, 0.11520466208457947, 0.11518087238073349, 0.11511057615280151, 0.11506916582584381, 0.11503513157367706, 0.11505037546157837, 0.11496033519506454, 0.11497332155704498, 0.11491965502500534, 0.11490140110254288, 0.11492076516151428, 0.11484123766422272, 0.11484678834676743, 0.1147691085934639, 0.11477240920066833, 0.11469680070877075, 0.11468967795372009, 0.11478187888860703, 0.11461514979600906, 0.11465328931808472, 0.11456619203090668, 0.1146252378821373, 0.11456405371427536, 0.11452563852071762, 0.11451064050197601, 0.1145377978682518, 0.114504374563694, 0.11450253427028656, 0.1144188717007637, 0.11438172310590744, 0.11438356339931488, 0.11439143866300583, 0.11430409550666809, 0.11445257067680359, 0.11429859697818756, 0.1143292635679245, 0.11428575962781906, 0.11423572152853012, 0.11431468278169632, 0.11422387510538101, 0.11422043293714523, 0.1142139732837677, 0.11413633823394775, 0.11413738131523132, 0.11411953717470169, 0.11412494629621506, 0.11411220580339432, 0.11407632380723953, 0.1140732392668724, 0.11408033221960068, 0.1139923706650734, 0.11406189948320389, 0.11399028450250626, 0.11399830132722855, 0.11395291984081268, 0.11396946012973785, 0.11396955698728561, 0.11394298076629639, 0.1139000654220581, 0.11391675472259521, 0.11389397829771042, 0.11389458179473877, 0.11386992782354355, 0.11386261135339737, 0.11378906667232513, 0.1138039380311966, 0.1138865202665329, 0.11376333981752396, 0.11376670747995377, 0.11373802274465561, 0.11377140879631042, 0.11376182734966278, 0.11377857625484467, 0.11366893351078033, 0.11372347921133041, 0.11369582265615463, 0.1136598214507103, 0.11362572759389877, 0.11362617462873459, 0.11358299851417542, 0.1135929524898529, 0.1136217787861824, 0.11365203559398651, 0.11355302482843399, 0.1135445386171341, 0.11349334567785263, 0.11350619047880173, 0.11350629478693008]}\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set_X, train_set_Y, batch_size=64, epochs=200)\n",
    "\n",
    "print(history.history)  # print per-epoch timeseries of metrics values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZaInGystESnk",
    "outputId": "99a97df5-b974-4728-b862-eb1e7be0d85b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.7669 - Recall: 0.6442 - accuracy: 0.7996 - loss: 0.1150  \n",
      "Loss: 0.12 \n",
      "Accuracy: 0.81 \n",
      "Precision: 0.80 \n",
      "Recall: 0.63\n"
     ]
    }
   ],
   "source": [
    "loss, acc, prec, rec = model.evaluate(test_set_X, test_set_Y)\n",
    "\n",
    "print(\"Loss: %.2f\" % loss, \"\\nAccuracy: %.2f\" % acc, \"\\nPrecision: %.2f\" % prec, \"\\nRecall: %.2f\" % rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wa620_k1EYUr",
    "outputId": "946963a8-41de-450f-8ded-7abbbbd2ebf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Predictions:  [0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0]\n",
      "\n",
      "Correct:      [0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "### INICIE O CÓDIGO AQUI ### (1 linha de código)\n",
    "predictions = model.predict(test_set_X)\n",
    "### TERMINE O CÓDIGO AQUI ###\n",
    "print(\"Predictions: \", [round(x[0]) for x in predictions])\n",
    "print(\"\\nCorrect:     \", [round(x) for x in test_set_Y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bodjhCTTI9XI"
   },
   "source": [
    "Consegui capturar um Overfitting para as seguintes configurações:\n",
    "\n",
    "\n",
    "*   test_size=0.001;\n",
    "*   model.compile(optimizer='Adam',loss='binary_crossentropy',  metrics=['accuracy', 'Precision', 'Recall']);\n",
    "*   history = model.fit(train_set_X, train_set_Y, batch_size=64, epochs=200)\n",
    "\n",
    "**Restante do código permaneu igual o original**\n",
    "\n",
    "*Obs.: não foi a solução do desafio mas foi uma resposta interessante.*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rVFQXBkvaeF"
   },
   "source": [
    "# Fim\n",
    "\n",
    "Parabéns! Você efetuou todos os passos para criar uma rede neural com várias camadas para um problema de classificação binária.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
